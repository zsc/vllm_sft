# ç¬¬ 3 ç« ï¼šSFT è®­ç»ƒç­–ç•¥

ç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-Tuning, SFTï¼‰æ˜¯å°†é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹é€‚é…åˆ°ç‰¹å®šä»»åŠ¡çš„å…³é”®æ­¥éª¤ã€‚ä¸çº¯è¯­è¨€æ¨¡å‹ä¸åŒï¼ŒVLM çš„ SFT éœ€è¦åŒæ—¶è€ƒè™‘è§†è§‰å’Œè¯­è¨€ä¸¤ç§æ¨¡æ€çš„å¯¹é½ï¼Œè¿™å¸¦æ¥äº†ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼šå¦‚ä½•è®¾è®¡æœ‰æ•ˆçš„æŒ‡ä»¤æ ¼å¼ï¼Ÿå¦‚ä½•å¹³è¡¡ä¸åŒä»»åŠ¡çš„æŸå¤±ï¼Ÿå¦‚ä½•åœ¨æœ‰é™çš„è®¡ç®—èµ„æºä¸‹é«˜æ•ˆå¾®è°ƒï¼Ÿæœ¬ç« å°†ç³»ç»Ÿä»‹ç» VLM SFT çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œä»æŒ‡ä»¤è®¾è®¡åˆ°è®­ç»ƒä¼˜åŒ–ï¼Œå¸®åŠ©æ‚¨æŒæ¡å°†é€šç”¨ VLM è½¬åŒ–ä¸ºä»»åŠ¡ä¸“å®¶çš„å®Œæ•´æµç¨‹ã€‚

## 3.1 æŒ‡ä»¤å¾®è°ƒçš„è®¾è®¡åŸåˆ™

æŒ‡ä»¤å¾®è°ƒçš„æ ¸å¿ƒåœ¨äºæ•™ä¼šæ¨¡å‹ç†è§£å’Œéµå¾ªäººç±»æŒ‡ä»¤ã€‚å¯¹äº VLMï¼Œè¿™æ„å‘³ç€æ¨¡å‹ä¸ä»…è¦ç†è§£æ–‡æœ¬æŒ‡ä»¤ï¼Œè¿˜è¦å°†å…¶ä¸è§†è§‰è¾“å…¥å…³è”èµ·æ¥ã€‚è®¾è®¡è‰¯å¥½çš„æŒ‡ä»¤æ ¼å¼æ˜¯æˆåŠŸå¾®è°ƒçš„ç¬¬ä¸€æ­¥ã€‚

### 3.1.1 æŒ‡ä»¤æ¨¡æ¿è®¾è®¡

VLM çš„æŒ‡ä»¤æ¨¡æ¿éœ€è¦æ˜ç¡®æ ‡è¯†å›¾åƒä½ç½®ã€ç”¨æˆ·æŒ‡ä»¤å’Œæ¨¡å‹å“åº”çš„è¾¹ç•Œã€‚å¸¸è§çš„æ¨¡æ¿æ ¼å¼åŒ…æ‹¬ï¼š

**åŸºç¡€å•è½®å¯¹è¯æ¨¡æ¿ï¼š**
```
<image>
User: {instruction}
Assistant: {response}
```

**å¸¦ç³»ç»Ÿæç¤ºçš„æ¨¡æ¿ï¼š**
```
System: {system_prompt}
<image>
User: {instruction}
Assistant: {response}
```

**å¤šå›¾åƒäº¤ç»‡æ¨¡æ¿ï¼š**
```
User: æ¯”è¾ƒè¿™ä¸¤å¼ å›¾ç‰‡ <image1> å’Œ <image2>ï¼Œ{instruction}
Assistant: {response}
```

å…³é”®è®¾è®¡åŸåˆ™ï¼š
1. **ä½ç½®æ ‡è®°æ˜ç¡®**ï¼šä½¿ç”¨ç‰¹æ®Š tokenï¼ˆå¦‚ `<image>`ã€`<|im_start|>`ï¼‰æ ‡è®°å›¾åƒåµŒå…¥ä½ç½®
2. **è§’è‰²åŒºåˆ†æ¸…æ™°**ï¼šæ˜ç¡®åŒºåˆ† systemã€userã€assistant è§’è‰²
3. **è¾¹ç•Œç¬¦å·ä¸€è‡´**ï¼šä½¿ç”¨ç»Ÿä¸€çš„å¼€å§‹/ç»“æŸæ ‡è®°ï¼ˆå¦‚ `<|im_end|>`ï¼‰

**Token åŒ–ç¤ºä¾‹ï¼š**
```
è¾“å…¥æ–‡æœ¬: "<image>\nUser: æè¿°è¿™å¼ å›¾ç‰‡\nAssistant: "
Token IDs: [32000, 13, 2659, 29901, 29871, 31904, 30810, 30775, 30998, 13, 7900, 22137, 29901, 29871]
            â†‘å›¾åƒå ä½  â†‘æ¢è¡Œ  â†‘User:        â†‘æè¿°è¿™å¼ å›¾ç‰‡      â†‘æ¢è¡Œ â†‘Assistant:
```

### 3.1.2 ç³»ç»Ÿæç¤ºè¯çš„ä½œç”¨

ç³»ç»Ÿæç¤ºè¯ï¼ˆSystem Promptï¼‰å®šä¹‰æ¨¡å‹çš„è§’è‰²å’Œè¡Œä¸ºå‡†åˆ™ï¼Œå¯¹ VLM çš„è¡¨ç°æœ‰æ˜¾è‘—å½±å“ï¼š

**é€šç”¨è§†è§‰åŠ©æ‰‹æç¤ºï¼š**
```
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†è§‰è¯­è¨€åŠ©æ‰‹ã€‚è¯·å‡†ç¡®æè¿°å›¾åƒå†…å®¹ï¼Œå›ç­”ç”¨æˆ·å…³äºå›¾åƒçš„é—®é¢˜ã€‚
å¦‚æœå›¾åƒä¸­åŒ…å«æ–‡å­—ï¼Œè¯·å‡†ç¡®è¯†åˆ«å¹¶è½¬å½•ã€‚é¿å…çŒœæµ‹æˆ–ç¼–é€ ä¸å­˜åœ¨çš„å†…å®¹ã€‚
```

**ä»»åŠ¡ç‰¹å®šæç¤ºï¼ˆOCRåœºæ™¯ï¼‰ï¼š**
```
ä½ æ˜¯ä¸€ä¸ªOCRä¸“å®¶ã€‚è¯·ï¼š
1. è¯†åˆ«å›¾åƒä¸­çš„æ‰€æœ‰æ–‡å­—
2. ä¿æŒåŸå§‹æ ¼å¼å’Œå¸ƒå±€
3. æ ‡æ³¨ä¸ç¡®å®šçš„å­—ç¬¦ä¸º[?]
4. å¿½ç•¥è£…é¥°æ€§å…ƒç´ ï¼Œä¸“æ³¨æ–‡å­—å†…å®¹
```

ç³»ç»Ÿæç¤ºçš„ä¼˜åŒ–æŠ€å·§ï¼š
- **é•¿åº¦æ§åˆ¶**ï¼šè¿‡é•¿çš„ç³»ç»Ÿæç¤ºä¼šå ç”¨ä¸Šä¸‹æ–‡çª—å£ï¼Œå»ºè®®æ§åˆ¶åœ¨ 100-200 token
- **ä»»åŠ¡èšç„¦**ï¼šé’ˆå¯¹ç‰¹å®šä»»åŠ¡å®šåˆ¶æç¤ºï¼Œé¿å…è¿‡äºå®½æ³›
- **ç¤ºä¾‹å¼•å¯¼**ï¼šåœ¨æç¤ºä¸­åŒ…å«æœŸæœ›è¾“å‡ºæ ¼å¼çš„ç¤ºä¾‹

### 3.1.3 å¤šè½®å¯¹è¯çš„å¤„ç†

VLM çš„å¤šè½®å¯¹è¯éœ€è¦å¤„ç†å†å²ä¸Šä¸‹æ–‡å’Œæ–°å›¾åƒè¾“å…¥çš„å…³ç³»ï¼š

**ç­–ç•¥1ï¼šå›¾åƒæŒä¹…åŒ–**
```python
# ç¬¬ä¸€è½®
messages = [
    {"role": "user", "content": "<image> è¿™æ˜¯ä»€ä¹ˆåŠ¨ç‰©ï¼Ÿ"},
    {"role": "assistant", "content": "è¿™æ˜¯ä¸€åªæ©™è‰²çš„çŒ«ã€‚"}
]
# ç¬¬äºŒè½®ï¼ˆå¼•ç”¨åŒä¸€å›¾åƒï¼‰
messages.append({"role": "user", "content": "å®ƒåœ¨åšä»€ä¹ˆï¼Ÿ"})
# æ¨¡å‹éœ€è¦è®°ä½ä¹‹å‰çš„å›¾åƒä¸Šä¸‹æ–‡
```

**ç­–ç•¥2ï¼šæ˜¾å¼å›¾åƒå¼•ç”¨**
```python
# ä½¿ç”¨å›¾åƒIDç³»ç»Ÿ
messages = [
    {"role": "user", "content": "<image id='img1'> æè¿°ç¬¬ä¸€å¼ å›¾"},
    {"role": "assistant", "content": "ç¬¬ä¸€å¼ å›¾æ˜¾ç¤º..."},
    {"role": "user", "content": "<image id='img2'> æ¯”è¾ƒimg1å’Œimg2çš„å·®å¼‚"},
]
```

**ä¸Šä¸‹æ–‡çª—å£ç®¡ç†ï¼š**
```
æœ€å¤§ä¸Šä¸‹æ–‡ = 4096 tokens
â”œâ”€â”€ ç³»ç»Ÿæç¤º: ~100 tokens
â”œâ”€â”€ å›¾åƒåµŒå…¥: 576 tokens Ã— Nå¼ å›¾
â”œâ”€â”€ å†å²å¯¹è¯: å¯å˜é•¿åº¦
â””â”€â”€ å½“å‰å›å¤: é¢„ç•™ 500-1000 tokens
```

### 3.1.4 è§†è§‰-è¯­è¨€æŒ‡ä»¤çš„å¯¹é½

ç¡®ä¿è§†è§‰ç†è§£ä¸è¯­è¨€ç”Ÿæˆçš„ä¸€è‡´æ€§æ˜¯ VLM SFT çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼š

**å¯¹é½å±‚æ¬¡ï¼š**
1. **å¯¹è±¡çº§å¯¹é½**ï¼šç‰©ä½“è¯†åˆ«ä¸å‘½åä¸€è‡´
2. **å±æ€§çº§å¯¹é½**ï¼šé¢œè‰²ã€å¤§å°ã€çº¹ç†æè¿°å‡†ç¡®
3. **å…³ç³»çº§å¯¹é½**ï¼šç©ºé—´å…³ç³»ã€åŠ¨ä½œå…³ç³»æ­£ç¡®
4. **åœºæ™¯çº§å¯¹é½**ï¼šæ•´ä½“ç†è§£ä¸æè¿°è¿è´¯

**å¯¹é½æŠ€æœ¯ï¼š**

```
è§†è§‰ç‰¹å¾å¯¹é½çŸ©é˜µ:
       ç‰©ä½“  å±æ€§  å…³ç³»  åœºæ™¯
       ________________
è§†è§‰  | 1.0  0.8  0.6  0.7 |  <- è§†è§‰ç¼–ç å™¨è¾“å‡º
è¯­è¨€  | 0.9  0.9  0.7  0.8 |  <- è¯­è¨€æ¨¡å‹ç†è§£
       â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾
å¯¹è§’çº¿å€¼è¶Šæ¥è¿‘1.0ï¼Œå¯¹é½è¶Šå¥½
```

**ç»†ç²’åº¦å¯¹é½ç¤ºä¾‹ï¼š**
```python
# Grounding æ ‡æ³¨æ ¼å¼
instruction = "æ‰¾å‡º<click>çº¢è‰²çš„çƒ</click>åœ¨å“ªé‡Œ"
response = "çº¢è‰²çš„çƒä½äº<box>[[125, 235, 200, 310]]</box>å›¾åƒçš„å·¦ä¸‹è§’ã€‚"

# Referring æ ‡æ³¨æ ¼å¼  
instruction = "æè¿°ä½äº<region>[[x1,y1,x2,y2]]</region>çš„ç‰©ä½“"
response = "è¿™æ˜¯ä¸€ä¸ªçº¢è‰²çš„ç¯®çƒï¼Œè¡¨é¢æœ‰é»‘è‰²çš„çº¿æ¡çº¹ç†ã€‚"
```

## 3.2 æŸå¤±å‡½æ•°è®¾è®¡ä¸æƒé‡ç­–ç•¥

æŸå¤±å‡½æ•°è®¾è®¡ç›´æ¥å½±å“æ¨¡å‹çš„å­¦ä¹ ç›®æ ‡å’Œæ”¶æ•›è¡Œä¸ºã€‚VLM çš„ SFT éœ€è¦ç²¾å¿ƒè®¾è®¡æŸå¤±å‡½æ•°æ¥å¹³è¡¡ä¸åŒç±»å‹çš„é¢„æµ‹ä»»åŠ¡ã€‚

### 3.2.1 è‡ªå›å½’è¯­è¨€æ¨¡å‹æŸå¤±

VLM çš„æ ¸å¿ƒæŸå¤±æ˜¯è‡ªå›å½’è¯­è¨€å»ºæ¨¡æŸå¤±ï¼Œå³é¢„æµ‹ä¸‹ä¸€ä¸ª token çš„äº¤å‰ç†µæŸå¤±ï¼š

$$\mathcal{L}_{LM} = -\sum_{t=1}^{T} \log P(x_t | x_{<t}, I)$$

å…¶ä¸­ $x_t$ æ˜¯ç¬¬ $t$ ä¸ª tokenï¼Œ$I$ æ˜¯è¾“å…¥å›¾åƒï¼Œ$x_{<t}$ æ˜¯ä¹‹å‰çš„æ‰€æœ‰ tokenã€‚

**å®ç°ç»†èŠ‚ï¼š**
```python
def compute_lm_loss(logits, labels, vocab_size=32000):
    """
    logits: [batch_size, seq_len, vocab_size]
    labels: [batch_size, seq_len]
    """
    # Shiftï¼šé¢„æµ‹ä½ç½®å’Œæ ‡ç­¾é”™ä½
    shift_logits = logits[..., :-1, :].contiguous()
    shift_labels = labels[..., 1:].contiguous()
    
    # Flatten ä¾¿äºè®¡ç®—
    shift_logits = shift_logits.view(-1, vocab_size)
    shift_labels = shift_labels.view(-1)
    
    # äº¤å‰ç†µæŸå¤±
    loss = F.cross_entropy(
        shift_logits, 
        shift_labels, 
        ignore_index=-100,  # å¿½ç•¥ padding
        reduction='mean'
    )
    return loss
```

**æ³¨æ„åŠ›æ©ç çš„å½±å“ï¼š**
```
åºåˆ—: [IMG] User: æè¿°å›¾ç‰‡ Assistant: è¿™æ˜¯ä¸€åªçŒ« [EOS]
æ©ç :  0    0     0        1          1          1

åªåœ¨ Assistant å“åº”éƒ¨åˆ†è®¡ç®—æŸå¤±
```

### 3.2.2 æ©ç ç­–ç•¥ä¸æƒé‡åˆ†é…

ä¸åŒéƒ¨åˆ†çš„ token å¯¹å­¦ä¹ çš„é‡è¦æ€§ä¸åŒï¼Œé€šè¿‡æ©ç å’Œæƒé‡è°ƒæ•´å¯ä»¥ä¼˜åŒ–è®­ç»ƒæ•ˆæœï¼š

**1. å“åº”æ©ç ï¼ˆResponse Maskingï¼‰ï¼š**
```python
def create_response_mask(input_ids, response_start_token_id):
    """åªåœ¨æ¨¡å‹å“åº”éƒ¨åˆ†è®¡ç®—æŸå¤±"""
    batch_size, seq_len = input_ids.shape
    mask = torch.zeros_like(input_ids, dtype=torch.bool)
    
    for i in range(batch_size):
        # æ‰¾åˆ°å“åº”å¼€å§‹ä½ç½®
        response_start = (input_ids[i] == response_start_token_id).nonzero()
        if len(response_start) > 0:
            start_idx = response_start[0].item()
            mask[i, start_idx:] = True
    
    return mask
```

**2. Token çº§åˆ«æƒé‡ï¼š**
```python
# ä¸åŒç±»å‹ token çš„æƒé‡
token_weights = {
    "special_tokens": 0.0,    # <image>, <pad> ç­‰
    "instruction": 0.0,        # ç”¨æˆ·æŒ‡ä»¤éƒ¨åˆ†
    "response": 1.0,          # åŠ©æ‰‹å“åº”
    "grounding_box": 2.0,     # åæ ‡é¢„æµ‹
    "key_entities": 1.5       # å…³é”®å®ä½“åè¯
}
```

**3. åŠ¨æ€æƒé‡è°ƒæ•´ï¼š**
```
æ—©æœŸè®­ç»ƒï¼ˆepoch 1-3ï¼‰ï¼š
- æ‰€æœ‰ token æƒé‡ = 1.0
- è®©æ¨¡å‹å­¦ä¹ åŸºç¡€çš„è¯­è¨€æ¨¡å¼

ä¸­æœŸè®­ç»ƒï¼ˆepoch 4-8ï¼‰ï¼š
- æŒ‡ä»¤éƒ¨åˆ†æƒé‡ = 0.5
- å“åº”éƒ¨åˆ†æƒé‡ = 1.0
- å¼ºåŒ–æŒ‡ä»¤éµå¾ªèƒ½åŠ›

åæœŸè®­ç»ƒï¼ˆepoch 9-10ï¼‰ï¼š
- åªè®¡ç®—å“åº”æŸå¤±
- ç²¾ç»†è°ƒæ•´ç”Ÿæˆè´¨é‡
```

### 3.2.3 å¤šä»»åŠ¡å­¦ä¹ çš„æŸå¤±å¹³è¡¡

VLM é€šå¸¸éœ€è¦åŒæ—¶å¤„ç†å¤šä¸ªä»»åŠ¡ï¼Œå¦‚å›¾åƒæè¿°ã€VQAã€OCR ç­‰ã€‚å¤šä»»åŠ¡æŸå¤±å¹³è¡¡æ˜¯å…³é”®ï¼š

**æŸå¤±ç»„åˆç­–ç•¥ï¼š**
$$\mathcal{L}_{total} = \sum_{i=1}^{N} w_i \mathcal{L}_i$$

**è‡ªé€‚åº”æƒé‡æ–¹æ³•ï¼š**

1. **ä¸ç¡®å®šæ€§åŠ æƒï¼ˆUncertainty Weightingï¼‰ï¼š**
$$\mathcal{L}_{total} = \sum_{i=1}^{N} \frac{1}{2\sigma_i^2} \mathcal{L}_i + \log \sigma_i$$

å…¶ä¸­ $\sigma_i$ æ˜¯å¯å­¦ä¹ çš„ä»»åŠ¡ä¸ç¡®å®šæ€§å‚æ•°ã€‚

2. **æ¢¯åº¦å½’ä¸€åŒ–ï¼ˆGradNormï¼‰ï¼š**
```python
def gradnorm_weights(losses, shared_params, alpha=1.5):
    """æ ¹æ®æ¢¯åº¦å¤§å°åŠ¨æ€è°ƒæ•´ä»»åŠ¡æƒé‡"""
    # è®¡ç®—æ¯ä¸ªä»»åŠ¡çš„æ¢¯åº¦èŒƒæ•°
    grad_norms = []
    for loss in losses:
        grads = torch.autograd.grad(loss, shared_params, retain_graph=True)
        grad_norm = torch.norm(torch.cat([g.flatten() for g in grads]))
        grad_norms.append(grad_norm)
    
    # è®¡ç®—å¹³å‡æ¢¯åº¦èŒƒæ•°
    mean_norm = torch.stack(grad_norms).mean()
    
    # è°ƒæ•´æƒé‡
    weights = []
    for i, norm in enumerate(grad_norms):
        relative_norm = norm / mean_norm
        weight = relative_norm ** alpha
        weights.append(weight)
    
    return F.softmax(torch.stack(weights), dim=0)
```

**ä»»åŠ¡é‡‡æ ·ç­–ç•¥ï¼š**
```
æ‰¹æ¬¡æ„å»ºç­–ç•¥:
â”œâ”€â”€ å‡åŒ€é‡‡æ ·: æ¯ä¸ª batch åŒ…å«æ‰€æœ‰ä»»åŠ¡
â”œâ”€â”€ ä»»åŠ¡åˆ†ç»„: ç›¸ä¼¼ä»»åŠ¡æ”¾åœ¨åŒä¸€ batch
â””â”€â”€ æ¸©åº¦é‡‡æ ·: P(task_i) âˆ (1/loss_i)^T
    
æ¸©åº¦ T æ§åˆ¶é‡‡æ ·åˆ†å¸ƒ:
- T â†’ 0: åªé‡‡æ ·æŸå¤±æœ€å¤§çš„ä»»åŠ¡
- T = 1: æ ¹æ®æŸå¤±åæ¯”é‡‡æ ·  
- T â†’ âˆ: å‡åŒ€é‡‡æ ·æ‰€æœ‰ä»»åŠ¡
```

### 3.2.4 è§†è§‰ Grounding æŸå¤±è®¾è®¡

å¯¹äºéœ€è¦å®šä½çš„ä»»åŠ¡ï¼ˆå¦‚ç›®æ ‡æ£€æµ‹ã€referring segmentationï¼‰ï¼Œéœ€è¦ä¸“é—¨çš„æŸå¤±è®¾è®¡ï¼š

**1. è¾¹ç•Œæ¡†å›å½’æŸå¤±ï¼š**
```python
def box_loss(pred_boxes, gt_boxes):
    """
    pred_boxes: [batch, num_queries, 4]  # (x1, y1, x2, y2) å½’ä¸€åŒ–åæ ‡
    gt_boxes: [batch, num_targets, 4]
    """
    # L1 æŸå¤±
    l1_loss = F.l1_loss(pred_boxes, gt_boxes)
    
    # GIoU æŸå¤±
    giou_loss = 1 - compute_giou(pred_boxes, gt_boxes)
    
    return l1_loss + giou_loss
```

**2. åæ ‡ Token åŒ–ç­–ç•¥ï¼š**
```
æ–¹æ³•1ï¼šè¿ç»­åæ ‡ç¦»æ•£åŒ–
[0, 1] â†’ [0, 999] â†’ token_id âˆˆ [32000, 32999]

æ–¹æ³•2ï¼šåŒºåŸŸç¼–ç 
å›¾åƒåˆ†æˆ 32Ã—32 ç½‘æ ¼ â†’ æ¯ä¸ªç½‘æ ¼ä¸€ä¸ª token

æ–¹æ³•3ï¼šç‰¹æ®Šæ•°å­— token
<x>0.123</x> <y>0.456</y> â†’ è§£ææ—¶æå–
```

**3. Referring æŸå¤±è®¾è®¡ï¼š**
```python
def referring_loss(pred_mask, gt_mask, pred_box, gt_box):
    """ç»„åˆåˆ†å‰²å’Œæ£€æµ‹æŸå¤±"""
    # åƒç´ çº§åˆ†å‰²æŸå¤±
    seg_loss = F.binary_cross_entropy_with_logits(pred_mask, gt_mask)
    
    # è¾¹ç•Œæ¡†æŸå¤±
    box_loss = compute_box_loss(pred_box, gt_box)
    
    # ä¸€è‡´æ€§æŸå¤±ï¼šç¡®ä¿ mask å’Œ box å¯¹åº”
    mask_from_box = box_to_mask(pred_box)
    consistency_loss = F.mse_loss(pred_mask, mask_from_box)
    
    return seg_loss + 0.5 * box_loss + 0.1 * consistency_loss
```

**4. è´Ÿæ ·æœ¬å¤„ç†ï¼š**
```
Grounding ä»»åŠ¡çš„è´Ÿæ ·æœ¬ç­–ç•¥:
â”œâ”€â”€ Hard Negative: é€‰æ‹©æœ€å®¹æ˜“æ··æ·†çš„ç‰©ä½“
â”œâ”€â”€ Random Negative: éšæœºé€‰æ‹©å…¶ä»–ç‰©ä½“
â””â”€â”€ Background: é€‰æ‹©èƒŒæ™¯åŒºåŸŸ

è´Ÿæ ·æœ¬æ¯”ä¾‹å»ºè®®:
- æ­£è´Ÿæ¯” 1:3 for ç›®æ ‡æ£€æµ‹
- æ­£è´Ÿæ¯” 1:1 for referring expression
- åŠ¨æ€è°ƒæ•´based on éš¾åº¦
```

## 3.3 å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼ˆLoRAã€QLoRAã€Adapterï¼‰

å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æ–¹æ³•å…è®¸åœ¨æœ‰é™çš„è®¡ç®—èµ„æºä¸‹å¾®è°ƒå¤§è§„æ¨¡ VLMã€‚è¿™äº›æ–¹æ³•é€šè¿‡åªæ›´æ–°å°‘é‡å‚æ•°æ¥å®ç°ä¸å…¨é‡å¾®è°ƒç›¸è¿‘çš„æ•ˆæœã€‚

### 3.3.1 LoRA åŸç†ä¸å®ç°

LoRAï¼ˆLow-Rank Adaptationï¼‰é€šè¿‡ä½ç§©åˆ†è§£æ¥è¿‘ä¼¼æƒé‡æ›´æ–°ï¼š

**æ ¸å¿ƒåŸç†ï¼š**
$$W' = W + \Delta W = W + BA$$

å…¶ä¸­ $B \in \mathbb{R}^{d \times r}$ï¼Œ$A \in \mathbb{R}^{r \times k}$ï¼Œ$r \ll \min(d, k)$ã€‚

**VLM ä¸­çš„ LoRA é…ç½®ï¼š**
```python
class LoRAConfig:
    # è¯­è¨€æ¨¡å‹éƒ¨åˆ†
    lm_target_modules = [
        "q_proj", "v_proj",  # æ³¨æ„åŠ›å±‚
        "k_proj", "o_proj",
        "gate_proj", "up_proj", "down_proj"  # FFN å±‚
    ]
    
    # è§†è§‰ç¼–ç å™¨éƒ¨åˆ†ï¼ˆå¯é€‰ï¼‰
    vision_target_modules = [
        "qkv",  # ViT çš„ QKV æŠ•å½±
        "proj", # è¾“å‡ºæŠ•å½±
        "mlp.fc1", "mlp.fc2"  # MLP å±‚
    ]
    
    # å…³é”®è¶…å‚æ•°
    r = 16  # rankï¼Œå¸¸ç”¨ 8/16/32/64
    alpha = 16  # ç¼©æ”¾å› å­ï¼Œé€šå¸¸ = r
    dropout = 0.1
```

**åŠ¨æ€ Rank é€‰æ‹©ï¼š**
```
ä¸åŒæ¨¡å—çš„é‡è¦æ€§åˆ†æ:
æ¨¡å—ç±»å‹        å»ºè®® rank   å‚æ•°å æ¯”
-----------------------------------------
Q, K æŠ•å½±       8-16       ~15%
V, O æŠ•å½±       16-32      ~20%  
FFN ä¸ŠæŠ•å½±      32-64      ~35%
FFN ä¸‹æŠ•å½±      16-32      ~25%
Cross-Attn     32-64      ~5% (å¦‚æœæœ‰)
```

**å®ç°ç»†èŠ‚ï¼š**
```python
class LoRALayer(nn.Module):
    def __init__(self, in_features, out_features, rank=16, alpha=16):
        super().__init__()
        self.scaling = alpha / rank
        
        # ä½ç§©çŸ©é˜µ
        self.lora_A = nn.Parameter(torch.randn(rank, in_features))
        self.lora_B = nn.Parameter(torch.zeros(out_features, rank))
        
        # åˆå§‹åŒ–
        nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))
        
    def forward(self, x, base_output):
        # base_output æ˜¯åŸå§‹å±‚çš„è¾“å‡º
        lora_output = (x @ self.lora_A.T @ self.lora_B.T) * self.scaling
        return base_output + lora_output
```

### 3.3.2 QLoRA çš„é‡åŒ–ç­–ç•¥

QLoRA ç»“åˆ 4-bit é‡åŒ–å’Œ LoRAï¼Œå¤§å¹…é™ä½æ˜¾å­˜å ç”¨ï¼š

**é‡åŒ–æµç¨‹ï¼š**
```
åŸå§‹æ¨¡å‹ (16-bit) â†’ NF4 é‡åŒ– (4-bit) + LoRA é€‚é…å™¨ (16-bit)
æ˜¾å­˜èŠ‚çœ: ~75% (ç›¸æ¯”å…¨ç²¾åº¦)
```

**NF4ï¼ˆNormalFloat4ï¼‰é‡åŒ–ï¼š**
```python
def quantize_nf4(tensor):
    """4-bit NormalFloat é‡åŒ–"""
    # 1. å½’ä¸€åŒ–åˆ° [-1, 1]
    absmax = tensor.abs().max()
    tensor_normalized = tensor / absmax
    
    # 2. é‡åŒ–åˆ° 16 ä¸ªçº§åˆ«
    quantization_levels = [
        -1.0, -0.6961, -0.5250, -0.3949, 
        -0.2844, -0.1848, -0.0911, 0.0,
        0.0796, 0.1609, 0.2461, 0.3379,
        0.4407, 0.5626, 0.7230, 1.0
    ]
    
    # 3. æ‰¾æœ€è¿‘çš„é‡åŒ–çº§åˆ«
    quantized = quantize_to_nearest(tensor_normalized, quantization_levels)
    
    return quantized, absmax  # ä¿å­˜ scale ç”¨äºåé‡åŒ–
```

**åŒé‡é‡åŒ–ï¼ˆDouble Quantizationï¼‰ï¼š**
```
ç¬¬ä¸€æ¬¡é‡åŒ–: æ¨¡å‹æƒé‡ â†’ 4-bit
ç¬¬äºŒæ¬¡é‡åŒ–: é‡åŒ–å¸¸æ•° â†’ 8-bit
é¢å¤–èŠ‚çœ: ~0.37 bit/å‚æ•°
```

**QLoRA è®­ç»ƒé…ç½®ï¼š**
```python
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_use_double_quant=True,
)

# Paged Optimizer èŠ‚çœä¼˜åŒ–å™¨å†…å­˜
optimizer = PagedAdamW32bit(
    model.parameters(),
    lr=2e-4,
    weight_decay=0.01,
    optim_bits=32  # ä¼˜åŒ–å™¨çŠ¶æ€ä¿æŒ 32-bit
)
```

### 3.3.3 Adapter å±‚çš„è®¾è®¡é€‰æ‹©

Adapter é€šè¿‡æ’å…¥å°å‹ç½‘ç»œæ¨¡å—æ¥å®ç°å‚æ•°é«˜æ•ˆå¾®è°ƒï¼š

**æ ‡å‡† Adapter æ¶æ„ï¼š**
```
è¾“å…¥ â†’ LayerNorm â†’ Down-projection â†’ æ¿€æ´» â†’ Up-projection â†’ æ®‹å·®è¿æ¥
  â†“                                                               â†‘
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**VLM ä¸­çš„ Adapter å˜ä½“ï¼š**

1. **Sequential Adapterï¼š**
```python
class SequentialAdapter(nn.Module):
    def __init__(self, dim, reduction_factor=16):
        super().__init__()
        hidden_dim = dim // reduction_factor
        self.down_proj = nn.Linear(dim, hidden_dim)
        self.activation = nn.GELU()
        self.up_proj = nn.Linear(hidden_dim, dim)
        
    def forward(self, x):
        residual = x
        x = self.down_proj(x)
        x = self.activation(x)
        x = self.up_proj(x)
        return x + residual
```

2. **Parallel Adapterï¼š**
```python
class ParallelAdapter(nn.Module):
    """å¹¶è¡Œå¤„ç†ï¼Œå‡å°‘å»¶è¿Ÿ"""
    def forward(self, x, original_output):
        adapter_output = self.adapter(x)
        return original_output + self.scale * adapter_output
```

3. **Cross-Modal Adapterï¼š**
```python
class CrossModalAdapter(nn.Module):
    """ä¸“é—¨å¤„ç†è§†è§‰-è¯­è¨€äº¤äº’"""
    def __init__(self, vision_dim, text_dim, hidden_dim):
        super().__init__()
        self.vision_proj = nn.Linear(vision_dim, hidden_dim)
        self.text_proj = nn.Linear(text_dim, hidden_dim)
        self.fusion = nn.MultiheadAttention(hidden_dim, num_heads=8)
        
    def forward(self, vision_features, text_features):
        v = self.vision_proj(vision_features)
        t = self.text_proj(text_features)
        fused, _ = self.fusion(t, v, v)  # text ä½œ query
        return fused
```

### 3.3.4 PEFT æ–¹æ³•å¯¹æ¯”ä¸é€‰æ‹©

**æ€§èƒ½å¯¹æ¯”è¡¨ï¼š**
```
æ–¹æ³•        å‚æ•°é‡   æ˜¾å­˜å ç”¨  è®­ç»ƒé€Ÿåº¦  æ•ˆæœ(ç›¸å¯¹å…¨é‡)
---------------------------------------------------------
å…¨é‡å¾®è°ƒ     100%     100%      1.0x      100%
LoRA        0.1-1%   ~60%      1.5x      95-98%
QLoRA       0.1-1%   ~25%      1.2x      92-96%
Adapter     1-5%     ~70%      1.3x      93-97%
Prefix      <0.1%    ~50%      1.8x      85-92%
IA3         <0.01%   ~55%      1.6x      88-94%
```

**é€‰æ‹©å†³ç­–æ ‘ï¼š**
```
æ˜¾å­˜é™åˆ¶ä¸¥æ ¼ï¼Ÿ
â”œâ”€ æ˜¯ â†’ QLoRAï¼ˆ4-bité‡åŒ– + LoRAï¼‰
â””â”€ å¦ â†’ éœ€è¦æœ€ä½³æ€§èƒ½ï¼Ÿ
        â”œâ”€ æ˜¯ â†’ å…¨é‡å¾®è°ƒ or LoRA (r=64)
        â””â”€ å¦ â†’ æ¨ç†é€Ÿåº¦ä¼˜å…ˆï¼Ÿ
                â”œâ”€ æ˜¯ â†’ LoRA (å¯åˆå¹¶æƒé‡)
                â””â”€ å¦ â†’ Adapter (çµæ´»æ€§é«˜)
```

**ç»„åˆç­–ç•¥ï¼š**
```python
# æ··åˆ PEFTï¼šä¸åŒå±‚ä½¿ç”¨ä¸åŒæ–¹æ³•
config = {
    "vision_encoder": "frozen",  # å†»ç»“
    "projection": "full",        # å…¨é‡å¾®è°ƒ
    "llm_layers_0_16": "lora",  # åº•å±‚ç”¨ LoRA
    "llm_layers_16_32": "adapter",  # é«˜å±‚ç”¨ Adapter
}
```

**å®è·µå»ºè®®ï¼š**
1. **åˆå§‹å®éªŒ**ï¼šä» LoRA r=8 å¼€å§‹ï¼Œé€æ­¥å¢åŠ 
2. **è§†è§‰ç¼–ç å™¨**ï¼šé€šå¸¸å†»ç»“æˆ–ç”¨å¾ˆå°çš„ rankï¼ˆr=4ï¼‰
3. **æŠ•å½±å±‚**ï¼šå»ºè®®å…¨é‡å¾®è°ƒï¼Œå‚æ•°é‡å°ä½†é‡è¦
4. **ä»»åŠ¡é€‚é…**ï¼šç®€å•ä»»åŠ¡ç”¨ LoRAï¼Œå¤æ‚ä»»åŠ¡è€ƒè™‘ Adapter

## 3.4 è®­ç»ƒç¨³å®šæ€§ä¸æ”¶æ•›æŠ€å·§

è®­ç»ƒå¤§è§„æ¨¡ VLM æ—¶ç»å¸¸é‡åˆ°ä¸ç¨³å®šé—®é¢˜ï¼šæŸå¤±çªç„¶çˆ†ç‚¸ã€æ¢¯åº¦æ¶ˆå¤±ã€æ”¶æ•›ç¼“æ…¢ç­‰ã€‚æœ¬èŠ‚ä»‹ç»å®ç”¨çš„ç¨³å®šæ€§æŠ€å·§ã€‚

### 3.4.1 å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥

**VLM å¸¸ç”¨è°ƒåº¦å™¨ï¼š**

1. **Cosine with Warmupï¼š**
```python
def cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):
    def lr_lambda(current_step):
        if current_step < num_warmup_steps:
            # çº¿æ€§ warmup
            return float(current_step) / float(max(1, num_warmup_steps))
        # Cosine è¡°å‡
        progress = float(current_step - num_warmup_steps) / \
                  float(max(1, num_training_steps - num_warmup_steps))
        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))
    
    return LambdaLR(optimizer, lr_lambda)
```

2. **åˆ†é˜¶æ®µå­¦ä¹ ç‡ï¼š**
```
é˜¶æ®µ1ï¼ˆé¢„çƒ­ï¼‰: lr = 1e-6 â†’ 2e-4 (çº¿æ€§å¢é•¿)
é˜¶æ®µ2ï¼ˆä¸»è®­ç»ƒï¼‰: lr = 2e-4 (æ’å®šæˆ–ç¼“æ…¢è¡°å‡)
é˜¶æ®µ3ï¼ˆç²¾è°ƒï¼‰: lr = 2e-4 â†’ 1e-5 (cosineè¡°å‡)
```

**è§†è§‰ç¼–ç å™¨ç‰¹æ®Šå¤„ç†ï¼š**
```python
# ä¸åŒç»„ä»¶ä¸åŒå­¦ä¹ ç‡
param_groups = [
    {"params": vision_encoder.parameters(), "lr": 1e-5},  # æ›´å°
    {"params": projection.parameters(), "lr": 5e-4},      # æ›´å¤§
    {"params": language_model.parameters(), "lr": 2e-4},  # æ ‡å‡†
]
```

### 3.4.2 æ¢¯åº¦è£å‰ªä¸å½’ä¸€åŒ–

**æ¢¯åº¦è£å‰ªç­–ç•¥ï¼š**
```python
# 1. å…¨å±€æ¢¯åº¦è£å‰ªï¼ˆæ¨èï¼‰
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

# 2. åˆ†å±‚æ¢¯åº¦è£å‰ª
for name, param in model.named_parameters():
    if "vision" in name:
        torch.nn.utils.clip_grad_norm_([param], max_norm=0.5)
    else:
        torch.nn.utils.clip_grad_norm_([param], max_norm=1.0)
```

**æ¢¯åº¦ç›‘æ§ï¼š**
```python
def monitor_gradients(model):
    """ç›‘æ§æ¢¯åº¦ç»Ÿè®¡ä¿¡æ¯"""
    grad_stats = {}
    for name, param in model.named_parameters():
        if param.grad is not None:
            grad_stats[name] = {
                "mean": param.grad.mean().item(),
                "std": param.grad.std().item(),
                "max": param.grad.abs().max().item(),
            }
    return grad_stats

# å¼‚å¸¸æ£€æµ‹
if any(stat["max"] > 100 for stat in grad_stats.values()):
    logger.warning("æ¢¯åº¦çˆ†ç‚¸é£é™©ï¼")
```

### 3.4.3 æƒé‡åˆå§‹åŒ–æŠ€å·§

**å…³é”®ç»„ä»¶åˆå§‹åŒ–ï¼š**
```python
def init_vlm_weights(model):
    # 1. æŠ•å½±å±‚ï¼šXavier åˆå§‹åŒ–
    if hasattr(model, 'visual_projection'):
        nn.init.xavier_uniform_(model.visual_projection.weight)
        nn.init.zeros_(model.visual_projection.bias)
    
    # 2. LoRA å±‚ï¼šæ¥è¿‘é›¶åˆå§‹åŒ–
    for name, param in model.named_parameters():
        if "lora_B" in name:
            nn.init.zeros_(param)  # B çŸ©é˜µåˆå§‹åŒ–ä¸º0
        elif "lora_A" in name:
            nn.init.kaiming_uniform_(param, a=math.sqrt(5))
    
    # 3. Layer Scaleï¼šå°å€¼åˆå§‹åŒ–
    if hasattr(model, 'layer_scale'):
        nn.init.constant_(model.layer_scale, 1e-4)
```

**ç¨³å®šæ€§æŠ€å·§ï¼š**
```
åˆå§‹åŒ–æ£€æŸ¥æ¸…å•ï¼š
â–¡ æŠ•å½±å±‚ä¸èƒ½å¤ªå¤§ï¼ˆstd < 0.02ï¼‰
â–¡ LoRA B çŸ©é˜µåˆå§‹ä¸º 0
â–¡ Layer Norm æƒé‡ = 1, åç½® = 0
â–¡ æ–°å¢ token embedding ç”¨å·²æœ‰ token å¹³å‡å€¼
```

### 3.4.4 æ—©åœä¸ Checkpoint ç­–ç•¥

**æ™ºèƒ½ Checkpointï¼š**
```python
class SmartCheckpointer:
    def __init__(self, patience=3, delta=0.001):
        self.patience = patience
        self.delta = delta
        self.best_score = None
        self.counter = 0
        
    def should_save(self, val_loss):
        if self.best_score is None:
            self.best_score = val_loss
            return True
        
        if val_loss < self.best_score - self.delta:
            self.best_score = val_loss
            self.counter = 0
            return True
        else:
            self.counter += 1
            return False
    
    def should_stop(self):
        return self.counter >= self.patience
```

**Checkpoint ç®¡ç†ï¼š**
```python
checkpoint = {
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'scheduler_state_dict': scheduler.state_dict(),
    'best_val_loss': best_val_loss,
    'training_history': {
        'train_losses': train_losses,
        'val_losses': val_losses,
        'learning_rates': lrs,
    }
}

# ä¿å­˜ç­–ç•¥
save_strategies = {
    "best": "checkpoint_best.pt",        # æœ€ä½³éªŒè¯æ€§èƒ½
    "latest": "checkpoint_latest.pt",    # æœ€æ–°çŠ¶æ€
    "periodic": f"checkpoint_epoch_{epoch}.pt",  # å®šæœŸä¿å­˜
}
```

## Case Study: Qwen-VL çš„ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥å®æˆ˜

Qwen-VL é‡‡ç”¨æ¸è¿›å¼ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œä»å¤§è§„æ¨¡é¢„è®­ç»ƒåˆ°ç²¾ç»†æŒ‡ä»¤å¾®è°ƒï¼Œå®ç°äº†ä¼˜ç§€çš„å¤šæ¨¡æ€æ€§èƒ½ã€‚

### é˜¶æ®µä¸€ï¼šè§†è§‰-è¯­è¨€é¢„è®­ç»ƒ

**ç›®æ ‡**ï¼šå»ºç«‹åŸºç¡€çš„è§†è§‰-è¯­è¨€å¯¹é½èƒ½åŠ›

**æ•°æ®é…ç½®ï¼š**
```
æ€»é‡ï¼š1.4B å›¾æ–‡å¯¹
â”œâ”€â”€ LAION-400M: 40%ï¼ˆç½‘ç»œçˆ¬å–ï¼‰
â”œâ”€â”€ COYO-700M: 30%ï¼ˆéŸ©è¯­+è‹±è¯­ï¼‰
â”œâ”€â”€ CC12M: 15%ï¼ˆæ¦‚å¿µæè¿°ï¼‰
â””â”€â”€ å†…éƒ¨æ•°æ®: 15%ï¼ˆé«˜è´¨é‡ç­›é€‰ï¼‰
```

**è®­ç»ƒé…ç½®ï¼š**
```python
stage1_config = {
    "vision_encoder": "frozen",  # OpenCLIP ViT-G/14
    "projection": "trainable",   # æ–°å¢çš„ Resampler
    "language_model": "trainable",  # Qwen-7B
    "batch_size": 2048,
    "learning_rate": 1e-4,
    "warmup_steps": 2000,
    "total_steps": 50000,
}
```

### é˜¶æ®µäºŒï¼šå¤šä»»åŠ¡é¢„è®­ç»ƒ

**ç›®æ ‡**ï¼šå­¦ä¹ å¤šæ ·åŒ–çš„è§†è§‰ä»»åŠ¡èƒ½åŠ›

**ä»»åŠ¡åˆ†å¸ƒï¼š**
```
ä»»åŠ¡ç±»å‹         æ•°æ®é‡    æŸå¤±æƒé‡
--------------------------------------
å›¾åƒæè¿°         50M      0.3
VQA             30M      0.2
OCR             20M      0.2
Grounding       15M      0.15
Referring       10M      0.15
```

**å…³é”®æŠ€æœ¯ï¼š**
```python
# åŠ¨æ€åˆ†è¾¨ç‡å¤„ç†
def dynamic_resolution(image, min_pixels=224*224, max_pixels=1024*1024):
    """ä¿æŒå®½é«˜æ¯”çš„åŠ¨æ€åˆ†è¾¨ç‡"""
    h, w = image.shape[:2]
    current_pixels = h * w
    
    if current_pixels < min_pixels:
        scale = math.sqrt(min_pixels / current_pixels)
    elif current_pixels > max_pixels:
        scale = math.sqrt(max_pixels / current_pixels)
    else:
        scale = 1.0
    
    new_h, new_w = int(h * scale), int(w * scale)
    # ç¡®ä¿æ˜¯ 14 çš„å€æ•°ï¼ˆViT patch sizeï¼‰
    new_h = (new_h // 14) * 14
    new_w = (new_w // 14) * 14
    
    return resize(image, (new_h, new_w))
```

### é˜¶æ®µä¸‰ï¼šæŒ‡ä»¤å¾®è°ƒ

**ç›®æ ‡**ï¼šä¼˜åŒ–æŒ‡ä»¤éµå¾ªå’Œå¯¹è¯èƒ½åŠ›

**æ•°æ®æ„æˆï¼š**
```python
sft_data = {
    "high_quality_vqa": 200k,  # äººå·¥æ ‡æ³¨
    "complex_reasoning": 150k,  # GPT-4V ç”Ÿæˆ
    "multi_turn_dialog": 100k,  # å¤šè½®å¯¹è¯
    "rejection_sampling": 50k,  # è´Ÿæ ·æœ¬
}
```

**LoRA å¾®è°ƒé…ç½®ï¼š**
```python
lora_config = LoRAConfig(
    r=64,  # è¾ƒå¤§çš„ rank
    lora_alpha=16,
    target_modules=[
        "c_attn",  # Qwen çš„æ³¨æ„åŠ›æ¨¡å—
        "c_proj", 
        "w1", "w2",  # MLP
    ],
    lora_dropout=0.05,
    task_type="CAUSAL_LM",
)

# åªå¾®è°ƒè¯­è¨€æ¨¡å‹éƒ¨åˆ†
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
total_params = sum(p.numel() for p in model.parameters())
print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params/1e6:.2f}M ({100*trainable_params/total_params:.2f}%)")
# è¾“å‡º: å¯è®­ç»ƒå‚æ•°: 384.00M (4.92%)
```

**è®­ç»ƒæ›²çº¿ç›‘æ§ï¼š**
```
       Loss
   3.5 |
   3.0 |  Stage 1
   2.5 |    â•²___
   2.0 |         â•²__ Stage 2
   1.5 |             â•²____
   1.0 |                  â•²___ Stage 3
   0.5 |                      â•²________
       |__|__|__|__|__|__|__|__|__|__|__
         10k  20k  30k  40k  50k  60k  Steps
```

## é«˜çº§è¯é¢˜

### è§†è§‰ç¼–ç å™¨è§£å†»æ—¶æœº

**è§£å†»ç­–ç•¥å¯¹æ¯”ï¼š**
```
ç­–ç•¥            ä¼˜ç‚¹                ç¼ºç‚¹              é€‚ç”¨åœºæ™¯
-----------------------------------------------------------------
å§‹ç»ˆå†»ç»“        çœæ˜¾å­˜ã€è®­ç»ƒå¿«      å¯èƒ½æ¬ æ‹Ÿåˆ        æ•°æ®ä¸é¢„è®­ç»ƒç›¸ä¼¼
ä»å¤´è§£å†»        å……åˆ†é€‚åº”æ–°ä»»åŠ¡      æ˜“è¿‡æ‹Ÿåˆã€æ…¢      å¤§è§„æ¨¡æ–°é¢†åŸŸæ•°æ®
é˜¶æ®µæ€§è§£å†»      å¹³è¡¡æ€§èƒ½ä¸æ•ˆç‡      éœ€è¦ç»éªŒè°ƒå‚      é€šç”¨åœºæ™¯ï¼ˆæ¨èï¼‰
```

**é˜¶æ®µæ€§è§£å†»å®è·µï¼š**
```python
def staged_unfreeze(model, current_step, total_steps):
    """æ¸è¿›è§£å†»è§†è§‰ç¼–ç å™¨"""
    progress = current_step / total_steps
    
    if progress < 0.5:
        # å‰ 50%: å…¨éƒ¨å†»ç»“
        freeze_vision_encoder(model)
    elif progress < 0.8:
        # 50-80%: è§£å†»æœ€å 4 å±‚
        for i, layer in enumerate(model.vision_encoder.layers):
            if i < len(model.vision_encoder.layers) - 4:
                freeze_layer(layer)
            else:
                unfreeze_layer(layer)
    else:
        # æœ€å 20%: å…¨éƒ¨è§£å†»ï¼Œä½†ç”¨æ›´å°å­¦ä¹ ç‡
        unfreeze_vision_encoder(model)
        # è§†è§‰ç¼–ç å™¨å­¦ä¹ ç‡ = 0.1 * åŸºç¡€å­¦ä¹ ç‡
```

### LoRA Rank è‡ªé€‚åº”é€‰æ‹©

**åŸºäºé‡è¦æ€§çš„ Rank åˆ†é…ï¼š**
```python
def compute_layer_importance(model, dataloader, num_samples=100):
    """è®¡ç®—å„å±‚çš„ Fisher ä¿¡æ¯çŸ©é˜µè¿¹"""
    importance_scores = {}
    
    for batch in dataloader[:num_samples]:
        outputs = model(batch)
        loss = compute_loss(outputs, batch['labels'])
        
        for name, param in model.named_parameters():
            if param.requires_grad:
                grad = torch.autograd.grad(loss, param, retain_graph=True)[0]
                if name not in importance_scores:
                    importance_scores[name] = 0
                importance_scores[name] += (grad ** 2).sum().item()
    
    # å½’ä¸€åŒ–
    total = sum(importance_scores.values())
    for name in importance_scores:
        importance_scores[name] /= total
    
    return importance_scores

# æ ¹æ®é‡è¦æ€§åˆ†é… rank
def adaptive_rank_allocation(importance_scores, total_rank_budget=512):
    rank_allocation = {}
    for name, score in importance_scores.items():
        # rank âˆˆ [4, 64]
        rank = min(64, max(4, int(score * total_rank_budget)))
        # ç¡®ä¿æ˜¯ 4 çš„å€æ•°ï¼ˆç¡¬ä»¶å‹å¥½ï¼‰
        rank = (rank // 4) * 4
        rank_allocation[name] = rank
    return rank_allocation
```

### æ··åˆç²¾åº¦è®­ç»ƒçš„ç¨³å®šæ€§

**BF16 vs FP16 é€‰æ‹©ï¼š**
```
ç‰¹æ€§          FP16            BF16
-----------------------------------------
åŠ¨æ€èŒƒå›´      Â±65504          Â±3.4e38
ç²¾åº¦          é«˜              ä¸­
ç¡¬ä»¶æ”¯æŒ      å¹¿æ³›            A100+
æº¢å‡ºé£é™©      é«˜              æä½
æ¨èåœºæ™¯      æ¨ç†ä¸ºä¸»        è®­ç»ƒä¸ºä¸»
```

**æ··åˆç²¾åº¦æœ€ä½³å®è·µï¼š**
```python
# è‡ªåŠ¨æ··åˆç²¾åº¦é…ç½®
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler(
    init_scale=2.**16,  # åˆå§‹ç¼©æ”¾å› å­
    growth_factor=2.0,   # å¢é•¿å› å­
    backoff_factor=0.5,  # å›é€€å› å­
    growth_interval=2000,  # å¢é•¿é—´éš”
)

# è®­ç»ƒå¾ªç¯
for batch in dataloader:
    optimizer.zero_grad()
    
    with autocast(dtype=torch.bfloat16):  # æˆ– torch.float16
        outputs = model(batch)
        loss = compute_loss(outputs, batch['labels'])
    
    # æ¢¯åº¦ç¼©æ”¾
    scaler.scale(loss).backward()
    
    # æ¢¯åº¦è£å‰ªï¼ˆåœ¨ç¼©æ”¾ç©ºé—´ï¼‰
    scaler.unscale_(optimizer)
    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
    
    # ä¼˜åŒ–å™¨æ­¥éª¤
    scaler.step(optimizer)
    scaler.update()
    
    # ç›‘æ§æº¢å‡º
    if scaler.get_scale() < 1.0:
        logger.warning(f"æ¢¯åº¦æº¢å‡ºï¼Œå½“å‰ scale: {scaler.get_scale()}")
```

## æœ¬ç« å°ç»“

æœ¬ç« ç³»ç»Ÿä»‹ç»äº† VLM çš„ç›‘ç£å¾®è°ƒç­–ç•¥ï¼Œæ¶µç›–äº†ä»æŒ‡ä»¤è®¾è®¡åˆ°è®­ç»ƒä¼˜åŒ–çš„å®Œæ•´æµç¨‹ï¼š

**æ ¸å¿ƒè¦ç‚¹å›é¡¾ï¼š**
1. **æŒ‡ä»¤è®¾è®¡**ï¼šæ¸…æ™°çš„æ¨¡æ¿ã€åˆç†çš„ç³»ç»Ÿæç¤ºã€å¤šè½®å¯¹è¯å¤„ç†ã€è§†è§‰-è¯­è¨€å¯¹é½
2. **æŸå¤±å‡½æ•°**ï¼šè‡ªå›å½’æŸå¤±ã€æ©ç ç­–ç•¥ã€å¤šä»»åŠ¡å¹³è¡¡ã€grounding æŸå¤±
3. **PEFT æ–¹æ³•**ï¼šLoRAã€QLoRAã€Adapter çš„åŸç†ä¸é€‰æ‹©
4. **è®­ç»ƒç¨³å®šæ€§**ï¼šå­¦ä¹ ç‡è°ƒåº¦ã€æ¢¯åº¦è£å‰ªã€æƒé‡åˆå§‹åŒ–ã€checkpoint ç­–ç•¥

**å…³é”®å…¬å¼æ±‡æ€»ï¼š**
- è¯­è¨€æ¨¡å‹æŸå¤±ï¼š$\mathcal{L}_{LM} = -\sum_{t=1}^{T} \log P(x_t | x_{<t}, I)$
- LoRA åˆ†è§£ï¼š$W' = W + BA$ï¼Œå…¶ä¸­ $r \ll \min(d, k)$
- å¤šä»»åŠ¡æŸå¤±ï¼š$\mathcal{L}_{total} = \sum_{i=1}^{N} w_i \mathcal{L}_i$
- ä¸ç¡®å®šæ€§åŠ æƒï¼š$\mathcal{L}_{total} = \sum_{i=1}^{N} \frac{1}{2\sigma_i^2} \mathcal{L}_i + \log \sigma_i$

## ç»ƒä¹ é¢˜

### åŸºç¡€é¢˜ï¼ˆç†è§£æ¦‚å¿µï¼‰

**é¢˜ 1ï¼šæŒ‡ä»¤æ¨¡æ¿è®¾è®¡**
è®¾è®¡ä¸€ä¸ªæ”¯æŒå¤šå›¾åƒè¾“å…¥å’Œ CoTï¼ˆChain of Thoughtï¼‰æ¨ç†çš„æŒ‡ä»¤æ¨¡æ¿ã€‚è¦æ±‚èƒ½å¤Ÿå¤„ç†å›¾åƒé—´çš„æ¯”è¾ƒä»»åŠ¡ã€‚

<details>
<summary>ğŸ’¡ æç¤º</summary>
è€ƒè™‘ï¼š1) å¦‚ä½•æ ‡è®°ä¸åŒå›¾åƒ 2) CoT çš„æ­¥éª¤åˆ†éš” 3) å›¾åƒå¼•ç”¨æ–¹å¼
</details>

<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>

```
System: ä½ æ˜¯ä¸€ä¸ªè§†è§‰æ¨ç†åŠ©æ‰‹ï¼Œè¯·ä¸€æ­¥æ­¥åˆ†æé—®é¢˜ã€‚

User: æ¯”è¾ƒ <image_1> å’Œ <image_2>ï¼Œæ‰¾å‡ºä¸»è¦å·®å¼‚ã€‚Assistant: è®©æˆ‘é€æ­¥åˆ†æï¼š
æ­¥éª¤1ï¼šè§‚å¯Ÿå›¾åƒ1çš„ä¸»è¦å…ƒç´ ...
æ­¥éª¤2ï¼šè§‚å¯Ÿå›¾åƒ2çš„ä¸»è¦å…ƒç´ ...
æ­¥éª¤3ï¼šå¯¹æ¯”å·®å¼‚...
ç»“è®ºï¼šä¸»è¦å·®å¼‚åŒ…æ‹¬...
```
</details>

**é¢˜ 2ï¼šLoRA Rank é€‰æ‹©**
ç»™å®šä¸€ä¸ª 7B å‚æ•°çš„ VLMï¼Œæ˜¾å­˜é™åˆ¶ä¸º 24GBï¼Œå¦‚ä½•é€‰æ‹©åˆé€‚çš„ LoRA rankï¼Ÿè€ƒè™‘è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½çš„æƒè¡¡ã€‚

<details>
<summary>ğŸ’¡ æç¤º</summary>
è®¡ç®—ä¸åŒ rank ä¸‹çš„å‚æ•°é‡å’Œæ˜¾å­˜å ç”¨ï¼Œè€ƒè™‘æ¢¯åº¦å’Œä¼˜åŒ–å™¨çŠ¶æ€
</details>

<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>

å¯¹äº 7B æ¨¡å‹ï¼Œ24GB æ˜¾å­˜ä¸‹çš„ rank é€‰æ‹©ï¼š
- QLoRA 4-bit: r=64 å¯è¡Œï¼ˆ~20GBï¼‰
- LoRA 16-bit: r=16-32 åˆé€‚ï¼ˆ~18-22GBï¼‰
- å»ºè®®ä» r=16 å¼€å§‹ï¼Œç›‘æ§éªŒè¯é›†æ€§èƒ½ï¼Œé€æ­¥å¢åŠ åˆ° r=32
</details>

**é¢˜ 3ï¼šå¤šä»»åŠ¡æŸå¤±å¹³è¡¡**
ä¸‰ä¸ªä»»åŠ¡çš„åˆå§‹æŸå¤±åˆ†åˆ«ä¸ºï¼šå›¾åƒæè¿° 2.5ã€VQA 3.2ã€OCR 1.8ã€‚å¦‚ä½•è®¾ç½®åˆå§‹æƒé‡ï¼Ÿ

<details>
<summary>ğŸ’¡ æç¤º</summary>
è€ƒè™‘æŸå¤±é‡çº§å·®å¼‚å’Œä»»åŠ¡é‡è¦æ€§
</details>

<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>

åˆå§‹æƒé‡è®¾ç½®ï¼š
- å›¾åƒæè¿°: 1.0 / 2.5 = 0.4
- VQA: 1.0 / 3.2 = 0.31
- OCR: 1.0 / 1.8 = 0.56
å½’ä¸€åŒ–åï¼š[0.32, 0.25, 0.43]
</details>

### æŒ‘æˆ˜é¢˜ï¼ˆæ·±å…¥æ€è€ƒï¼‰

**é¢˜ 4ï¼šæ¢¯åº¦ç´¯ç§¯ç­–ç•¥**
æ˜¾å­˜åªå¤Ÿ batch_size=2ï¼Œä½†æœ€ä¼˜ batch_size=32ã€‚è®¾è®¡ä¸€ä¸ªè€ƒè™‘ VLM ç‰¹æ€§çš„æ¢¯åº¦ç´¯ç§¯æ–¹æ¡ˆã€‚

<details>
<summary>ğŸ’¡ æç¤º</summary>
è€ƒè™‘ï¼š1) ç´¯ç§¯æ­¥æ•° 2) å­¦ä¹ ç‡ç¼©æ”¾ 3) æ¢¯åº¦è£å‰ªæ—¶æœº
</details>

<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>

```python
accumulation_steps = 16  # 2 * 16 = 32
effective_batch_size = 32

for step, batch in enumerate(dataloader):
    loss = compute_loss(batch) / accumulation_steps
    loss.backward()
    
    if (step + 1) % accumulation_steps == 0:
        # åœ¨ç´¯ç§¯å®Œæˆåè£å‰ª
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()
        optimizer.zero_grad()
        
# å­¦ä¹ ç‡çº¿æ€§ç¼©æ”¾
lr = base_lr * sqrt(effective_batch_size / base_batch_size)
```
</details>

**é¢˜ 5ï¼šè§†è§‰ç¼–ç å™¨å¾®è°ƒå†³ç­–**
æ–°ä»»åŠ¡æ˜¯åŒ»å­¦å›¾åƒåˆ†æï¼Œä¸é¢„è®­ç»ƒæ•°æ®ï¼ˆè‡ªç„¶å›¾åƒï¼‰å·®å¼‚å¾ˆå¤§ã€‚è®¾è®¡ä¸€ä¸ªæ¸è¿›å¼è§£å†»æ–¹æ¡ˆã€‚

<details>
<summary>ğŸ’¡ æç¤º</summary>
åŒ»å­¦å›¾åƒçš„ä½å±‚ç‰¹å¾ï¼ˆè¾¹ç¼˜ã€çº¹ç†ï¼‰å¯èƒ½ç›¸ä¼¼ï¼Œä½†é«˜å±‚è¯­ä¹‰å·®å¼‚å¤§
</details>

<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>

ä¸‰é˜¶æ®µè§£å†»æ–¹æ¡ˆï¼š
1. é˜¶æ®µ1ï¼ˆ0-30%ï¼‰ï¼šå†»ç»“æ‰€æœ‰å±‚ï¼Œåªè®­ç»ƒæŠ•å½±å±‚
2. é˜¶æ®µ2ï¼ˆ30-70%ï¼‰ï¼šè§£å†»å 50% å±‚ï¼Œå­¦ä¹ ç‡ 0.1x
3. é˜¶æ®µ3ï¼ˆ70-100%ï¼‰ï¼šå…¨éƒ¨è§£å†»ï¼Œå‰ 50% å±‚ç”¨ 0.01x å­¦ä¹ ç‡ï¼Œå 50% ç”¨ 0.1x
ç†ç”±ï¼šä¿ç•™ä½å±‚é€šç”¨ç‰¹å¾ï¼Œé‡ç‚¹è°ƒæ•´é«˜å±‚è¯­ä¹‰ç†è§£
</details>

**é¢˜ 6ï¼šè®­ç»ƒå´©æºƒè¯Šæ–­**
è®­ç»ƒåˆ° 40% æ—¶æŸå¤±çªç„¶å˜æˆ NaNã€‚ç»™å‡ºç³»ç»Ÿçš„æ’æŸ¥æµç¨‹å’Œå¯èƒ½åŸå› ã€‚

<details>
<summary>ğŸ’¡ æç¤º</summary>
ä»æ•°æ®ã€æ¨¡å‹ã€ä¼˜åŒ–å™¨ä¸‰ä¸ªè§’åº¦æ’æŸ¥
</details>

<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>

æ’æŸ¥æµç¨‹ï¼š
1. **æ•°æ®æ£€æŸ¥**ï¼š
   - æ˜¯å¦æœ‰æŸåå›¾åƒï¼ˆå…¨é»‘ã€å…¨ç™½ï¼‰
   - æ ‡ç­¾æ˜¯å¦æœ‰å¼‚å¸¸å€¼
   - Token ID æ˜¯å¦è¶…å‡ºè¯è¡¨èŒƒå›´

2. **æ¢¯åº¦ç›‘æ§**ï¼š
   - æ£€æŸ¥æ¢¯åº¦èŒƒæ•°å†å²
   - å®šä½ç¬¬ä¸€ä¸ª NaN å‡ºç°çš„å±‚
   - æŸ¥çœ‹è¯¥ batch çš„å…·ä½“æ•°æ®

3. **å¯èƒ½åŸå› åŠè§£å†³**ï¼š
   - å­¦ä¹ ç‡è¿‡å¤§ â†’ é™ä½å­¦ä¹ ç‡
   - é™¤é›¶é”™è¯¯ â†’ æ·»åŠ  epsilon
   - FP16 æº¢å‡º â†’ åˆ‡æ¢åˆ° BF16 æˆ–å¢å¤§ loss scale
   - æŸå±‚æœªåˆå§‹åŒ– â†’ æ£€æŸ¥æ–°å¢æ¨¡å—
</details>

**é¢˜ 7ï¼šPEFT ç»„åˆä¼˜åŒ–**
è®¾è®¡ä¸€ä¸ªé’ˆå¯¹ VLM ä¸åŒç»„ä»¶çš„æ··åˆ PEFT ç­–ç•¥ï¼Œç›®æ ‡æ˜¯åœ¨ 16GB æ˜¾å­˜é™åˆ¶ä¸‹æœ€å¤§åŒ–æ€§èƒ½ã€‚

<details>
<summary>ğŸ’¡ æç¤º</summary>
ä¸åŒç»„ä»¶çš„é‡è¦æ€§å’Œå‚æ•°é‡ä¸åŒ
</details>

<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>

æ··åˆç­–ç•¥ï¼š
```python
config = {
    "vision_encoder": "frozen",         # çœæ˜¾å­˜
    "vision_projection": "full",        # å…³é”®ç»„ä»¶ï¼Œå‚æ•°å°‘
    "llm_embed": "frozen",              # è¯åµŒå…¥ä¸åŠ¨
    "llm_layers[0:8]": "lora_r8",      # åº•å±‚å° rank
    "llm_layers[8:24]": "lora_r16",    # ä¸­å±‚ä¸­ rank
    "llm_layers[24:32]": "lora_r32",   # é«˜å±‚å¤§ rank
    "llm_head": "lora_r8",             # è¾“å‡ºå¤´å° rank
}
```
é¢„è®¡æ˜¾å­˜ï¼š~14GBï¼Œå¯è®­ç»ƒå‚æ•°ï¼š~200M
</details>

**é¢˜ 8ï¼šå¼€æ”¾æ€§æ€è€ƒ**
å¦‚æœè¦è®¾è®¡ä¸‹ä¸€ä»£ VLM çš„ SFT ç­–ç•¥ï¼Œä½ è®¤ä¸ºæœ€éœ€è¦æ”¹è¿›çš„ä¸‰ä¸ªæ–¹å‘æ˜¯ä»€ä¹ˆï¼Ÿ

<details>
<summary>ğŸ’¡ æç¤º</summary>
æ€è€ƒå½“å‰æ–¹æ³•çš„å±€é™æ€§å’Œå®é™…åº”ç”¨éœ€æ±‚
</details>

<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>

ä¸‰ä¸ªæ”¹è¿›æ–¹å‘ï¼š
1. **åŠ¨æ€è®¡ç®—åˆ†é…**ï¼šæ ¹æ®å›¾åƒå¤æ‚åº¦åŠ¨æ€è°ƒæ•´è®¡ç®—èµ„æºï¼Œç®€å•å›¾åƒç”¨å°‘é‡ tokenï¼Œå¤æ‚å›¾åƒç”¨æ›´å¤š
2. **ä¸»åŠ¨å­¦ä¹ **ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­è‡ªåŠ¨è¯†åˆ«æ¨¡å‹è–„å¼±ç¯èŠ‚ï¼ŒåŠ¨æ€è°ƒæ•´æ•°æ®é‡‡æ ·ç­–ç•¥
3. **è·¨æ¨¡æ€ä¸€è‡´æ€§**ï¼šè®¾è®¡æ›´å¥½çš„å¯¹é½æœºåˆ¶ï¼Œç¡®ä¿è§†è§‰ç†è§£å’Œè¯­è¨€ç”Ÿæˆçš„ä¸€è‡´æ€§ï¼Œå‡å°‘å¹»è§‰

ç†ç”±ï¼šå½“å‰ SFT ç­–ç•¥è¾ƒä¸ºé™æ€ï¼Œæ²¡æœ‰å……åˆ†åˆ©ç”¨æ¨¡å‹çš„è‡ªé€‚åº”èƒ½åŠ›
</details>

## å¸¸è§é™·é˜±ä¸é”™è¯¯ (Gotchas)

### æ•°æ®ç›¸å…³é™·é˜±

**1. å›¾åƒ Token è®¡ç®—é”™è¯¯**
```python
# é”™è¯¯ï¼šå¿˜è®°å›¾åƒ token å ç”¨
max_length = 2048  # ä»¥ä¸ºæœ‰ 2048 ä¸ªæ–‡æœ¬ token

# æ­£ç¡®ï¼šæ‰£é™¤å›¾åƒå ç”¨
image_tokens = 576  # ViT-L/14 
text_budget = 2048 - image_tokens  # å®é™…åªæœ‰ 1472
```

**2. å“åº”æˆªæ–­é—®é¢˜**
```python
# é™·é˜±ï¼šå“åº”è¢«æˆªæ–­ä½†ä»è®¡ç®—æŸå¤±
if len(tokens) > max_length:
    tokens = tokens[:max_length]  # å¯èƒ½æˆªæ–­åˆ°å“åº”ä¸­é—´
    
# è§£å†³ï¼šç¡®ä¿å®Œæ•´å“åº”æˆ–ä¸è®¡ç®—æŸå¤±
if len(tokens) > max_length:
    # æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´å¥å­
    last_period = tokens[:max_length].rfind(period_token_id)
    tokens = tokens[:last_period+1]
```

### è®­ç»ƒç›¸å…³é™·é˜±

**3. LoRA ä¸æ­£åˆ™åŒ–å†²çª**
```python
# é™·é˜±ï¼šå¯¹ LoRA å‚æ•°ä½¿ç”¨ weight decay
optimizer = AdamW(model.parameters(), weight_decay=0.01)

# æ­£ç¡®ï¼šLoRA å‚æ•°ä¸ç”¨ weight decay
lora_params = [p for n, p in model.named_parameters() if 'lora' in n]
other_params = [p for n, p in model.named_parameters() if 'lora' not in n]
optimizer = AdamW([
    {'params': lora_params, 'weight_decay': 0.0},
    {'params': other_params, 'weight_decay': 0.01}
])
```

**4. æ··åˆç²¾åº¦çš„ NaN é™·é˜±**
```python
# é™·é˜±ï¼šæŸäº›æ“ä½œåœ¨ FP16 ä¸‹ä¸ç¨³å®š
attention_scores = Q @ K.T / sqrt(d_k)  # å¯èƒ½æº¢å‡º

# è§£å†³ï¼šå…³é”®æ“ä½œç”¨ FP32
with autocast(enabled=False):
    attention_scores = Q.float() @ K.float().T / sqrt(d_k)
```

**5. æ¢¯åº¦ç´¯ç§¯ä¸ Batch Norm**
```python
# é™·é˜±ï¼šæ¢¯åº¦ç´¯ç§¯æ—¶ BN ç»Ÿè®¡ä¸å‡†
# BN åªçœ‹å½“å‰ micro-batchï¼Œä¸æ˜¯å®Œæ•´ batch

# è§£å†³ï¼šä½¿ç”¨ Layer Norm æˆ– RMSNorm
# æˆ–è€…åŒæ­¥ BNï¼ˆä½†ä¼šå¢åŠ é€šä¿¡å¼€é”€ï¼‰
```

### è¯„ä¼°ç›¸å…³é™·é˜±

**6. ç”Ÿæˆé•¿åº¦åå·®**
```python
# é™·é˜±ï¼šä¸åŒé•¿åº¦çš„ç”Ÿæˆå½±å“è¯„ä¼°
# çŸ­å›ç­”å¯èƒ½ perplexity æ›´ä½ä½†ä¿¡æ¯ä¸è¶³

# è§£å†³ï¼šæ§åˆ¶ç”Ÿæˆé•¿åº¦æˆ–ä½¿ç”¨é•¿åº¦å½’ä¸€åŒ–
score = log_prob / (length ** alpha)  # alpha ~ 0.6-0.8
```

**7. Teacher Forcing ä¸æ¨ç†ä¸ä¸€è‡´**
```python
# è®­ç»ƒæ—¶ï¼šæ¯æ­¥éƒ½ç”¨çœŸå®æ ‡ç­¾
# æ¨ç†æ—¶ï¼šç”¨è‡ªå·±çš„é¢„æµ‹ï¼Œè¯¯å·®ç´¯ç§¯

# ç¼“è§£ï¼šScheduled Sampling
if random.random() < teacher_forcing_ratio:
    input_token = ground_truth[t]
else:
    input_token = predicted[t-1]
```

### è°ƒè¯•æŠ€å·§

**å¿«é€Ÿè¯Šæ–­æ£€æŸ¥ç‚¹ï¼š**
```bash
# 1. æ£€æŸ¥æ¢¯åº¦
python -c "import torch; ckpt=torch.load('model.pt'); print([(k,v.abs().max().item()) for k,v in ckpt['grad_dict'].items() if v.abs().max() > 100])"

# 2. æ£€æŸ¥æƒé‡åˆ†å¸ƒ
python -c "import torch; ckpt=torch.load('model.pt'); print([(k, v.std().item()) for k,v in ckpt['model_state_dict'].items() if 'weight' in k])"

# 3. æ£€æŸ¥æŸå¤±å†å²
python -c "import torch; import matplotlib.pyplot as plt; ckpt=torch.load('model.pt'); plt.plot(ckpt['loss_history']); plt.show()"
```

## æœ€ä½³å®è·µæ£€æŸ¥æ¸…å•

### è®­ç»ƒå‰å‡†å¤‡

- [ ] **æ•°æ®éªŒè¯**
  - [ ] æ‰€æœ‰å›¾åƒå¯æ­£å¸¸åŠ è½½
  - [ ] å›¾åƒå°ºå¯¸åˆ†å¸ƒåˆç†ï¼ˆæ²¡æœ‰æç«¯å¤§/å°ï¼‰
  - [ ] æ–‡æœ¬é•¿åº¦åˆ†å¸ƒæ£€æŸ¥
  - [ ] ç‰¹æ®Šå­—ç¬¦æ­£ç¡®è½¬ä¹‰
  
- [ ] **æ¨¡å‹é…ç½®**
  - [ ] å›¾åƒ token æ•°è®¡ç®—æ­£ç¡®
  - [ ] ä¸Šä¸‹æ–‡é•¿åº¦è®¾ç½®åˆç†
  - [ ] LoRA rank æ ¹æ®æ˜¾å­˜é€‰æ‹©
  - [ ] æ£€æŸ¥ç‚¹ä¿å­˜è·¯å¾„å¯å†™

- [ ] **è®­ç»ƒé…ç½®**
  - [ ] å­¦ä¹ ç‡è®¾ç½®ï¼ˆé€šå¸¸ 1e-4 åˆ° 5e-4ï¼‰
  - [ ] Warmup æ­¥æ•°ï¼ˆå»ºè®® 3-10% æ€»æ­¥æ•°ï¼‰
  - [ ] æ¢¯åº¦è£å‰ªé˜ˆå€¼ï¼ˆé€šå¸¸ 1.0ï¼‰
  - [ ] æ··åˆç²¾åº¦è®¾ç½®ï¼ˆBF16 ä¼˜äº FP16ï¼‰

### è®­ç»ƒä¸­ç›‘æ§

- [ ] **æ€§èƒ½æŒ‡æ ‡**
  - [ ] GPU åˆ©ç”¨ç‡ > 90%
  - [ ] æ˜¾å­˜ä½¿ç”¨ç¨³å®šï¼ˆæ— æ³„æ¼ï¼‰
  - [ ] è®­ç»ƒé€Ÿåº¦ï¼ˆsamples/secï¼‰ç¨³å®š
  - [ ] æ•°æ®åŠ è½½ä¸æ˜¯ç“¶é¢ˆ

- [ ] **æ¨¡å‹æŒ‡æ ‡**
  - [ ] æŸå¤±å¹³ç¨³ä¸‹é™
  - [ ] æ¢¯åº¦èŒƒæ•°ç¨³å®š
  - [ ] å­¦ä¹ ç‡æŒ‰è®¡åˆ’è¡°å‡
  - [ ] éªŒè¯é›†æŒ‡æ ‡æå‡

- [ ] **å¼‚å¸¸æ£€æµ‹**
  - [ ] æ—  NaN/Inf å‡ºç°
  - [ ] æ— æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±
  - [ ] æƒé‡æ›´æ–°å¹…åº¦åˆç†
  - [ ] ç”Ÿæˆæ ·æœ¬è´¨é‡æ£€æŸ¥

### è®­ç»ƒåéªŒè¯

- [ ] **æ¨¡å‹è´¨é‡**
  - [ ] åŸºç¡€èƒ½åŠ›ä¿æŒï¼ˆæ²¡æœ‰ç¾éš¾æ€§é—å¿˜ï¼‰
  - [ ] æ–°ä»»åŠ¡æ€§èƒ½è¾¾æ ‡
  - [ ] ç”Ÿæˆå¤šæ ·æ€§é€‚ä¸­
  - [ ] æ— æ˜æ˜¾åè§æˆ–æœ‰å®³è¾“å‡º

- [ ] **éƒ¨ç½²å‡†å¤‡**
  - [ ] æ¨¡å‹å¯æ­£ç¡®åŠ è½½
  - [ ] æ¨ç†é€Ÿåº¦æ»¡è¶³è¦æ±‚
  - [ ] é‡åŒ–åç²¾åº¦æŸå¤±å¯æ¥å—
  - [ ] è¾¹ç•Œcaseæµ‹è¯•é€šè¿‡

- [ ] **æ–‡æ¡£å®Œå–„**
  - [ ] è®­ç»ƒé…ç½®è®°å½•
  - [ ] æ•°æ®é›†ç‰ˆæœ¬è®°å½•
  - [ ] æ€§èƒ½åŸºå‡†è®°å½•
  - [ ] å·²çŸ¥é—®é¢˜è®°å½•

### é—®é¢˜æ’æŸ¥é¡ºåº

é‡åˆ°é—®é¢˜æ—¶ï¼ŒæŒ‰ä»¥ä¸‹é¡ºåºæ’æŸ¥ï¼š

1. **æ•°æ®é—®é¢˜**ï¼ˆ50% çš„é—®é¢˜æ¥æºï¼‰
   - æ£€æŸ¥å½“å‰ batch çš„æ•°æ®
   - éªŒè¯æ•°æ®é¢„å¤„ç†æµç¨‹
   
2. **é…ç½®é—®é¢˜**ï¼ˆ30% çš„é—®é¢˜æ¥æºï¼‰
   - å­¦ä¹ ç‡æ˜¯å¦è¿‡å¤§
   - Batch size æ˜¯å¦åˆé€‚
   
3. **ä»£ç é—®é¢˜**ï¼ˆ20% çš„é—®é¢˜æ¥æºï¼‰
   - æ˜¯å¦æœ‰ç»´åº¦ä¸åŒ¹é…
   - æ˜¯å¦æœ‰æœªåˆå§‹åŒ–çš„å‚æ•°

---

*é€šè¿‡æœ¬ç« çš„å­¦ä¹ ï¼Œæ‚¨åº”è¯¥å·²ç»æŒæ¡äº† VLM ç›‘ç£å¾®è°ƒçš„æ ¸å¿ƒæŠ€æœ¯ã€‚ä¸‹ä¸€ç« æˆ‘ä»¬å°†æ¢è®¨åˆ†å¸ƒå¼è®­ç»ƒä¸ä¼˜åŒ–ï¼Œè¿›ä¸€æ­¥æå‡è®­ç»ƒæ•ˆç‡ã€‚*

[â† è¿”å›ç›®å½•](index.md) | [ä¸‹ä¸€ç« ï¼šåˆ†å¸ƒå¼è®­ç»ƒä¸ä¼˜åŒ– â†’](chapter4.md)