<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>ç¬¬ 10 ç« ï¼šè®­ç»ƒå´©æºƒä¸ NaN é—®é¢˜</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>ç›®å½•</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="æœç´¢..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„ç›‘ç£å¾®è°ƒä¸å¼ºåŒ–å­¦ä¹ å®æˆ˜æ•™ç¨‹</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬ 1 ç« ï¼šVLM æ¶æ„ä¸åŸç†</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬ 2 ç« ï¼šæ•°æ®å‡†å¤‡ä¸é¢„å¤„ç†</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬ 3 ç« ï¼šSFT è®­ç»ƒç­–ç•¥</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬ 4 ç« ï¼šåˆ†å¸ƒå¼è®­ç»ƒä¸ä¼˜åŒ–</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬ 5 ç« ï¼šRLHF åŸºç¡€ä¸å®ç°</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬ 6 ç« ï¼šç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬ 7 ç« ï¼šè¯„ä¼°ä½“ç³»è®¾è®¡</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬ 8 ç« ï¼šæ¨¡å‹éƒ¨ç½²ä¸æœåŠ¡åŒ–</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬ 9 ç« ï¼šCUDA OOM è°ƒè¯•å®Œå…¨æŒ‡å—</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬ 10 ç« ï¼šè®­ç»ƒå´©æºƒä¸ NaN é—®é¢˜</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬ 11 ç« ï¼šè®­ç»ƒé€Ÿåº¦ä¼˜åŒ–å®æˆ˜</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬ 12 ç« ï¼šå¤šæœºå¤šå¡è°ƒè¯•åœ°ç‹±</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="10-nan">ç¬¬ 10 ç« ï¼šè®­ç»ƒå´©æºƒä¸ NaN é—®é¢˜</h1>
<p>è®­ç»ƒè¿‡ç¨‹ä¸­çªç„¶å‡ºç° Loss çˆ†ç‚¸æˆ– NaNï¼Œæ˜¯æ¯ä¸ª VLM å·¥ç¨‹å¸ˆçš„å™©æ¢¦ã€‚ä¸€ä¸ªåŸæœ¬æ­£å¸¸è¿è¡Œçš„è®­ç»ƒï¼Œå¯èƒ½åœ¨å‡ ä¸ª step å†…å½»åº•å´©æºƒï¼Œæµªè´¹æ•°å¤©çš„è®¡ç®—èµ„æºã€‚æœ¬ç« å°†ç³»ç»Ÿä»‹ç»è®­ç»ƒä¸ç¨³å®šçš„æ ¹æœ¬åŸå› ã€å¿«é€Ÿè¯Šæ–­æ–¹æ³•ï¼Œä»¥åŠç»è¿‡å®æˆ˜æ£€éªŒçš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•åœ¨ 5 åˆ†é’Ÿå†…å®šä½é—®é¢˜ï¼ŒæŒæ¡æ··åˆç²¾åº¦è®­ç»ƒçš„ç¨³å®šæ€§æŠ€å·§ï¼Œå¹¶å»ºç«‹å®Œå–„çš„å®¹é”™æœºåˆ¶ã€‚</p>
<h2 id="101-loss-5">10.1 Loss çˆ†ç‚¸çš„ 5 åˆ†é’Ÿæ’æŸ¥æµç¨‹</h2>
<p>å½“è®­ç»ƒ Loss çªç„¶é£™å‡æˆ–å‡ºç° NaN æ—¶ï¼Œæ—¶é—´å°±æ˜¯é‡‘é’±ã€‚ä»¥ä¸‹æ˜¯ç»è¿‡å¤§é‡å®è·µæ€»ç»“çš„å¿«é€Ÿè¯Šæ–­æµç¨‹ï¼š</p>
<h3 id="1011-30">10.1.1 ç¬¬ä¸€æ­¥ï¼šç«‹å³ä¿å­˜ç°åœºï¼ˆ30 ç§’ï¼‰</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># ç´§æ€¥ä¿å­˜å½“å‰çŠ¶æ€</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
    <span class="s1">&#39;step&#39;</span><span class="p">:</span> <span class="n">current_step</span><span class="p">,</span>
    <span class="s1">&#39;model_state&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
    <span class="s1">&#39;optimizer_state&#39;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
    <span class="s1">&#39;loss_history&#39;</span><span class="p">:</span> <span class="n">loss_history</span><span class="p">[</span><span class="o">-</span><span class="mi">100</span><span class="p">:],</span>  <span class="c1"># æœ€è¿‘100ä¸ªstepçš„loss</span>
    <span class="s1">&#39;grad_norm_history&#39;</span><span class="p">:</span> <span class="n">grad_norm_history</span><span class="p">[</span><span class="o">-</span><span class="mi">100</span><span class="p">:],</span>
<span class="p">},</span> <span class="sa">f</span><span class="s1">&#39;debug_checkpoint_step_</span><span class="si">{</span><span class="n">current_step</span><span class="si">}</span><span class="s1">.pt&#39;</span><span class="p">)</span>
</code></pre></div>

<h3 id="1012-loss-1">10.1.2 ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥ Loss æ›²çº¿æ¨¡å¼ï¼ˆ1 åˆ†é’Ÿï¼‰</h3>
<p>Loss çˆ†ç‚¸é€šå¸¸æœ‰ä¸‰ç§æ¨¡å¼ï¼Œæ¯ç§å¯¹åº”ä¸åŒçš„åŸå› ï¼š</p>
<div class="codehilite"><pre><span></span><code>æ¨¡å¼ 1: çªç„¶è·³è·ƒ
Loss: 2.1 â†’ 2.0 â†’ 1.9 â†’ 8734.5 â†’ NaN
åŸå› : å•ä¸ªå¼‚å¸¸æ ·æœ¬æˆ–æ•°å€¼æº¢å‡º

æ¨¡å¼ 2: æŒ‡æ•°å¢é•¿
Loss: 2.1 â†’ 2.3 â†’ 2.8 â†’ 4.5 â†’ 12.3 â†’ 89.7 â†’ NaN
åŸå› : å­¦ä¹ ç‡è¿‡å¤§æˆ–æ¢¯åº¦ç´¯ç§¯é”™è¯¯

æ¨¡å¼ 3: éœ‡è¡å‘æ•£
Loss: 2.1 â†’ 1.8 â†’ 2.5 â†’ 1.6 â†’ 3.2 â†’ 1.4 â†’ 5.8 â†’ NaN
åŸå› : ä¼˜åŒ–å™¨çŠ¶æ€æŸåæˆ–æ•°å€¼ä¸ç¨³å®š
</code></pre></div>

<h3 id="1013-2">10.1.3 ç¬¬ä¸‰æ­¥ï¼šå®šä½é—®é¢˜å±‚çº§ï¼ˆ2 åˆ†é’Ÿï¼‰</h3>
<p>ä½¿ç”¨ä»¥ä¸‹ä»£ç å¿«é€Ÿå®šä½é—®é¢˜å‘ç”Ÿçš„å±‚çº§ï¼š</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">check_model_health</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;å¿«é€Ÿæ£€æŸ¥æ¨¡å‹å„å±‚çš„å¥åº·çŠ¶æ€&quot;&quot;&quot;</span>
    <span class="n">issues</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
        <span class="c1"># æ£€æŸ¥å‚æ•°æœ¬èº«</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">param</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="n">issues</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NaN in parameter: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">param</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="n">issues</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inf in parameter: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># æ£€æŸ¥æ¢¯åº¦</span>
        <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="n">issues</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NaN in gradient: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="n">issues</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inf in gradient: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># æ£€æŸ¥æ¢¯åº¦èŒƒæ•°</span>
            <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">grad_norm</span> <span class="o">&gt;</span> <span class="mi">1000</span><span class="p">:</span>
                <span class="n">issues</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Large gradient norm (</span><span class="si">{</span><span class="n">grad_norm</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">issues</span>
</code></pre></div>

<h3 id="1014-15">10.1.4 ç¬¬å››æ­¥ï¼šæ£€æŸ¥å…³é”®æ•°å€¼ï¼ˆ1.5 åˆ†é’Ÿï¼‰</h3>
<p>VLM è®­ç»ƒä¸­æœ€å®¹æ˜“å‡ºé—®é¢˜çš„æ•°å€¼è®¡ç®—ï¼š</p>
<ol>
<li><strong>æ³¨æ„åŠ›åˆ†æ•°</strong>ï¼š</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># æ£€æŸ¥æ³¨æ„åŠ›æƒé‡</span>
<span class="n">attention_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d_k</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="k">if</span> <span class="p">(</span><span class="n">attention_weights</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;è­¦å‘Šï¼šå‡ºç°å…¨é›¶æ³¨æ„åŠ›æƒé‡ï¼ˆæ•°å€¼ä¸‹æº¢ï¼‰&quot;</span><span class="p">)</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;è­¦å‘Šï¼šæ³¨æ„åŠ›æƒé‡åŒ…å« NaN&quot;</span><span class="p">)</span>
</code></pre></div>

<ol start="2">
<li><strong>æŸå¤±å‡½æ•°ä¸­çš„ log æ“ä½œ</strong>ï¼š</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># æ·»åŠ æ•°å€¼ç¨³å®šæ€§</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="c1"># é”™è¯¯ï¼šå¯èƒ½å¯¼è‡´ log(0)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
<span class="c1"># æ­£ç¡®ï¼šæ·»åŠ  epsilon</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="n">target</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
</code></pre></div>

<ol start="3">
<li><strong>LayerNorm çš„é™¤æ³•</strong>ï¼š</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># æ£€æŸ¥ LayerNorm æ˜¯å¦ç¨³å®š</span>
<span class="k">def</span> <span class="nf">stable_layer_norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">):</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">unbiased</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># ç¡®ä¿æ–¹å·®ä¸ä¸ºé›¶</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
</code></pre></div>

<h3 id="1015">10.1.5 ç´§æ€¥å¤„ç†å†³ç­–æ ‘</h3>
<div class="codehilite"><pre><span></span><code><span class="nx">å‘ç°</span><span class="w"> </span><span class="nx">Loss</span><span class="w"> </span><span class="nx">çˆ†ç‚¸</span><span class="o">/</span><span class="nx">NaN</span>
<span class="err">â”‚</span>
<span class="err">â”œâ”€</span><span class="w"> </span><span class="nx">æ˜¯å¦åœ¨å‰</span><span class="w"> </span><span class="mi">1000</span><span class="w"> </span><span class="nx">æ­¥å†…</span><span class="err">ï¼Ÿ</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="nx">æ˜¯</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="nx">æ£€æŸ¥åˆå§‹åŒ–å’Œå­¦ä¹ ç‡é¢„çƒ­</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â””â”€</span><span class="w"> </span><span class="nx">å¦</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="nx">ç»§ç»­è¯Šæ–­</span>
<span class="err">â”‚</span>
<span class="err">â”œâ”€</span><span class="w"> </span><span class="nx">æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦</span><span class="err">ï¼Ÿ</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="nx">æ˜¯</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="nx">æ£€æŸ¥</span><span class="w"> </span><span class="nx">loss</span><span class="w"> </span><span class="nx">scaling</span><span class="w"> </span><span class="nx">å’Œ</span><span class="w"> </span><span class="nx">dtype</span><span class="w"> </span><span class="nx">è½¬æ¢</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â””â”€</span><span class="w"> </span><span class="nx">å¦</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="nx">æ£€æŸ¥æ•°å€¼æº¢å‡º</span>
<span class="err">â”‚</span>
<span class="err">â”œâ”€</span><span class="w"> </span><span class="nx">æ˜¯å¦æœ‰å¼‚å¸¸å¤§çš„æ¢¯åº¦</span><span class="err">ï¼Ÿ</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="nx">æ˜¯</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="nx">é™ä½å­¦ä¹ ç‡æˆ–å¢å¼º</span><span class="w"> </span><span class="nx">gradient</span><span class="w"> </span><span class="nx">clipping</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â””â”€</span><span class="w"> </span><span class="nx">å¦</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="nx">æ£€æŸ¥æ•°æ®å’ŒæŸå¤±å‡½æ•°</span>
<span class="err">â”‚</span>
<span class="err">â””â”€</span><span class="w"> </span><span class="nx">æ˜¯å¦å¯ä»¥ä»</span><span class="w"> </span><span class="nx">checkpoint</span><span class="w"> </span><span class="nx">æ¢å¤</span><span class="err">ï¼Ÿ</span>
<span class="w">   </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="nx">æ˜¯</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="nx">è°ƒæ•´è¶…å‚æ•°åæ¢å¤è®­ç»ƒ</span>
<span class="w">   </span><span class="err">â””â”€</span><span class="w"> </span><span class="nx">å¦</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="nx">é™çº§åˆ°æ›´ä¿å®ˆçš„é…ç½®é‡æ–°å¼€å§‹</span>
</code></pre></div>

<h2 id="102">10.2 æ¢¯åº¦ç›‘æ§ä¸å¼‚å¸¸å€¼å®šä½</h2>
<h3 id="1021">10.2.1 å®æ—¶æ¢¯åº¦ç›‘æ§ç³»ç»Ÿ</h3>
<p>å»ºç«‹å®Œå–„çš„æ¢¯åº¦ç›‘æ§æ˜¯é¢„é˜²è®­ç»ƒå´©æºƒçš„ç¬¬ä¸€é“é˜²çº¿ï¼š</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">GradientMonitor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;æ¢¯åº¦ç›‘æ§å™¨ï¼Œå®æ—¶è·Ÿè¸ªæ¢¯åº¦ç»Ÿè®¡ä¿¡æ¯&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">logger</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">logger</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">anomaly_threshold</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;max_norm&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span>
            <span class="s1">&#39;min_norm&#39;</span><span class="p">:</span> <span class="mf">1e-8</span><span class="p">,</span>
            <span class="s1">&#39;nan_tolerance&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">check_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;æ£€æŸ¥å½“å‰æ­¥çš„æ¢¯åº¦å¥åº·çŠ¶æ€&quot;&quot;&quot;</span>
        <span class="n">alerts</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">grad</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span>

            <span class="c1"># è®¡ç®—ç»Ÿè®¡ä¿¡æ¯</span>
            <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">grad</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">grad_mean</span> <span class="o">=</span> <span class="n">grad</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">grad_std</span> <span class="o">=</span> <span class="n">grad</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

            <span class="c1"># è®°å½•å†å²</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;step&#39;</span><span class="p">:</span> <span class="n">step</span><span class="p">,</span>
                <span class="s1">&#39;norm&#39;</span><span class="p">:</span> <span class="n">grad_norm</span><span class="p">,</span>
                <span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="n">grad_mean</span><span class="p">,</span>
                <span class="s1">&#39;std&#39;</span><span class="p">:</span> <span class="n">grad_std</span>
            <span class="p">})</span>

            <span class="c1"># å¼‚å¸¸æ£€æµ‹</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="n">alerts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">: NaN gradient in </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">grad_norm</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">anomaly_threshold</span><span class="p">[</span><span class="s1">&#39;max_norm&#39;</span><span class="p">]:</span>
                <span class="n">alerts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">: Large gradient norm </span><span class="si">{</span><span class="n">grad_norm</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> in </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">grad_norm</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">anomaly_threshold</span><span class="p">[</span><span class="s1">&#39;min_norm&#39;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">grad_norm</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">alerts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">: Vanishing gradient </span><span class="si">{</span><span class="n">grad_norm</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2"> in </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">alerts</span>
</code></pre></div>

<h3 id="1022">10.2.2 æ¢¯åº¦å¼‚å¸¸çš„æ ¹æºåˆ†æ</h3>
<p>ä¸åŒå±‚çš„æ¢¯åº¦å¼‚å¸¸å¾€å¾€æŒ‡å‘ä¸åŒçš„é—®é¢˜ï¼š</p>
<ol>
<li>
<p><strong>è§†è§‰ç¼–ç å™¨å±‚çš„æ¢¯åº¦çˆ†ç‚¸</strong>
   - åŸå› ï¼šå›¾åƒé¢„å¤„ç†é”™è¯¯ï¼ˆå¦‚æœªå½’ä¸€åŒ–ï¼‰
   - è§£å†³ï¼šæ£€æŸ¥å›¾åƒè¾“å…¥èŒƒå›´ï¼Œç¡®ä¿åœ¨ [-1, 1] æˆ– [0, 1]</p>
</li>
<li>
<p><strong>æŠ•å½±å±‚çš„æ¢¯åº¦æ¶ˆå¤±</strong>
   - åŸå› ï¼šç»´åº¦ä¸åŒ¹é…æˆ–åˆå§‹åŒ–ä¸å½“
   - è§£å†³ï¼šä½¿ç”¨ Xavier æˆ– Kaiming åˆå§‹åŒ–</p>
</li>
<li>
<p><strong>è¯­è¨€æ¨¡å‹å±‚çš„æ¢¯åº¦éœ‡è¡</strong>
   - åŸå› ï¼šåºåˆ—é•¿åº¦å˜åŒ–è¿‡å¤§æˆ– padding ç­–ç•¥ä¸å½“
   - è§£å†³ï¼šä½¿ç”¨åŠ¨æ€ padding å’Œæ³¨æ„åŠ› mask</p>
</li>
</ol>
<h3 id="1023">10.2.3 é«˜çº§æ¢¯åº¦åˆ†æå·¥å…·</h3>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">analyze_gradient_flow</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;åˆ†ææ¢¯åº¦åœ¨æ¨¡å‹ä¸­çš„æµåŠ¨æƒ…å†µ&quot;&quot;&quot;</span>

    <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_batch</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">compute_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># æ”¶é›†æ¯å±‚çš„æ¢¯åº¦ä¿¡æ¯</span>
    <span class="n">gradient_flow</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">grad_data</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span>
            <span class="n">gradient_flow</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;layer&#39;</span><span class="p">:</span> <span class="n">name</span><span class="p">,</span>
                <span class="s1">&#39;grad_norm&#39;</span><span class="p">:</span> <span class="n">grad_data</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                <span class="s1">&#39;grad_mean&#39;</span><span class="p">:</span> <span class="n">grad_data</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                <span class="s1">&#39;grad_max&#39;</span><span class="p">:</span> <span class="n">grad_data</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                <span class="s1">&#39;grad_min&#39;</span><span class="p">:</span> <span class="n">grad_data</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                <span class="s1">&#39;percent_zeros&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">grad_data</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="mi">100</span>
            <span class="p">})</span>

    <span class="c1"># å¯è§†åŒ–æ¢¯åº¦æµ</span>
    <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

    <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">g</span><span class="p">[</span><span class="s1">&#39;layer&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">gradient_flow</span><span class="p">]</span>
    <span class="n">grad_norms</span> <span class="o">=</span> <span class="p">[</span><span class="n">g</span><span class="p">[</span><span class="s1">&#39;grad_norm&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">gradient_flow</span><span class="p">]</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">grad_norms</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Gradient Norm&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)),</span> <span class="n">layers</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Layers&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Gradient Norm (log scale)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Gradient Flow Through Network&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">gradient_flow</span>
</code></pre></div>

<h2 id="103">10.3 æ··åˆç²¾åº¦è®­ç»ƒçš„ç¨³å®šæ€§æŠ€å·§</h2>
<h3 id="1031-fp16-vs-bf16">10.3.1 FP16 vs BF16 çš„é€‰æ‹©</h3>
<p>æ··åˆç²¾åº¦è®­ç»ƒæ˜¯æå‡è®­ç»ƒé€Ÿåº¦çš„å…³é”®ï¼Œä½†ä¹Ÿæ˜¯ç¨³å®šæ€§é—®é¢˜çš„ä¸»è¦æ¥æºï¼š</p>
<div class="codehilite"><pre><span></span><code>FP16 (åŠç²¾åº¦æµ®ç‚¹)
â”œâ”€ ä¼˜ç‚¹ï¼šç¡¬ä»¶æ”¯æŒå¹¿æ³›ï¼Œé€Ÿåº¦å¿«
â”œâ”€ ç¼ºç‚¹ï¼šæ•°å€¼èŒƒå›´å° (Â±65,504)ï¼Œå®¹æ˜“æº¢å‡º
â””â”€ é€‚ç”¨ï¼šç¨³å®šçš„æ¨¡å‹ï¼Œå……åˆ†çš„ loss scaling

BF16 (Brain Float 16)
â”œâ”€ ä¼˜ç‚¹ï¼šæ•°å€¼èŒƒå›´å¤§ (Â±3.4Ã—10^38)ï¼Œä¸FP32ç›¸åŒ
â”œâ”€ ç¼ºç‚¹ï¼šç²¾åº¦è¾ƒä½ï¼Œéœ€è¦æ–°ç¡¬ä»¶ï¼ˆA100+ï¼‰
â””â”€ é€‚ç”¨ï¼šå¤§æ¨¡å‹è®­ç»ƒï¼Œæ•°å€¼ç¨³å®šæ€§è¦æ±‚é«˜
</code></pre></div>

<h3 id="1032-loss-scaling">10.3.2 åŠ¨æ€ Loss Scaling ç­–ç•¥</h3>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">DynamicLossScaler</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;è‡ªé€‚åº”çš„ loss scalingï¼Œé˜²æ­¢æ¢¯åº¦ä¸‹æº¢/ä¸Šæº¢&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_scale</span><span class="o">=</span><span class="mi">2</span><span class="o">**</span><span class="mi">16</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> 
                 <span class="n">scale_window</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">init_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_factor</span> <span class="o">=</span> <span class="n">scale_factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_window</span> <span class="o">=</span> <span class="n">scale_window</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span> <span class="o">=</span> <span class="n">tolerance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">overflow_counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">scale_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;æ”¾å¤§lossé˜²æ­¢æ¢¯åº¦ä¸‹æº¢&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">loss</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>

    <span class="k">def</span> <span class="nf">unscale_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;ç¼©å°æ¢¯åº¦åˆ°æ­£ç¡®èŒƒå›´&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update_scale</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">overflow</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;æ ¹æ®æº¢å‡ºæƒ…å†µåŠ¨æ€è°ƒæ•´scale&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">overflow</span><span class="p">:</span>
            <span class="c1"># å‘ç”Ÿæº¢å‡ºï¼Œå‡å°scale</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_factor</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">overflow_counter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient overflow! Reducing scale to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_window</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># é•¿æ—¶é—´æ— æº¢å‡ºï¼Œå°è¯•å¢å¤§scale</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_factor</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Increasing scale to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="kc">False</span>
</code></pre></div>

<h3 id="1033">10.3.3 å…³é”®å±‚çš„ç²¾åº¦ä¿æŠ¤</h3>
<p>æŸäº›å±‚å¿…é¡»ä¿æŒ FP32 ç²¾åº¦ä»¥ç¡®ä¿ç¨³å®šæ€§ï¼š</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">configure_mixed_precision</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;é…ç½®æ··åˆç²¾åº¦è®­ç»ƒçš„å±‚çº§ç²¾åº¦&quot;&quot;&quot;</span>

    <span class="c1"># å§‹ç»ˆä¿æŒ FP32 çš„å±‚</span>
    <span class="n">fp32_layers</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;layer_norm&#39;</span><span class="p">,</span>      <span class="c1"># LayerNorm å¯¹ç²¾åº¦æ•æ„Ÿ</span>
        <span class="s1">&#39;softmax&#39;</span><span class="p">,</span>         <span class="c1"># Softmax éœ€è¦é«˜ç²¾åº¦</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">,</span>            <span class="c1"># æŸå¤±è®¡ç®—</span>
        <span class="s1">&#39;positional&#39;</span><span class="p">,</span>      <span class="c1"># ä½ç½®ç¼–ç </span>
    <span class="p">]</span>

    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
        <span class="c1"># æ£€æŸ¥æ˜¯å¦éœ€è¦FP32</span>
        <span class="n">need_fp32</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="n">fp_layer</span> <span class="ow">in</span> <span class="n">name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> 
                        <span class="k">for</span> <span class="n">fp_layer</span> <span class="ow">in</span> <span class="n">fp32_layers</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">need_fp32</span><span class="p">:</span>
            <span class="c1"># å¼ºåˆ¶ä½¿ç”¨FP32</span>
            <span class="n">module</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># å¯ä»¥ä½¿ç”¨FP16/BF16</span>
            <span class="n">module</span><span class="o">.</span><span class="n">half</span><span class="p">()</span>  <span class="c1"># or module.bfloat16()</span>

    <span class="k">return</span> <span class="n">model</span>
</code></pre></div>

<h3 id="1034">10.3.4 æ¢¯åº¦ç´¯ç§¯ä¸æ··åˆç²¾åº¦çš„äº¤äº’</h3>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">stable_gradient_accumulation</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> 
                                <span class="n">accumulation_steps</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ç¨³å®šçš„æ¢¯åº¦ç´¯ç§¯å®ç°&quot;&quot;&quot;</span>

    <span class="n">scaler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">GradScaler</span><span class="p">()</span>
    <span class="n">accumulated_loss</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_loader</span><span class="p">):</span>
        <span class="c1"># åˆ¤æ–­æ˜¯å¦æ˜¯ç´¯ç§¯çš„æœ€åä¸€æ­¥</span>
        <span class="n">is_accumulation_boundary</span> <span class="o">=</span> <span class="p">(</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">accumulation_steps</span> <span class="o">==</span> <span class="mi">0</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">():</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">])</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">compute_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>
            <span class="c1"># é‡è¦ï¼šé™¤ä»¥ç´¯ç§¯æ­¥æ•°</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">/</span> <span class="n">accumulation_steps</span>

        <span class="c1"># Scale losså¹¶åå‘ä¼ æ’­</span>
        <span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">accumulated_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">is_accumulation_boundary</span><span class="p">:</span>
            <span class="c1"># æ¢¯åº¦è£å‰ªï¼ˆåœ¨unscaleä¹‹åï¼Œstepä¹‹å‰ï¼‰</span>
            <span class="n">scaler</span><span class="o">.</span><span class="n">unscale_</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

            <span class="c1"># ä¼˜åŒ–å™¨æ­¥è¿›</span>
            <span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
            <span class="n">scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># è®°å½•</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">: Loss = </span><span class="si">{</span><span class="n">accumulated_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">accumulated_loss</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre></div>

<h2 id="104-checkpoint">10.4 Checkpoint æ¢å¤ä¸æ–­ç‚¹ç»­è®­</h2>
<h3 id="1041-checkpoint">10.4.1 å®Œæ•´çš„ Checkpoint ç³»ç»Ÿ</h3>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">CheckpointManager</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;å…¨é¢çš„æ£€æŸ¥ç‚¹ç®¡ç†å™¨&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">,</span> <span class="n">keep_last_n</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">save_interval</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_dir</span> <span class="o">=</span> <span class="n">save_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keep_last_n</span> <span class="o">=</span> <span class="n">keep_last_n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_interval</span> <span class="o">=</span> <span class="n">save_interval</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checkpoints</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> 
                       <span class="n">epoch</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">extra_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;ä¿å­˜å®Œæ•´çš„è®­ç»ƒçŠ¶æ€&quot;&quot;&quot;</span>

        <span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
            <span class="s1">&#39;step&#39;</span><span class="p">:</span> <span class="n">step</span><span class="p">,</span>
            <span class="s1">&#39;model_state_dict&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;scheduler_state_dict&#39;</span><span class="p">:</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span> <span class="k">if</span> <span class="n">scheduler</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="n">metrics</span><span class="p">,</span>
            <span class="s1">&#39;rng_state&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;python&#39;</span><span class="p">:</span> <span class="n">random</span><span class="o">.</span><span class="n">getstate</span><span class="p">(),</span>
                <span class="s1">&#39;numpy&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">get_state</span><span class="p">(),</span>
                <span class="s1">&#39;torch&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_rng_state</span><span class="p">(),</span>
                <span class="s1">&#39;cuda&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_rng_state_all</span><span class="p">(),</span>
            <span class="p">},</span>
            <span class="s1">&#39;timestamp&#39;</span><span class="p">:</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">isoformat</span><span class="p">(),</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="n">extra_state</span><span class="p">:</span>
            <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;extra_state&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">extra_state</span>

        <span class="c1"># ä¿å­˜checkpoint</span>
        <span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_dir</span><span class="p">,</span> 
            <span class="sa">f</span><span class="s1">&#39;checkpoint_step_</span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s1">.pt&#39;</span>
        <span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checkpoints</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>

        <span class="c1"># æ¸…ç†æ—§çš„checkpoints</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoints</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_last_n</span><span class="p">:</span>
            <span class="n">old_checkpoint</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoints</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">old_checkpoint</span><span class="p">):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">old_checkpoint</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">checkpoint_path</span>

    <span class="k">def</span> <span class="nf">load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                       <span class="n">scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;æ¢å¤è®­ç»ƒçŠ¶æ€&quot;&quot;&quot;</span>

        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

        <span class="c1"># æ¢å¤æ¨¡å‹</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;model_state_dict&#39;</span><span class="p">],</span> <span class="n">strict</span><span class="o">=</span><span class="n">strict</span><span class="p">)</span>

        <span class="c1"># æ¢å¤ä¼˜åŒ–å™¨</span>
        <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">and</span> <span class="s1">&#39;optimizer_state_dict&#39;</span> <span class="ow">in</span> <span class="n">checkpoint</span><span class="p">:</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">])</span>

        <span class="c1"># æ¢å¤å­¦ä¹ ç‡è°ƒåº¦å™¨</span>
        <span class="k">if</span> <span class="n">scheduler</span> <span class="ow">and</span> <span class="s1">&#39;scheduler_state_dict&#39;</span> <span class="ow">in</span> <span class="n">checkpoint</span><span class="p">:</span>
            <span class="n">scheduler</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;scheduler_state_dict&#39;</span><span class="p">])</span>

        <span class="c1"># æ¢å¤éšæœºæ•°çŠ¶æ€</span>
        <span class="k">if</span> <span class="s1">&#39;rng_state&#39;</span> <span class="ow">in</span> <span class="n">checkpoint</span><span class="p">:</span>
            <span class="n">random</span><span class="o">.</span><span class="n">setstate</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;rng_state&#39;</span><span class="p">][</span><span class="s1">&#39;python&#39;</span><span class="p">])</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;rng_state&#39;</span><span class="p">][</span><span class="s1">&#39;numpy&#39;</span><span class="p">])</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">set_rng_state</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;rng_state&#39;</span><span class="p">][</span><span class="s1">&#39;torch&#39;</span><span class="p">])</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_rng_state_all</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;rng_state&#39;</span><span class="p">][</span><span class="s1">&#39;cuda&#39;</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">checkpoint</span>
</code></pre></div>

<h3 id="1042">10.4.2 æ–­ç‚¹ç»­è®­çš„æœ€ä½³å®è·µ</h3>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">resume_training</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;å®‰å…¨çš„æ–­ç‚¹ç»­è®­æµç¨‹&quot;&quot;&quot;</span>

    <span class="c1"># 1. åŠ è½½checkpoint</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;model_state_dict&#39;</span><span class="p">])</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">])</span>

    <span class="c1"># 2. æ¢å¤åˆ°æ­£ç¡®çš„æ•°æ®ä½ç½®</span>
    <span class="n">start_epoch</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span>
    <span class="n">start_step</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">]</span>

    <span class="c1"># 3. éªŒè¯æ¢å¤æ˜¯å¦æˆåŠŸ</span>
    <span class="n">validation_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data_loader</span><span class="p">))</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">validation_batch</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">])</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">compute_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">validation_batch</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Validation loss after resume: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># 4. æ£€æŸ¥æ˜¯å¦éœ€è¦é™çº§é…ç½®</span>
    <span class="k">if</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;crashed&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Previous training crashed. Applying conservative settings...&quot;</span><span class="p">)</span>
        <span class="c1"># é™ä½å­¦ä¹ ç‡</span>
        <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">param_group</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">*=</span> <span class="mf">0.5</span>
        <span class="c1"># å¢å¼ºæ¢¯åº¦è£å‰ª</span>
        <span class="n">max_grad_norm</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">max_grad_norm</span> <span class="o">=</span> <span class="mf">1.0</span>

    <span class="k">return</span> <span class="n">start_epoch</span><span class="p">,</span> <span class="n">start_step</span><span class="p">,</span> <span class="n">max_grad_norm</span>
</code></pre></div>

<h3 id="1043">10.4.3 å´©æºƒæ¢å¤ç­–ç•¥</h3>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">CrashRecoveryTrainer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;å…·æœ‰å´©æºƒæ¢å¤èƒ½åŠ›çš„è®­ç»ƒå™¨&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">crash_counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_crashes</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="k">def</span> <span class="nf">train_with_recovery</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;å¸¦è‡ªåŠ¨æ¢å¤çš„è®­ç»ƒå¾ªç¯&quot;&quot;&quot;</span>

        <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">crash_counter</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_crashes</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># æ­£å¸¸è®­ç»ƒ</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_train_epoch</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">crash_counter</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># é‡ç½®è®¡æ•°å™¨</span>

            <span class="k">except</span> <span class="p">(</span><span class="ne">RuntimeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">crash_counter</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training crashed (attempt </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">crash_counter</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_crashes</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># å´©æºƒæ¢å¤ç­–ç•¥</span>
                <span class="n">recovery_actions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_recovery_strategy</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">recovery_actions</span><span class="p">:</span>
                    <span class="n">action</span><span class="p">()</span>

                <span class="c1"># ä»æœ€è¿‘çš„checkpointæ¢å¤</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_checkpoint</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">last_checkpoint</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No checkpoint available, restarting training...&quot;</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_reinitialize_training</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_get_recovery_strategy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">error</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;æ ¹æ®é”™è¯¯ç±»å‹ç¡®å®šæ¢å¤ç­–ç•¥&quot;&quot;&quot;</span>

        <span class="n">strategies</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="s2">&quot;CUDA out of memory&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">error</span><span class="p">):</span>
            <span class="n">strategies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_reduce_batch_size</span><span class="p">)</span>
            <span class="n">strategies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_enable_gradient_checkpointing</span><span class="p">)</span>

        <span class="k">elif</span> <span class="s2">&quot;nan&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">error</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
            <span class="n">strategies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_reduce_learning_rate</span><span class="p">)</span>
            <span class="n">strategies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_reset_optimizer_state</span><span class="p">)</span>
            <span class="n">strategies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_switch_to_fp32</span><span class="p">)</span>

        <span class="k">elif</span> <span class="s2">&quot;gradient&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">error</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
            <span class="n">strategies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_enhance_gradient_clipping</span><span class="p">)</span>
            <span class="n">strategies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_reduce_accumulation_steps</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">strategies</span>
</code></pre></div>

<h2 id="_1">æœ¬ç« å°ç»“</h2>
<p>åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬ç³»ç»Ÿå­¦ä¹ äº† VLM è®­ç»ƒä¸­å´©æºƒå’Œ NaN é—®é¢˜çš„è¯Šæ–­ä¸è§£å†³æ–¹æ³•ï¼š</p>
<h3 id="_2">æ ¸å¿ƒçŸ¥è¯†ç‚¹</h3>
<ol>
<li>
<p><strong>5åˆ†é’Ÿå¿«é€Ÿè¯Šæ–­æµç¨‹</strong>
   - ä¿å­˜ç°åœº â†’ åˆ†æLossæ¨¡å¼ â†’ å®šä½é—®é¢˜å±‚ â†’ æ£€æŸ¥å…³é”®æ•°å€¼ â†’ ç´§æ€¥å¤„ç†
   - ä¸‰ç§å…¸å‹çš„ Loss çˆ†ç‚¸æ¨¡å¼ï¼šçªç„¶è·³è·ƒã€æŒ‡æ•°å¢é•¿ã€éœ‡è¡å‘æ•£
   - ä¸åŒæ¨¡å¼å¯¹åº”ä¸åŒçš„æ ¹æœ¬åŸå› å’Œè§£å†³æ–¹æ¡ˆ</p>
</li>
<li>
<p><strong>æ¢¯åº¦ç›‘æ§ä½“ç³»</strong>
   - å®æ—¶æ¢¯åº¦ç»Ÿè®¡ï¼šèŒƒæ•°ã€å‡å€¼ã€æ ‡å‡†å·®ã€é›¶å€¼æ¯”ä¾‹
   - å±‚çº§æ¢¯åº¦åˆ†æï¼šè§†è§‰ç¼–ç å™¨ã€æŠ•å½±å±‚ã€è¯­è¨€æ¨¡å‹çš„ç‰¹å¾
   - æ¢¯åº¦æµå¯è§†åŒ–ï¼šå¿«é€Ÿå®šä½æ¢¯åº¦æ¶ˆå¤±æˆ–çˆ†ç‚¸çš„ä½ç½®</p>
</li>
<li>
<p><strong>æ··åˆç²¾åº¦è®­ç»ƒç¨³å®šæ€§</strong>
   - FP16 vs BF16 çš„æƒè¡¡ï¼šæ•°å€¼èŒƒå›´ vs ç²¾åº¦
   - åŠ¨æ€ Loss Scalingï¼šè‡ªé€‚åº”è°ƒæ•´é˜²æ­¢æº¢å‡º
   - å…³é”®å±‚ç²¾åº¦ä¿æŠ¤ï¼šLayerNormã€Softmax å¿…é¡» FP32
   - æ¢¯åº¦ç´¯ç§¯çš„æ­£ç¡®å®ç°ï¼šé˜²æ­¢ç²¾åº¦æŸå¤±ç´¯ç§¯</p>
</li>
<li>
<p><strong>Checkpoint ä¸å®¹é”™æœºåˆ¶</strong>
   - å®Œæ•´çŠ¶æ€ä¿å­˜ï¼šæ¨¡å‹ã€ä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨ã€éšæœºæ•°ç§å­
   - æ™ºèƒ½æ¢å¤ç­–ç•¥ï¼šæ ¹æ®å´©æºƒç±»å‹è‡ªåŠ¨è°ƒæ•´é…ç½®
   - å´©æºƒè®¡æ•°å™¨ï¼šé¿å…æ— é™å¾ªç¯ï¼Œè®¾ç½®æœ€å¤§é‡è¯•æ¬¡æ•°</p>
</li>
</ol>
<h3 id="_3">å…³é”®å…¬å¼</h3>
<ol>
<li>
<p><strong>æ¢¯åº¦èŒƒæ•°è®¡ç®—</strong>ï¼š
   $$|\nabla|_2 = \sqrt{\sum_{i} g_i^2}$$</p>
</li>
<li>
<p><strong>Loss Scaling åŸç†</strong>ï¼š
$$\nabla_{\text{scaled}} = \text{scale} \times \nabla_{\text{original}}$$
   $$\nabla_{\text{final}} = \nabla_{\text{scaled}} / \text{scale}$$</p>
</li>
<li>
<p><strong>æ¢¯åº¦è£å‰ª</strong>ï¼š
$$\nabla_{\text{clipped}} = \begin{cases}
   \nabla &amp; \text{if } |\nabla| \leq \text{max_norm} \\
   \nabla \times \frac{\text{max_norm}}{|\nabla|} &amp; \text{otherwise}
   \end{cases}$$</p>
</li>
<li>
<p><strong>æ•°å€¼ç¨³å®šçš„ Softmax</strong>ï¼š
$$\text{softmax}(x_i) = \frac{e^{x_i - \max(x)}}{\sum_j e^{x_j - \max(x)}}$$</p>
</li>
</ol>
<h2 id="_4">ç»ƒä¹ é¢˜</h2>
<h3 id="_5">åŸºç¡€é¢˜</h3>
<p><strong>ç»ƒä¹  10.1ï¼šLoss æ¨¡å¼è¯†åˆ«</strong>
ç»™å®šä»¥ä¸‹ Loss åºåˆ—ï¼Œåˆ¤æ–­å±äºå“ªç§çˆ†ç‚¸æ¨¡å¼å¹¶åˆ†æå¯èƒ½çš„åŸå› ï¼š</p>
<div class="codehilite"><pre><span></span><code><span class="err">åºåˆ—</span><span class="n">A</span><span class="o">:</span><span class="w"> </span><span class="mf">1.8</span><span class="o">,</span><span class="w"> </span><span class="mf">1.7</span><span class="o">,</span><span class="w"> </span><span class="mf">1.6</span><span class="o">,</span><span class="w"> </span><span class="mf">1.5</span><span class="o">,</span><span class="w"> </span><span class="mf">1.4</span><span class="o">,</span><span class="w"> </span><span class="mf">87234.5</span><span class="o">,</span><span class="w"> </span><span class="kc">NaN</span>
<span class="err">åºåˆ—</span><span class="n">B</span><span class="o">:</span><span class="w"> </span><span class="mf">2.1</span><span class="o">,</span><span class="w"> </span><span class="mf">2.2</span><span class="o">,</span><span class="w"> </span><span class="mf">2.5</span><span class="o">,</span><span class="w"> </span><span class="mf">3.1</span><span class="o">,</span><span class="w"> </span><span class="mf">4.8</span><span class="o">,</span><span class="w"> </span><span class="mf">9.2</span><span class="o">,</span><span class="w"> </span><span class="mf">23.5</span><span class="o">,</span><span class="w"> </span><span class="mf">156.7</span><span class="o">,</span><span class="w"> </span><span class="kc">NaN</span>
<span class="err">åºåˆ—</span><span class="n">C</span><span class="o">:</span><span class="w"> </span><span class="mf">2.0</span><span class="o">,</span><span class="w"> </span><span class="mf">1.8</span><span class="o">,</span><span class="w"> </span><span class="mf">2.2</span><span class="o">,</span><span class="w"> </span><span class="mf">1.6</span><span class="o">,</span><span class="w"> </span><span class="mf">2.5</span><span class="o">,</span><span class="w"> </span><span class="mf">1.4</span><span class="o">,</span><span class="w"> </span><span class="mf">3.2</span><span class="o">,</span><span class="w"> </span><span class="mf">1.2</span><span class="o">,</span><span class="w"> </span><span class="mf">5.8</span><span class="o">,</span><span class="w"> </span><span class="kc">NaN</span>
</code></pre></div>

<p>ğŸ’¡ <strong>æç¤º</strong>ï¼šå›é¡¾10.1.2èŠ‚çš„ä¸‰ç§æ¨¡å¼ç‰¹å¾</p>
<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>
<ul>
<li><strong>åºåˆ—A</strong>ï¼šçªç„¶è·³è·ƒæ¨¡å¼ã€‚Lossä»1.4ç›´æ¥è·³åˆ°87234.5ï¼Œè¡¨æ˜é‡åˆ°äº†å¼‚å¸¸æ ·æœ¬æˆ–æ•°å€¼æº¢å‡ºã€‚å¯èƒ½åŸå› ï¼š</li>
<li>æ•°æ®é›†ä¸­å­˜åœ¨å¼‚å¸¸æ ·æœ¬ï¼ˆå¦‚æ ‡ç­¾é”™è¯¯ï¼‰</li>
<li>é™¤é›¶é”™è¯¯æˆ–log(0)æ“ä½œ</li>
<li>
<p>æ³¨æ„åŠ›è®¡ç®—ä¸­çš„æ•°å€¼æº¢å‡º</p>
</li>
<li>
<p><strong>åºåˆ—B</strong>ï¼šæŒ‡æ•°å¢é•¿æ¨¡å¼ã€‚Losså‘ˆæŒ‡æ•°çº§å¢é•¿ï¼Œæ¯æ­¥å¤§çº¦ç¿»å€ã€‚å¯èƒ½åŸå› ï¼š</p>
</li>
<li>å­¦ä¹ ç‡è¿‡å¤§å¯¼è‡´å‚æ•°æ›´æ–°è¿‡æ¿€</li>
<li>æ¢¯åº¦ç´¯ç§¯å®ç°é”™è¯¯ï¼ˆå¿˜è®°é™¤ä»¥ç´¯ç§¯æ­¥æ•°ï¼‰</li>
<li>
<p>ä¼˜åŒ–å™¨momentumè®¾ç½®ä¸å½“</p>
</li>
<li>
<p><strong>åºåˆ—C</strong>ï¼šéœ‡è¡å‘æ•£æ¨¡å¼ã€‚Lossåœ¨ä¸‹é™å’Œä¸Šå‡ä¹‹é—´éœ‡è¡ï¼ŒæŒ¯å¹…é€æ¸å¢å¤§ã€‚å¯èƒ½åŸå› ï¼š</p>
</li>
<li>ä¼˜åŒ–å™¨çŠ¶æ€æŸåï¼ˆå¦‚Adamçš„äºŒé˜¶çŸ©ä¼°è®¡ï¼‰</li>
<li>æ‰¹æ¬¡é—´æ•°æ®åˆ†å¸ƒå·®å¼‚è¿‡å¤§</li>
<li>å­¦ä¹ ç‡è°ƒåº¦å™¨é…ç½®é”™è¯¯</li>
</ul>
</details>
<p><strong>ç»ƒä¹  10.2ï¼šæ¢¯åº¦è£å‰ªé˜ˆå€¼é€‰æ‹©</strong>
ä½ çš„æ¨¡å‹æ­£å¸¸è®­ç»ƒæ—¶æ¢¯åº¦èŒƒæ•°åœ¨ 0.5-2.0 ä¹‹é—´ï¼Œå¶å°”ä¼šè¾¾åˆ° 10-20ã€‚åº”è¯¥å¦‚ä½•è®¾ç½®æ¢¯åº¦è£å‰ªçš„é˜ˆå€¼ï¼Ÿå¦‚æœè®¾ç½®ä¸º 1.0 ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿè®¾ç½®ä¸º 100 å‘¢ï¼Ÿ</p>
<p>ğŸ’¡ <strong>æç¤º</strong>ï¼šè€ƒè™‘æ¢¯åº¦è£å‰ªå¯¹æ”¶æ•›é€Ÿåº¦å’Œç¨³å®šæ€§çš„å½±å“</p>
<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>
<p>åˆç†çš„æ¢¯åº¦è£å‰ªé˜ˆå€¼åº”è¯¥è®¾ç½®ä¸º <strong>5.0-10.0</strong>ï¼ŒåŸå› å¦‚ä¸‹ï¼š</p>
<ul>
<li><strong>è®¾ç½®ä¸º 1.0 çš„é—®é¢˜</strong>ï¼š</li>
<li>ä¼šé¢‘ç¹è§¦å‘è£å‰ªï¼ˆæ­£å¸¸æ¢¯åº¦å°±æœ‰2.0ï¼‰</li>
<li>äººä¸ºé™åˆ¶äº†æ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›</li>
<li>å¯èƒ½å¯¼è‡´æ”¶æ•›å˜æ…¢æˆ–æ— æ³•æ”¶æ•›åˆ°æœ€ä¼˜è§£</li>
<li>
<p>ç›¸å½“äºå¼ºåˆ¶é™ä½äº†æœ‰æ•ˆå­¦ä¹ ç‡</p>
</li>
<li>
<p><strong>è®¾ç½®ä¸º 100 çš„é—®é¢˜</strong>ï¼š</p>
</li>
<li>åŸºæœ¬ä¸ä¼šè§¦å‘ï¼ˆæ­£å¸¸æœ€å¤§å€¼æ‰20ï¼‰</li>
<li>å¤±å»äº†é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸çš„ä¿æŠ¤ä½œç”¨</li>
<li>
<p>å½“çœŸæ­£å‡ºç°å¼‚å¸¸æ—¶æ— æ³•åŠæ—¶é˜»æ­¢</p>
</li>
<li>
<p><strong>æ¨èç­–ç•¥</strong>ï¼š
  1. åˆå§‹è®¾ç½®ä¸ºæ­£å¸¸æœ€å¤§å€¼çš„ 2-3 å€ï¼ˆå¦‚ 5.0ï¼‰
  2. ç›‘æ§è£å‰ªé¢‘ç‡ï¼Œå¦‚æœé¢‘ç¹è§¦å‘åˆ™é€‚å½“æé«˜
  3. å¯¹ä¸åŒå±‚ä½¿ç”¨ä¸åŒé˜ˆå€¼ï¼ˆè§†è§‰ç¼–ç å™¨å¯ä»¥æ›´å¤§ï¼‰</p>
</li>
</ul>
</details>
<p><strong>ç»ƒä¹  10.3ï¼šæ··åˆç²¾åº¦æ•°å€¼èŒƒå›´</strong>
è®¡ç®—å¹¶æ¯”è¾ƒ FP16 å’Œ BF16 èƒ½è¡¨ç¤ºçš„æœ€å¤§æœ€å°æ­£æ•°ã€‚ä¸ºä»€ä¹ˆ BF16 æ›´ä¸å®¹æ˜“å‡ºç°æ¢¯åº¦ä¸‹æº¢ï¼Ÿ</p>
<p>ğŸ’¡ <strong>æç¤º</strong>ï¼šæŸ¥é˜… IEEE 754 æ ‡å‡†ä¸­çš„æµ®ç‚¹æ•°æ ¼å¼å®šä¹‰</p>
<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>
<p><strong>FP16ï¼ˆåŠç²¾åº¦ï¼‰</strong>ï¼š</p>
<ul>
<li>æ ¼å¼ï¼š1ä½ç¬¦å· + 5ä½æŒ‡æ•° + 10ä½å°¾æ•°</li>
<li>æœ€å¤§å€¼ï¼š65,504</li>
<li>æœ€å°æ­£è§„å€¼ï¼š6.10 Ã— 10^-5</li>
<li>æœ€å°éæ­£è§„å€¼ï¼š5.96 Ã— 10^-8</li>
</ul>
<p><strong>BF16ï¼ˆBrain Float 16ï¼‰</strong>ï¼š</p>
<ul>
<li>æ ¼å¼ï¼š1ä½ç¬¦å· + 8ä½æŒ‡æ•° + 7ä½å°¾æ•°</li>
<li>æœ€å¤§å€¼ï¼š3.39 Ã— 10^38ï¼ˆä¸FP32ç›¸åŒï¼‰</li>
<li>æœ€å°æ­£è§„å€¼ï¼š1.18 Ã— 10^-38</li>
<li>æœ€å°éæ­£è§„å€¼ï¼š9.18 Ã— 10^-41</li>
</ul>
<p><strong>BF16 ä¸æ˜“æ¢¯åº¦ä¸‹æº¢çš„åŸå› </strong>ï¼š</p>
<ol>
<li>æŒ‡æ•°ä½æ•°å¤šï¼ˆ8ä½ vs 5ä½ï¼‰ï¼Œæ•°å€¼èŒƒå›´å¤§</li>
<li>å¯ä»¥è¡¨ç¤ºæå°çš„æ¢¯åº¦å€¼è€Œä¸ä¼šç›´æ¥å˜ä¸º0</li>
<li>ä¸FP32çš„æ•°å€¼èŒƒå›´ä¸€è‡´ï¼Œè½¬æ¢æ—¶ä¸ä¼šæº¢å‡º</li>
<li>ä»£ä»·æ˜¯å°¾æ•°ç²¾åº¦é™ä½ï¼ˆ7ä½ vs 10ä½ï¼‰ï¼Œä½†æ·±åº¦å­¦ä¹ ä¸­é€šå¸¸å¯æ¥å—</li>
</ol>
</details>
<h3 id="_6">æŒ‘æˆ˜é¢˜</h3>
<p><strong>ç»ƒä¹  10.4ï¼šè®¾è®¡è‡ªé€‚åº”æ¢¯åº¦è£å‰ªç®—æ³•</strong>
æ ‡å‡†çš„æ¢¯åº¦è£å‰ªä½¿ç”¨å›ºå®šé˜ˆå€¼ï¼Œè¯·è®¾è®¡ä¸€ä¸ªè‡ªé€‚åº”ç®—æ³•ï¼Œæ ¹æ®å†å²æ¢¯åº¦ç»Ÿè®¡åŠ¨æ€è°ƒæ•´è£å‰ªé˜ˆå€¼ã€‚è¦æ±‚ï¼š</p>
<ol>
<li>èƒ½å¤Ÿé€‚åº”è®­ç»ƒè¿‡ç¨‹ä¸­æ¢¯åº¦èŒƒæ•°çš„è‡ªç„¶å˜åŒ–</li>
<li>ä»ç„¶èƒ½å¤Ÿæ£€æµ‹å’Œå¤„ç†å¼‚å¸¸å€¼</li>
<li>ç»™å‡ºä¼ªä»£ç å®ç°</li>
</ol>
<p>ğŸ’¡ <strong>æç¤º</strong>ï¼šå¯ä»¥ä½¿ç”¨ç§»åŠ¨å¹³å‡å’Œæ ‡å‡†å·®</p>
<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">AdaptiveGradientClipper</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">percentile</span><span class="o">=</span><span class="mf">99.5</span><span class="p">,</span> <span class="n">history_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> 
                 <span class="n">min_threshold</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">max_threshold</span><span class="o">=</span><span class="mf">100.0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">percentile</span> <span class="o">=</span> <span class="n">percentile</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">history_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_threshold</span> <span class="o">=</span> <span class="n">min_threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_threshold</span> <span class="o">=</span> <span class="n">max_threshold</span>

    <span class="k">def</span> <span class="nf">compute_threshold</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">100</span><span class="p">:</span>  <span class="c1"># åˆå§‹é˜¶æ®µä½¿ç”¨å›ºå®šå€¼</span>
            <span class="k">return</span> <span class="mf">10.0</span>

        <span class="c1"># æ–¹æ³•1ï¼šåŸºäºç™¾åˆ†ä½æ•°</span>
        <span class="n">threshold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">percentile</span><span class="p">)</span>

        <span class="c1"># æ–¹æ³•2ï¼šåŸºäºå‡å€¼å’Œæ ‡å‡†å·®ï¼ˆ3-sigmaè§„åˆ™ï¼‰</span>
        <span class="c1"># mean = np.mean(self.history)</span>
        <span class="c1"># std = np.std(self.history)</span>
        <span class="c1"># threshold = mean + 3 * std</span>

        <span class="c1"># é™åˆ¶åœ¨åˆç†èŒƒå›´å†…</span>
        <span class="n">threshold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_threshold</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_threshold</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">threshold</span>

    <span class="k">def</span> <span class="nf">clip_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="c1"># è®¡ç®—å½“å‰æ¢¯åº¦èŒƒæ•°</span>
        <span class="n">total_norm</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">total_norm</span> <span class="o">+=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">total_norm</span> <span class="o">=</span> <span class="n">total_norm</span> <span class="o">**</span> <span class="mf">0.5</span>

        <span class="c1"># æ›´æ–°å†å²</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_norm</span><span class="p">)</span>

        <span class="c1"># è®¡ç®—è‡ªé€‚åº”é˜ˆå€¼</span>
        <span class="n">clip_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_threshold</span><span class="p">()</span>

        <span class="c1"># æ‰§è¡Œè£å‰ª</span>
        <span class="k">if</span> <span class="n">total_norm</span> <span class="o">&gt;</span> <span class="n">clip_value</span><span class="p">:</span>
            <span class="n">clip_coef</span> <span class="o">=</span> <span class="n">clip_value</span> <span class="o">/</span> <span class="p">(</span><span class="n">total_norm</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">clip_coef</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">True</span><span class="p">,</span> <span class="n">clip_value</span>

        <span class="k">return</span> <span class="kc">False</span><span class="p">,</span> <span class="n">clip_value</span>
</code></pre></div>

<p><strong>ä¼˜åŠ¿</strong>ï¼š</p>
<ol>
<li>è‡ªåŠ¨é€‚åº”ä¸åŒè®­ç»ƒé˜¶æ®µçš„æ¢¯åº¦èŒƒå›´</li>
<li>é¿å…å›ºå®šé˜ˆå€¼è¿‡æ¾æˆ–è¿‡ç´§</li>
<li>åŸºäºç»Ÿè®¡çš„å¼‚å¸¸æ£€æµ‹æ›´é²æ£’</li>
</ol>
</details>
<p><strong>ç»ƒä¹  10.5ï¼šå®ç°æ¢¯åº¦å¼‚å¸¸å®šä½å™¨</strong>
è®¾è®¡ä¸€ä¸ªå·¥å…·ï¼Œå½“æ£€æµ‹åˆ° NaN æ¢¯åº¦æ—¶ï¼Œèƒ½å¤Ÿå¿«é€Ÿå®šä½æ˜¯å“ªä¸ªæ“ä½œäº§ç”Ÿçš„ NaNï¼Œå¹¶ç»™å‡ºå¯èƒ½çš„åŸå› ã€‚è€ƒè™‘ VLM ä¸­çš„ç‰¹æ®Šæƒ…å†µã€‚</p>
<p>ğŸ’¡ <strong>æç¤º</strong>ï¼šä½¿ç”¨ PyTorch çš„ autograd å¼‚å¸¸æ£€æµ‹æ¨¡å¼</p>
<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">NaNGradientLocator</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">forward_hooks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backward_hooks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">problematic_layers</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">enable_detection</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;å¯ç”¨NaNæ£€æµ‹&quot;&quot;&quot;</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">set_detect_anomaly</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># æ³¨å†Œå‰å‘é’©å­</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
            <span class="n">handle</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">register_forward_hook</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_make_forward_hook</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">forward_hooks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>

            <span class="c1"># æ³¨å†Œåå‘é’©å­</span>
            <span class="n">handle</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">register_backward_hook</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_make_backward_hook</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">backward_hooks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_make_forward_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_name</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
            <span class="c1"># æ£€æŸ¥è¾“å…¥</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">inp</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">problematic_layers</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                        <span class="s1">&#39;layer&#39;</span><span class="p">:</span> <span class="n">layer_name</span><span class="p">,</span>
                        <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;forward_input&#39;</span><span class="p">,</span>
                        <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span>
                        <span class="s1">&#39;stage&#39;</span><span class="p">:</span> <span class="s1">&#39;forward&#39;</span>
                    <span class="p">})</span>

            <span class="c1"># æ£€æŸ¥è¾“å‡º</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="c1"># VLMç‰¹æ®Šæ£€æŸ¥</span>
                <span class="k">if</span> <span class="s1">&#39;attention&#39;</span> <span class="ow">in</span> <span class="n">layer_name</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                    <span class="c1"># æ£€æŸ¥æ³¨æ„åŠ›åˆ†æ•°</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NaN in attention layer </span><span class="si">{</span><span class="n">layer_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;å¯èƒ½åŸå› ï¼š1) åºåˆ—é•¿åº¦è¿‡é•¿å¯¼è‡´æ•°å€¼æº¢å‡º&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;         2) æ³¨æ„åŠ›maskè®¾ç½®é”™è¯¯&quot;</span><span class="p">)</span>

                <span class="k">elif</span> <span class="s1">&#39;vision&#39;</span> <span class="ow">in</span> <span class="n">layer_name</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NaN in vision layer </span><span class="si">{</span><span class="n">layer_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;å¯èƒ½åŸå› ï¼š1) å›¾åƒæœªå½’ä¸€åŒ–&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;         2) å›¾åƒåŒ…å«å¼‚å¸¸å€¼ï¼ˆå…¨é»‘/å…¨ç™½ï¼‰&quot;</span><span class="p">)</span>

                <span class="k">elif</span> <span class="s1">&#39;proj&#39;</span> <span class="ow">in</span> <span class="n">layer_name</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NaN in projection layer </span><span class="si">{</span><span class="n">layer_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;å¯èƒ½åŸå› ï¼š1) ç»´åº¦ä¸åŒ¹é…&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;         2) åˆå§‹åŒ–ä¸å½“&quot;</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">problematic_layers</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                    <span class="s1">&#39;layer&#39;</span><span class="p">:</span> <span class="n">layer_name</span><span class="p">,</span>
                    <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;forward_output&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;stage&#39;</span><span class="p">:</span> <span class="s1">&#39;forward&#39;</span>
                <span class="p">})</span>
        <span class="k">return</span> <span class="n">hook</span>

    <span class="k">def</span> <span class="nf">_make_backward_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_name</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
            <span class="c1"># æ£€æŸ¥æ¢¯åº¦è¾“å‡º</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">grad</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">grad_output</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">problematic_layers</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                        <span class="s1">&#39;layer&#39;</span><span class="p">:</span> <span class="n">layer_name</span><span class="p">,</span>
                        <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;grad_output&#39;</span><span class="p">,</span>
                        <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span>
                        <span class="s1">&#39;stage&#39;</span><span class="p">:</span> <span class="s1">&#39;backward&#39;</span>
                    <span class="p">})</span>

                    <span class="c1"># åˆ†æå…·ä½“åŸå› </span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_analyze_nan_cause</span><span class="p">(</span><span class="n">layer_name</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">grad</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hook</span>

    <span class="k">def</span> <span class="nf">_analyze_nan_cause</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_name</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">grad</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;åˆ†æNaNçš„å…·ä½“åŸå› &quot;&quot;&quot;</span>

        <span class="c1"># æ£€æŸ¥å¸¸è§æ“ä½œ</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LayerNorm </span><span class="si">{</span><span class="n">layer_name</span><span class="si">}</span><span class="s2">: æ£€æŸ¥è¾“å…¥æ–¹å·®æ˜¯å¦ä¸º0&quot;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Softmax </span><span class="si">{</span><span class="n">layer_name</span><span class="si">}</span><span class="s2">: æ£€æŸ¥æ˜¯å¦æœ‰-infè¾“å…¥å¯¼è‡´exp(x)=0&quot;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="s1">&#39;loss&#39;</span> <span class="ow">in</span> <span class="n">layer_name</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loss layer </span><span class="si">{</span><span class="n">layer_name</span><span class="si">}</span><span class="s2">: æ£€æŸ¥log(0)æˆ–é™¤é›¶&quot;</span><span class="p">)</span>

        <span class="c1"># ç»™å‡ºä¿®å¤å»ºè®®</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">å»ºè®®ä¿®å¤æ–¹æ¡ˆ:&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;1. æ·»åŠ epsilon: x + 1e-8&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;2. ä½¿ç”¨torch.clampé™åˆ¶èŒƒå›´&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;3. æ£€æŸ¥æ•°æ®é¢„å¤„ç†æµç¨‹&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;4. é™ä½å­¦ä¹ ç‡æˆ–ä½¿ç”¨æ¢¯åº¦è£å‰ª&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_report</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">problematic_layers</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;æœªæ£€æµ‹åˆ°NaN&quot;</span>

        <span class="n">report</span> <span class="o">=</span> <span class="s2">&quot;NaNæ¢¯åº¦è¯Šæ–­æŠ¥å‘Š</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">50</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># æŒ‰å‡ºç°é¡ºåºæ’åº</span>
        <span class="k">for</span> <span class="n">issue</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">problematic_layers</span><span class="p">:</span>
            <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">å±‚: </span><span class="si">{</span><span class="n">issue</span><span class="p">[</span><span class="s1">&#39;layer&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;ç±»å‹: </span><span class="si">{</span><span class="n">issue</span><span class="p">[</span><span class="s1">&#39;type&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;é˜¶æ®µ: </span><span class="si">{</span><span class="n">issue</span><span class="p">[</span><span class="s1">&#39;stage&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">report</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">30</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># ç»™å‡ºæœ€å¯èƒ½çš„æ ¹å› </span>
        <span class="n">first_issue</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">problematic_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">report</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">æœ€å¯èƒ½çš„æ ¹å› : </span><span class="si">{</span><span class="n">first_issue</span><span class="p">[</span><span class="s1">&#39;layer&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">å±‚çš„</span><span class="si">{</span><span class="n">first_issue</span><span class="p">[</span><span class="s1">&#39;type&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="k">return</span> <span class="n">report</span>
</code></pre></div>

<p>è¿™ä¸ªå·¥å…·èƒ½å¤Ÿï¼š</p>
<ol>
<li>ç²¾ç¡®å®šä½äº§ç”ŸNaNçš„å±‚å’Œæ“ä½œ</li>
<li>åŒºåˆ†å‰å‘å’Œåå‘ä¼ æ’­ä¸­çš„NaN</li>
<li>é’ˆå¯¹VLMç‰¹æœ‰ç»„ä»¶ç»™å‡ºè¯Šæ–­</li>
<li>æä¾›å…·ä½“çš„ä¿®å¤å»ºè®®</li>
</ol>
</details>
<p><strong>ç»ƒä¹  10.6ï¼šå´©æºƒé¢„æµ‹ç³»ç»Ÿ</strong>
è®¾è®¡ä¸€ä¸ªç³»ç»Ÿï¼Œèƒ½å¤Ÿåœ¨è®­ç»ƒçœŸæ­£å´©æºƒå‰ 10-20 æ­¥é¢„æµ‹å³å°†å‘ç”Ÿçš„å´©æºƒï¼Œå¹¶è‡ªåŠ¨é‡‡å–é¢„é˜²æªæ–½ã€‚</p>
<p>ğŸ’¡ <strong>æç¤º</strong>ï¼šç›‘æ§å¤šä¸ªæŒ‡æ ‡çš„è¶‹åŠ¿å˜åŒ–</p>
<details>
<summary>ğŸ“ å‚è€ƒç­”æ¡ˆ</summary>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">CrashPredictor</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">alert_threshold</span><span class="o">=</span><span class="mf">0.8</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="n">window_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alert_threshold</span> <span class="o">=</span> <span class="n">alert_threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">window_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">crash_probability</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">update_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">grad_norm</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;æ›´æ–°ç›‘æ§æŒ‡æ ‡&quot;&quot;&quot;</span>

        <span class="c1"># è®°å½•åŸå§‹æŒ‡æ ‡</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;grad_norm&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">grad_norm</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span>

        <span class="c1"># è®¡ç®—å¯¼æ•°æŒ‡æ ‡</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">loss_delta</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;loss_delta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_delta</span><span class="p">)</span>

            <span class="c1"># äºŒé˜¶å¯¼æ•°ï¼ˆåŠ é€Ÿåº¦ï¼‰</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;loss_delta&#39;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">loss_accel</span> <span class="o">=</span> <span class="n">loss_delta</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;loss_delta&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;loss_accel&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_accel</span><span class="p">)</span>

        <span class="c1"># é¢„æµ‹å´©æºƒæ¦‚ç‡</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">crash_probability</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_crash</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">crash_probability</span>

    <span class="k">def</span> <span class="nf">_predict_crash</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;åŸºäºå¤šä¸ªä¿¡å·é¢„æµ‹å´©æºƒæ¦‚ç‡&quot;&quot;&quot;</span>

        <span class="n">signals</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># ä¿¡å·1ï¼šLossè¿ç»­å¢é•¿</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">recent_losses</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])[</span><span class="o">-</span><span class="mi">3</span><span class="p">:]</span>
            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">recent_losses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">recent_losses</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> 
                   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">recent_losses</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)):</span>
                <span class="n">signals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span>

        <span class="c1"># ä¿¡å·2ï¼šLosså¢é•¿åŠ é€Ÿ</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;loss_accel&#39;</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">recent_accel</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;loss_accel&#39;</span><span class="p">])[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span>
            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">a</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.1</span> 
                   <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">recent_accel</span><span class="p">):</span>
                <span class="n">signals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)</span>

        <span class="c1"># ä¿¡å·3ï¼šæ¢¯åº¦èŒƒæ•°æŒ‡æ•°å¢é•¿</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;grad_norm&#39;</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">recent_grads</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;grad_norm&#39;</span><span class="p">])[</span><span class="o">-</span><span class="mi">3</span><span class="p">:]</span>
            <span class="k">if</span> <span class="n">recent_grads</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">recent_grads</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">5</span><span class="p">:</span>
                <span class="n">signals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>

        <span class="c1"># ä¿¡å·4ï¼šæ¢¯åº¦èŒƒæ•°è¶…è¿‡å†å²99åˆ†ä½</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;grad_norm&#39;</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span><span class="p">:</span>
            <span class="n">threshold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;grad_norm&#39;</span><span class="p">],</span> <span class="mi">99</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics_history</span><span class="p">[</span><span class="s1">&#39;grad_norm&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span> <span class="o">*</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">signals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.6</span><span class="p">)</span>

        <span class="c1"># ç»¼åˆæ‰€æœ‰ä¿¡å·</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">signals</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>

        <span class="c1"># ä½¿ç”¨æ¦‚ç‡ç»„åˆå…¬å¼</span>
        <span class="n">combined_prob</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="k">for</span> <span class="n">signal</span> <span class="ow">in</span> <span class="n">signals</span><span class="p">:</span>
            <span class="n">combined_prob</span> <span class="o">*=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">signal</span><span class="p">)</span>
        <span class="n">crash_prob</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">combined_prob</span>

        <span class="k">return</span> <span class="n">crash_prob</span>

    <span class="k">def</span> <span class="nf">get_preventive_action</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;æ ¹æ®å´©æºƒæ¦‚ç‡è¿”å›é¢„é˜²æªæ–½&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">crash_probability</span> <span class="o">&lt;</span> <span class="mf">0.3</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="n">actions</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">crash_probability</span> <span class="o">&gt;=</span> <span class="mf">0.3</span><span class="p">:</span>
            <span class="n">actions</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;save_checkpoint&#39;</span><span class="p">,</span> <span class="s1">&#39;Preventive checkpoint&#39;</span><span class="p">))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">crash_probability</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="n">actions</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;reduce_lr&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>  <span class="c1"># é™ä½å­¦ä¹ ç‡50%</span>
            <span class="n">actions</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;increase_grad_clip&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>  <span class="c1"># åŠ å¼ºæ¢¯åº¦è£å‰ª</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">crash_probability</span> <span class="o">&gt;=</span> <span class="mf">0.7</span><span class="p">:</span>
            <span class="n">actions</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;reduce_batch_size&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>  <span class="c1"># å‡å°batch size</span>
            <span class="n">actions</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;switch_to_fp32&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>  <span class="c1"># åˆ‡æ¢åˆ°FP32</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">crash_probability</span> <span class="o">&gt;=</span> <span class="mf">0.9</span><span class="p">:</span>
            <span class="n">actions</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;emergency_stop&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>  <span class="c1"># ç´§æ€¥åœæ­¢</span>

        <span class="k">return</span> <span class="n">actions</span>

    <span class="k">def</span> <span class="nf">apply_preventive_actions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;åº”ç”¨é¢„é˜²æªæ–½&quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">action</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="s1">&#39;save_checkpoint&#39;</span><span class="p">:</span>
                <span class="n">save_emergency_checkpoint</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">param</span><span class="p">)</span>

            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s1">&#39;reduce_lr&#39;</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
                    <span class="n">param_group</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">*=</span> <span class="n">param</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;é™ä½å­¦ä¹ ç‡åˆ° </span><span class="si">{</span><span class="n">param_group</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s1">&#39;increase_grad_clip&#39;</span><span class="p">:</span>
                <span class="n">config</span><span class="o">.</span><span class="n">grad_clip_norm</span> <span class="o">*=</span> <span class="n">param</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;åŠ å¼ºæ¢¯åº¦è£å‰ªåˆ° </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">grad_clip_norm</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s1">&#39;reduce_batch_size&#39;</span><span class="p">:</span>
                <span class="n">config</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">param</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;å‡å°batch sizeåˆ° </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s1">&#39;switch_to_fp32&#39;</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;åˆ‡æ¢åˆ°FP32ç²¾åº¦&quot;</span><span class="p">)</span>

            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s1">&#39;emergency_stop&#39;</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;æ£€æµ‹åˆ°å³å°†å´©æºƒï¼Œç´§æ€¥åœæ­¢è®­ç»ƒï¼&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">False</span>  <span class="c1"># åœæ­¢è®­ç»ƒ</span>

        <span class="k">return</span> <span class="kc">True</span>  <span class="c1"># ç»§ç»­è®­ç»ƒ</span>
</code></pre></div>

<p>è¯¥ç³»ç»Ÿçš„ç‰¹ç‚¹ï¼š</p>
<ol>
<li>å¤šæŒ‡æ ‡è”åˆç›‘æ§ï¼ˆlossã€æ¢¯åº¦ã€å­¦ä¹ ç‡ï¼‰</li>
<li>åŸºäºè¶‹åŠ¿è€Œéå•ç‚¹å€¼åˆ¤æ–­</li>
<li>åˆ†çº§å“åº”æœºåˆ¶</li>
<li>é¢„é˜²æªæ–½é€’è¿›å¼å¢å¼º</li>
<li>ä¿ç•™ç´§æ€¥åœæ­¢é€‰é¡¹é¿å…èµ„æºæµªè´¹</li>
</ol>
</details>
<h2 id="_7">å¸¸è§é™·é˜±ä¸é”™è¯¯</h2>
<h3 id="1">1. å¿½è§†æ—©æœŸä¿¡å·</h3>
<p>âŒ <strong>é”™è¯¯</strong>ï¼šç­‰åˆ° Loss å®Œå…¨å˜æˆ NaN æ‰å¤„ç†
âœ… <strong>æ­£ç¡®</strong>ï¼šåœ¨ Loss å¼€å§‹å¼‚å¸¸å¢é•¿æ—¶å°±ä»‹å…¥</p>
<h3 id="2">2. è¿‡åº¦ä¾èµ–è‡ªåŠ¨æ··åˆç²¾åº¦</h3>
<p>âŒ <strong>é”™è¯¯</strong>ï¼šå®Œå…¨ä¿¡ä»» AMP çš„ loss scaling
âœ… <strong>æ­£ç¡®</strong>ï¼šæ‰‹åŠ¨æ£€æŸ¥å…³é”®æ“ä½œçš„æ•°å€¼èŒƒå›´</p>
<h3 id="3-checkpoint">3. Checkpoint ä¸å®Œæ•´</h3>
<p>âŒ <strong>é”™è¯¯</strong>ï¼šåªä¿å­˜æ¨¡å‹æƒé‡
âœ… <strong>æ­£ç¡®</strong>ï¼šä¿å­˜å®Œæ•´è®­ç»ƒçŠ¶æ€ï¼ˆåŒ…æ‹¬ä¼˜åŒ–å™¨ã€éšæœºæ•°ç§å­ï¼‰</p>
<h3 id="4">4. æ¢¯åº¦è£å‰ªæ—¶æœºé”™è¯¯</h3>
<p>âŒ <strong>é”™è¯¯</strong>ï¼šåœ¨ loss.backward() ä¹‹å‰è£å‰ª
âœ… <strong>æ­£ç¡®</strong>ï¼šåœ¨ backward ä¹‹åã€optimizer.step() ä¹‹å‰è£å‰ª</p>
<h3 id="5">5. å¿½ç•¥æ•°æ®é—®é¢˜</h3>
<p>âŒ <strong>é”™è¯¯</strong>ï¼šåªå…³æ³¨æ¨¡å‹å’Œä¼˜åŒ–å™¨
âœ… <strong>æ­£ç¡®</strong>ï¼šæ£€æŸ¥æ•°æ®é¢„å¤„ç†ã€æ ‡ç­¾æ­£ç¡®æ€§ã€å¼‚å¸¸æ ·æœ¬</p>
<h3 id="6">6. æ¢å¤è®­ç»ƒåä¸éªŒè¯</h3>
<p>âŒ <strong>é”™è¯¯</strong>ï¼šåŠ è½½ checkpoint åç›´æ¥ç»§ç»­è®­ç»ƒ
âœ… <strong>æ­£ç¡®</strong>ï¼šå…ˆåœ¨éªŒè¯é›†ä¸Šæµ‹è¯•ï¼Œç¡®è®¤çŠ¶æ€æ­£ç¡®</p>
<h2 id="_8">æœ€ä½³å®è·µæ£€æŸ¥æ¸…å•</h2>
<h3 id="_9">è®­ç»ƒå‰å‡†å¤‡</h3>
<ul>
<li>[ ] é…ç½®å®Œæ•´çš„ checkpoint ä¿å­˜æœºåˆ¶</li>
<li>[ ] è®¾ç½®åˆç†çš„æ¢¯åº¦è£å‰ªé˜ˆå€¼ï¼ˆåŸºäºå°è§„æ¨¡å®éªŒï¼‰</li>
<li>[ ] å‡†å¤‡ FP32 é™çº§æ–¹æ¡ˆ</li>
<li>[ ] å®ç°æ¢¯åº¦ç›‘æ§å’Œæ—¥å¿—è®°å½•</li>
<li>[ ] éªŒè¯æ•°æ®åŠ è½½å’Œé¢„å¤„ç†æµç¨‹</li>
<li>[ ] æµ‹è¯• checkpoint æ¢å¤æµç¨‹</li>
</ul>
<h3 id="_10">è®­ç»ƒä¸­ç›‘æ§</h3>
<ul>
<li>[ ] æ¯ N æ­¥æ£€æŸ¥æ¢¯åº¦èŒƒæ•°åˆ†å¸ƒ</li>
<li>[ ] ç›‘æ§ Loss çš„ä¸€é˜¶å’ŒäºŒé˜¶å¯¼æ•°</li>
<li>[ ] å…³æ³¨å…³é”®å±‚çš„å‚æ•°å’Œæ¢¯åº¦ç»Ÿè®¡</li>
<li>[ ] å®šæœŸä¿å­˜ checkpointï¼ˆè‡³å°‘æ¯å°æ—¶ï¼‰</li>
<li>[ ] è®¾ç½®å¼‚å¸¸å€¼æŠ¥è­¦é˜ˆå€¼</li>
</ul>
<h3 id="_11">å´©æºƒåæ¢å¤</h3>
<ul>
<li>[ ] åˆ†æå´©æºƒå‰çš„æ—¥å¿—å’ŒæŒ‡æ ‡</li>
<li>[ ] è¯†åˆ«å´©æºƒæ¨¡å¼ï¼ˆçªå‘/æ¸è¿›/å‘¨æœŸï¼‰</li>
<li>[ ] è°ƒæ•´é…ç½®ï¼ˆå­¦ä¹ ç‡ã€batch sizeã€ç²¾åº¦ï¼‰</li>
<li>[ ] ä»æœ€è¿‘çš„ç¨³å®š checkpoint æ¢å¤</li>
<li>[ ] éªŒè¯æ¢å¤åçš„æ¨¡å‹è¡Œä¸º</li>
<li>[ ] è®°å½•é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆä¾›æœªæ¥å‚è€ƒ</li>
</ul>
<h3 id="_12">é•¿æœŸä¼˜åŒ–</h3>
<ul>
<li>[ ] å»ºç«‹å´©æºƒæ¡ˆä¾‹åº“</li>
<li>[ ] æ€»ç»“ä¸åŒæ¨¡å‹æ¶æ„çš„ç¨³å®šæ€§ç‰¹ç‚¹</li>
<li>[ ] ä¼˜åŒ–æ•°æ®ç®¡é“å‡å°‘å¼‚å¸¸æ ·æœ¬</li>
<li>[ ] å®ç°è‡ªåŠ¨åŒ–çš„å´©æºƒæ£€æµ‹å’Œæ¢å¤</li>
<li>[ ] å®šæœŸæ›´æ–°ç›‘æ§æŒ‡æ ‡å’Œé˜ˆå€¼</li>
</ul>
            </article>
            
            <nav class="page-nav"><a href="chapter9.html" class="nav-link prev">â† ç¬¬ 9 ç« ï¼šCUDA OOM è°ƒè¯•å®Œå…¨æŒ‡å—</a><a href="chapter11.html" class="nav-link next">ç¬¬ 11 ç« ï¼šè®­ç»ƒé€Ÿåº¦ä¼˜åŒ–å®æˆ˜ â†’</a></nav>
        </main>
    </div>
</body>
</html>