<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>第 3 章：SFT 训练策略</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">视觉语言模型（VLM）的监督微调与强化学习实战教程</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 1 章：VLM 架构与原理</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 2 章：数据准备与预处理</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 3 章：SFT 训练策略</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 4 章：分布式训练与优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 5 章：RLHF 基础与实现</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 6 章：直接偏好优化（DPO）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 7 章：评估体系设计</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 8 章：模型部署与服务化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 9 章：CUDA OOM 调试完全指南</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 10 章：训练崩溃与 NaN 问题</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 11 章：训练速度优化实战</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 12 章：多机多卡调试地狱</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="3-sft">第 3 章：SFT 训练策略</h1>
<p>监督微调（Supervised Fine-Tuning, SFT）是将预训练的视觉语言模型适配到特定任务的关键步骤。与纯语言模型不同，VLM 的 SFT 需要同时考虑视觉和语言两种模态的对齐，这带来了独特的挑战：如何设计有效的指令格式？如何平衡不同任务的损失？如何在有限的计算资源下高效微调？本章将系统介绍 VLM SFT 的核心技术，从指令设计到训练优化，帮助您掌握将通用 VLM 转化为任务专家的完整流程。</p>
<h2 id="31">3.1 指令微调的设计原则</h2>
<p>指令微调的核心在于教会模型理解和遵循人类指令。对于 VLM，这意味着模型不仅要理解文本指令，还要将其与视觉输入关联起来。设计良好的指令格式是成功微调的第一步。</p>
<h3 id="311">3.1.1 指令模板设计</h3>
<p>VLM 的指令模板需要明确标识图像位置、用户指令和模型响应的边界。常见的模板格式包括：</p>
<p><strong>基础单轮对话模板：</strong></p>
<div class="codehilite"><pre><span></span><code>&lt;image&gt;
User: {instruction}
Assistant: {response}
</code></pre></div>

<p><strong>带系统提示的模板：</strong></p>
<div class="codehilite"><pre><span></span><code>System: {system_prompt}
&lt;image&gt;
User: {instruction}
Assistant: {response}
</code></pre></div>

<p><strong>多图像交织模板：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">User</span><span class="o">:</span><span class="w"> </span><span class="err">比较这两张图片</span><span class="w"> </span><span class="o">&lt;</span><span class="n">image1</span><span class="o">&gt;</span><span class="w"> </span><span class="err">和</span><span class="w"> </span><span class="o">&lt;</span><span class="n">image2</span><span class="o">&gt;</span><span class="err">，</span><span class="o">{</span><span class="n">instruction</span><span class="o">}</span>
<span class="n">Assistant</span><span class="o">:</span><span class="w"> </span><span class="o">{</span><span class="n">response</span><span class="o">}</span>
</code></pre></div>

<p>关键设计原则：</p>
<ol>
<li><strong>位置标记明确</strong>：使用特殊 token（如 <code>&lt;image&gt;</code>、<code>&lt;|im_start|&gt;</code>）标记图像嵌入位置</li>
<li><strong>角色区分清晰</strong>：明确区分 system、user、assistant 角色</li>
<li><strong>边界符号一致</strong>：使用统一的开始/结束标记（如 <code>&lt;|im_end|&gt;</code>）</li>
</ol>
<p><strong>Token 化示例：</strong></p>
<div class="codehilite"><pre><span></span><code>输入文本: &quot;&lt;image&gt;\nUser: 描述这张图片\nAssistant: &quot;
Token IDs: [32000, 13, 2659, 29901, 29871, 31904, 30810, 30775, 30998, 13, 7900, 22137, 29901, 29871]
            ↑图像占位  ↑换行  ↑User:        ↑描述这张图片      ↑换行 ↑Assistant:
</code></pre></div>

<h3 id="312">3.1.2 系统提示词的作用</h3>
<p>系统提示词（System Prompt）定义模型的角色和行为准则，对 VLM 的表现有显著影响：</p>
<p><strong>通用视觉助手提示：</strong></p>
<div class="codehilite"><pre><span></span><code>你是一个专业的视觉语言助手。请准确描述图像内容，回答用户关于图像的问题。
如果图像中包含文字，请准确识别并转录。避免猜测或编造不存在的内容。
</code></pre></div>

<p><strong>任务特定提示（OCR场景）：</strong></p>
<div class="codehilite"><pre><span></span><code>你是一个OCR专家。请：

1. 识别图像中的所有文字
2. 保持原始格式和布局
3. 标注不确定的字符为[?]
4. 忽略装饰性元素，专注文字内容
</code></pre></div>

<p>系统提示的优化技巧：</p>
<ul>
<li><strong>长度控制</strong>：过长的系统提示会占用上下文窗口，建议控制在 100-200 token</li>
<li><strong>任务聚焦</strong>：针对特定任务定制提示，避免过于宽泛</li>
<li><strong>示例引导</strong>：在提示中包含期望输出格式的示例</li>
</ul>
<h3 id="313">3.1.3 多轮对话的处理</h3>
<p>VLM 的多轮对话需要处理历史上下文和新图像输入的关系：</p>
<p><strong>策略1：图像持久化</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 第一轮</span>
<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;image&gt; 这是什么动物？&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;这是一只橙色的猫。&quot;</span><span class="p">}</span>
<span class="p">]</span>
<span class="c1"># 第二轮（引用同一图像）</span>
<span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;它在做什么？&quot;</span><span class="p">})</span>
<span class="c1"># 模型需要记住之前的图像上下文</span>
</code></pre></div>

<p><strong>策略2：显式图像引用</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 使用图像ID系统</span>
<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;image id=&#39;img1&#39;&gt; 描述第一张图&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;第一张图显示...&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;image id=&#39;img2&#39;&gt; 比较img1和img2的差异&quot;</span><span class="p">},</span>
<span class="p">]</span>
</code></pre></div>

<p><strong>上下文窗口管理：</strong></p>
<div class="codehilite"><pre><span></span><code>最大上下文 = 4096 tokens
├── 系统提示: ~100 tokens
├── 图像嵌入: 576 tokens × N张图
├── 历史对话: 可变长度
└── 当前回复: 预留 500-1000 tokens
</code></pre></div>

<h3 id="314-">3.1.4 视觉-语言指令的对齐</h3>
<p>确保视觉理解与语言生成的一致性是 VLM SFT 的核心挑战：</p>
<p><strong>对齐层次：</strong></p>
<ol>
<li><strong>对象级对齐</strong>：物体识别与命名一致</li>
<li><strong>属性级对齐</strong>：颜色、大小、纹理描述准确</li>
<li><strong>关系级对齐</strong>：空间关系、动作关系正确</li>
<li><strong>场景级对齐</strong>：整体理解与描述连贯</li>
</ol>
<p><strong>对齐技术：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="err">视觉特征对齐矩阵</span><span class="o">:</span>
<span class="w">       </span><span class="err">物体</span><span class="w">  </span><span class="err">属性</span><span class="w">  </span><span class="err">关系</span><span class="w">  </span><span class="err">场景</span>
<span class="w">       </span><span class="n">________________</span>
<span class="err">视觉</span><span class="w">  </span><span class="o">|</span><span class="w"> </span><span class="mf">1.0</span><span class="w">  </span><span class="mf">0.8</span><span class="w">  </span><span class="mf">0.6</span><span class="w">  </span><span class="mf">0.7</span><span class="w"> </span><span class="o">|</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="err">视觉编码器输出</span>
<span class="err">语言</span><span class="w">  </span><span class="o">|</span><span class="w"> </span><span class="mf">0.9</span><span class="w">  </span><span class="mf">0.9</span><span class="w">  </span><span class="mf">0.7</span><span class="w">  </span><span class="mf">0.8</span><span class="w"> </span><span class="o">|</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="err">语言模型理解</span>
<span class="w">       </span><span class="err">‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾</span>
<span class="err">对角线值越接近</span><span class="mf">1.0</span><span class="err">，对齐越好</span>
</code></pre></div>

<p><strong>细粒度对齐示例：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Grounding 标注格式</span>
<span class="n">instruction</span> <span class="o">=</span> <span class="s2">&quot;找出&lt;click&gt;红色的球&lt;/click&gt;在哪里&quot;</span>
<span class="n">response</span> <span class="o">=</span> <span class="s2">&quot;红色的球位于&lt;box&gt;[[125, 235, 200, 310]]&lt;/box&gt;图像的左下角。&quot;</span>

<span class="c1"># Referring 标注格式  </span>
<span class="n">instruction</span> <span class="o">=</span> <span class="s2">&quot;描述位于&lt;region&gt;[[x1,y1,x2,y2]]&lt;/region&gt;的物体&quot;</span>
<span class="n">response</span> <span class="o">=</span> <span class="s2">&quot;这是一个红色的篮球，表面有黑色的线条纹理。&quot;</span>
</code></pre></div>

<h2 id="32">3.2 损失函数设计与权重策略</h2>
<p>损失函数设计直接影响模型的学习目标和收敛行为。VLM 的 SFT 需要精心设计损失函数来平衡不同类型的预测任务。</p>
<h3 id="321">3.2.1 自回归语言模型损失</h3>
<p>VLM 的核心损失是自回归语言建模损失，即预测下一个 token 的交叉熵损失：</p>
<p>$$\mathcal{L}_{LM} = -\sum_{t=1}^{T} \log P(x_t | x_{&lt;t}, I)$$
其中 $x_t$ 是第 $t$ 个 token，$I$ 是输入图像，$x_{&lt;t}$ 是之前的所有 token。</p>
<p><strong>实现细节：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_lm_loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="mi">32000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    logits: [batch_size, seq_len, vocab_size]</span>
<span class="sd">    labels: [batch_size, seq_len]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Shift：预测位置和标签错位</span>
    <span class="n">shift_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
    <span class="n">shift_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

    <span class="c1"># Flatten 便于计算</span>
    <span class="n">shift_logits</span> <span class="o">=</span> <span class="n">shift_logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
    <span class="n">shift_labels</span> <span class="o">=</span> <span class="n">shift_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># 交叉熵损失</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span>
        <span class="n">shift_logits</span><span class="p">,</span> 
        <span class="n">shift_labels</span><span class="p">,</span> 
        <span class="n">ignore_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span>  <span class="c1"># 忽略 padding</span>
        <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div>

<p><strong>注意力掩码的影响：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="nl">序列</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">IMG</span><span class="o">]</span><span class="w"> </span><span class="k">User</span><span class="err">:</span><span class="w"> </span><span class="n">描述图片</span><span class="w"> </span><span class="nl">Assistant</span><span class="p">:</span><span class="w"> </span><span class="n">这是一只猫</span><span class="w"> </span><span class="o">[</span><span class="n">EOS</span><span class="o">]</span>
<span class="nl">掩码</span><span class="p">:</span><span class="w">  </span><span class="mi">0</span><span class="w">    </span><span class="mi">0</span><span class="w">     </span><span class="mi">0</span><span class="w">        </span><span class="mi">1</span><span class="w">          </span><span class="mi">1</span><span class="w">          </span><span class="mi">1</span>

<span class="n">只在</span><span class="w"> </span><span class="n">Assistant</span><span class="w"> </span><span class="n">响应部分计算损失</span>
</code></pre></div>

<h3 id="322">3.2.2 掩码策略与权重分配</h3>
<p>不同部分的 token 对学习的重要性不同，通过掩码和权重调整可以优化训练效果：</p>
<ol>
<li><strong>响应掩码（Response Masking）：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">create_response_mask</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">response_start_token_id</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;只在模型响应部分计算损失&quot;&quot;&quot;</span>
    <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="c1"># 找到响应开始位置</span>
        <span class="n">response_start</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">response_start_token_id</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">response_start</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">start_idx</span> <span class="o">=</span> <span class="n">response_start</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">start_idx</span><span class="p">:]</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">return</span> <span class="n">mask</span>
</code></pre></div>

<ol start="2">
<li><strong>Token 级别权重：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># 不同类型 token 的权重</span>
<span class="n">token_weights</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;special_tokens&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>    <span class="c1"># &lt;image&gt;, &lt;pad&gt; 等</span>
    <span class="s2">&quot;instruction&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>        <span class="c1"># 用户指令部分</span>
    <span class="s2">&quot;response&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>          <span class="c1"># 助手响应</span>
    <span class="s2">&quot;grounding_box&quot;</span><span class="p">:</span> <span class="mf">2.0</span><span class="p">,</span>     <span class="c1"># 坐标预测</span>
    <span class="s2">&quot;key_entities&quot;</span><span class="p">:</span> <span class="mf">1.5</span>       <span class="c1"># 关键实体名词</span>
<span class="p">}</span>
</code></pre></div>

<ol start="3">
<li><strong>动态权重调整：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code>早期训练（epoch 1-3）：

- 所有 token 权重 = 1.0
- 让模型学习基础的语言模式

中期训练（epoch 4-8）：

- 指令部分权重 = 0.5
- 响应部分权重 = 1.0
- 强化指令遵循能力

后期训练（epoch 9-10）：

- 只计算响应损失
- 精细调整生成质量
</code></pre></div>

<h3 id="323">3.2.3 多任务学习的损失平衡</h3>
<p>VLM 通常需要同时处理多个任务，如图像描述、VQA、OCR 等。多任务损失平衡是关键：</p>
<p><strong>损失组合策略：</strong>
$$\mathcal{L}_{total} = \sum_{i=1}^{N} w_i \mathcal{L}_i$$
<strong>自适应权重方法：</strong></p>
<ol>
<li>
<p><strong>不确定性加权（Uncertainty Weighting）：</strong>
$$\mathcal{L}_{total} = \sum_{i=1}^{N} \frac{1}{2\sigma_i^2} \mathcal{L}_i + \log \sigma_i$$
其中 $\sigma_i$ 是可学习的任务不确定性参数。</p>
</li>
<li>
<p><strong>梯度归一化（GradNorm）：</strong></p>
</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">gradnorm_weights</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">shared_params</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;根据梯度大小动态调整任务权重&quot;&quot;&quot;</span>
    <span class="c1"># 计算每个任务的梯度范数</span>
    <span class="n">grad_norms</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">loss</span> <span class="ow">in</span> <span class="n">losses</span><span class="p">:</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">shared_params</span><span class="p">,</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">g</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">]))</span>
        <span class="n">grad_norms</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">grad_norm</span><span class="p">)</span>

    <span class="c1"># 计算平均梯度范数</span>
    <span class="n">mean_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">grad_norms</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="c1"># 调整权重</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">norm</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">grad_norms</span><span class="p">):</span>
        <span class="n">relative_norm</span> <span class="o">=</span> <span class="n">norm</span> <span class="o">/</span> <span class="n">mean_norm</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">relative_norm</span> <span class="o">**</span> <span class="n">alpha</span>
        <span class="n">weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>

<p><strong>任务采样策略：</strong></p>
<div class="codehilite"><pre><span></span><code>批次构建策略:
├── 均匀采样: 每个 batch 包含所有任务
├── 任务分组: 相似任务放在同一 batch
└── 温度采样: P(task_i) ∝ (1/loss_i)^T

温度 T 控制采样分布:

<span class="k">-</span> T → 0: 只采样损失最大的任务
<span class="k">-</span> T = 1: 根据损失反比采样  
<span class="k">-</span> T → ∞: 均匀采样所有任务
</code></pre></div>

<h3 id="324-grounding">3.2.4 视觉 Grounding 损失设计</h3>
<p>对于需要定位的任务（如目标检测、referring segmentation），需要专门的损失设计：</p>
<ol>
<li><strong>边界框回归损失：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">box_loss</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">,</span> <span class="n">gt_boxes</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    pred_boxes: [batch, num_queries, 4]  # (x1, y1, x2, y2) 归一化坐标</span>
<span class="sd">    gt_boxes: [batch, num_targets, 4]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># L1 损失</span>
    <span class="n">l1_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">l1_loss</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">,</span> <span class="n">gt_boxes</span><span class="p">)</span>

    <span class="c1"># GIoU 损失</span>
    <span class="n">giou_loss</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">compute_giou</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">,</span> <span class="n">gt_boxes</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">l1_loss</span> <span class="o">+</span> <span class="n">giou_loss</span>
</code></pre></div>

<ol start="2">
<li><strong>坐标 Token 化策略：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code>方法1：连续坐标离散化
[0,<span class="w"> </span>1]<span class="w"> </span>→<span class="w"> </span>[0,<span class="w"> </span>999]<span class="w"> </span>→<span class="w"> </span>token_id<span class="w"> </span>∈<span class="w"> </span>[32000,<span class="w"> </span>32999]

方法2：区域编码
图像分成<span class="w"> </span>32×32<span class="w"> </span>网格<span class="w"> </span>→<span class="w"> </span>每个网格一个<span class="w"> </span>token

方法3：特殊数字<span class="w"> </span>token
<span class="nt">&lt;x&gt;</span>0.123<span class="nt">&lt;/x&gt;</span><span class="w"> </span><span class="nt">&lt;y&gt;</span>0.456<span class="nt">&lt;/y&gt;</span><span class="w"> </span>→<span class="w"> </span>解析时提取
</code></pre></div>

<ol start="3">
<li><strong>Referring 损失设计：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">referring_loss</span><span class="p">(</span><span class="n">pred_mask</span><span class="p">,</span> <span class="n">gt_mask</span><span class="p">,</span> <span class="n">pred_box</span><span class="p">,</span> <span class="n">gt_box</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;组合分割和检测损失&quot;&quot;&quot;</span>
    <span class="c1"># 像素级分割损失</span>
    <span class="n">seg_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">(</span><span class="n">pred_mask</span><span class="p">,</span> <span class="n">gt_mask</span><span class="p">)</span>

    <span class="c1"># 边界框损失</span>
    <span class="n">box_loss</span> <span class="o">=</span> <span class="n">compute_box_loss</span><span class="p">(</span><span class="n">pred_box</span><span class="p">,</span> <span class="n">gt_box</span><span class="p">)</span>

    <span class="c1"># 一致性损失：确保 mask 和 box 对应</span>
    <span class="n">mask_from_box</span> <span class="o">=</span> <span class="n">box_to_mask</span><span class="p">(</span><span class="n">pred_box</span><span class="p">)</span>
    <span class="n">consistency_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">pred_mask</span><span class="p">,</span> <span class="n">mask_from_box</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">seg_loss</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">box_loss</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">consistency_loss</span>
</code></pre></div>

<ol start="4">
<li><strong>负样本处理：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="nv">Grounding</span><span class="w"> </span>任务的负样本策略:
├──<span class="w"> </span><span class="nv">Hard</span><span class="w"> </span><span class="nv">Negative</span>:<span class="w"> </span>选择最容易混淆的物体
├──<span class="w"> </span><span class="k">Random</span><span class="w"> </span><span class="nv">Negative</span>:<span class="w"> </span>随机选择其他物体
└──<span class="w"> </span><span class="nv">Background</span>:<span class="w"> </span>选择背景区域

负样本比例建议:

<span class="o">-</span><span class="w"> </span>正负比<span class="w"> </span><span class="mi">1</span>:<span class="mi">3</span><span class="w"> </span><span class="k">for</span><span class="w"> </span>目标检测
<span class="o">-</span><span class="w"> </span>正负比<span class="w"> </span><span class="mi">1</span>:<span class="mi">1</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">referring</span><span class="w"> </span><span class="nv">expression</span>
<span class="o">-</span><span class="w"> </span>动态调整<span class="nv">based</span><span class="w"> </span><span class="nv">on</span><span class="w"> </span>难度
</code></pre></div>

<h2 id="33-loraqloraadapter">3.3 参数高效微调方法（LoRA、QLoRA、Adapter）</h2>
<p>参数高效微调（PEFT）方法允许在有限的计算资源下微调大规模 VLM。这些方法通过只更新少量参数来实现与全量微调相近的效果。</p>
<h3 id="331-lora">3.3.1 LoRA 原理与实现</h3>
<p>LoRA（Low-Rank Adaptation）通过低秩分解来近似权重更新：</p>
<p><strong>核心原理：</strong>
$$W' = W + \Delta W = W + BA$$</p>
<p>其中 $B \in \mathbb{R}^{d \times r}$，$A \in \mathbb{R}^{r \times k}$，$r \ll \min(d, k)$。</p>
<p><strong>VLM 中的 LoRA 配置：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">LoRAConfig</span><span class="p">:</span>
    <span class="c1"># 语言模型部分</span>
    <span class="n">lm_target_modules</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span>  <span class="c1"># 注意力层</span>
        <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">,</span>
        <span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;up_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;down_proj&quot;</span>  <span class="c1"># FFN 层</span>
    <span class="p">]</span>

    <span class="c1"># 视觉编码器部分（可选）</span>
    <span class="n">vision_target_modules</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;qkv&quot;</span><span class="p">,</span>  <span class="c1"># ViT 的 QKV 投影</span>
        <span class="s2">&quot;proj&quot;</span><span class="p">,</span> <span class="c1"># 输出投影</span>
        <span class="s2">&quot;mlp.fc1&quot;</span><span class="p">,</span> <span class="s2">&quot;mlp.fc2&quot;</span>  <span class="c1"># MLP 层</span>
    <span class="p">]</span>

    <span class="c1"># 关键超参数</span>
    <span class="n">r</span> <span class="o">=</span> <span class="mi">16</span>  <span class="c1"># rank，常用 8/16/32/64</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mi">16</span>  <span class="c1"># 缩放因子，通常 = r</span>
    <span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.1</span>
</code></pre></div>

<p><strong>动态 Rank 选择：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="err">不同模块的重要性分析</span><span class="o">:</span>
<span class="err">模块类型</span><span class="w">        </span><span class="err">建议</span><span class="w"> </span><span class="n">rank</span><span class="w">   </span><span class="err">参数占比</span>
<span class="o">-----------------------------------------</span>
<span class="n">Q</span><span class="o">,</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="err">投影</span><span class="w">       </span><span class="mi">8</span><span class="o">-</span><span class="mi">16</span><span class="w">       </span><span class="o">~</span><span class="mi">15</span><span class="o">%</span>
<span class="n">V</span><span class="o">,</span><span class="w"> </span><span class="n">O</span><span class="w"> </span><span class="err">投影</span><span class="w">       </span><span class="mi">16</span><span class="o">-</span><span class="mi">32</span><span class="w">      </span><span class="o">~</span><span class="mi">20</span><span class="o">%</span><span class="w">  </span>
<span class="n">FFN</span><span class="w"> </span><span class="err">上投影</span><span class="w">      </span><span class="mi">32</span><span class="o">-</span><span class="mi">64</span><span class="w">      </span><span class="o">~</span><span class="mi">35</span><span class="o">%</span>
<span class="n">FFN</span><span class="w"> </span><span class="err">下投影</span><span class="w">      </span><span class="mi">16</span><span class="o">-</span><span class="mi">32</span><span class="w">      </span><span class="o">~</span><span class="mi">25</span><span class="o">%</span>
<span class="n">Cross</span><span class="o">-</span><span class="n">Attn</span><span class="w">     </span><span class="mi">32</span><span class="o">-</span><span class="mi">64</span><span class="w">      </span><span class="o">~</span><span class="mi">5</span><span class="o">%</span><span class="w"> </span><span class="o">(</span><span class="err">如果有</span><span class="o">)</span>
</code></pre></div>

<p><strong>实现细节：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">LoRALayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">/</span> <span class="n">rank</span>

        <span class="c1"># 低秩矩阵</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lora_A</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">in_features</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lora_B</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">out_features</span><span class="p">,</span> <span class="n">rank</span><span class="p">))</span>

        <span class="c1"># 初始化</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lora_A</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">base_output</span><span class="p">):</span>
        <span class="c1"># base_output 是原始层的输出</span>
        <span class="n">lora_output</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">lora_A</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">lora_B</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span>
        <span class="k">return</span> <span class="n">base_output</span> <span class="o">+</span> <span class="n">lora_output</span>
</code></pre></div>

<h3 id="332-qlora">3.3.2 QLoRA 的量化策略</h3>
<p>QLoRA 结合 4-bit 量化和 LoRA，大幅降低显存占用：</p>
<p><strong>量化流程：</strong></p>
<div class="codehilite"><pre><span></span><code>原始模型 (16-bit) → NF4 量化 (4-bit) + LoRA 适配器 (16-bit)
显存节省: ~75% (相比全精度)
</code></pre></div>

<p><strong>NF4（NormalFloat4）量化：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">quantize_nf4</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;4-bit NormalFloat 量化&quot;&quot;&quot;</span>
    <span class="c1"># 1. 归一化到 [-1, 1]</span>
    <span class="n">absmax</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="n">tensor_normalized</span> <span class="o">=</span> <span class="n">tensor</span> <span class="o">/</span> <span class="n">absmax</span>

    <span class="c1"># 2. 量化到 16 个级别</span>
    <span class="n">quantization_levels</span> <span class="o">=</span> <span class="p">[</span>
        <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6961</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5250</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3949</span><span class="p">,</span> 
        <span class="o">-</span><span class="mf">0.2844</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1848</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0911</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="mf">0.0796</span><span class="p">,</span> <span class="mf">0.1609</span><span class="p">,</span> <span class="mf">0.2461</span><span class="p">,</span> <span class="mf">0.3379</span><span class="p">,</span>
        <span class="mf">0.4407</span><span class="p">,</span> <span class="mf">0.5626</span><span class="p">,</span> <span class="mf">0.7230</span><span class="p">,</span> <span class="mf">1.0</span>
    <span class="p">]</span>

    <span class="c1"># 3. 找最近的量化级别</span>
    <span class="n">quantized</span> <span class="o">=</span> <span class="n">quantize_to_nearest</span><span class="p">(</span><span class="n">tensor_normalized</span><span class="p">,</span> <span class="n">quantization_levels</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">quantized</span><span class="p">,</span> <span class="n">absmax</span>  <span class="c1"># 保存 scale 用于反量化</span>
</code></pre></div>

<p><strong>双重量化（Double Quantization）：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="err">第一次量化</span><span class="o">:</span><span class="w"> </span><span class="err">模型权重</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="mi">4</span><span class="o">-</span><span class="n">bit</span>
<span class="err">第二次量化</span><span class="o">:</span><span class="w"> </span><span class="err">量化常数</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="mi">8</span><span class="o">-</span><span class="n">bit</span>
<span class="err">额外节省</span><span class="o">:</span><span class="w"> </span><span class="o">~</span><span class="mf">0.37</span><span class="w"> </span><span class="n">bit</span><span class="o">/</span><span class="err">参数</span>
</code></pre></div>

<p><strong>QLoRA 训练配置：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">bnb_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span>
    <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">bnb_4bit_quant_type</span><span class="o">=</span><span class="s2">&quot;nf4&quot;</span><span class="p">,</span>
    <span class="n">bnb_4bit_compute_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>
    <span class="n">bnb_4bit_use_double_quant</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Paged Optimizer 节省优化器内存</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">PagedAdamW32bit</span><span class="p">(</span>
    <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">2e-4</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">optim_bits</span><span class="o">=</span><span class="mi">32</span>  <span class="c1"># 优化器状态保持 32-bit</span>
<span class="p">)</span>
</code></pre></div>

<h3 id="333-adapter">3.3.3 Adapter 层的设计选择</h3>
<p>Adapter 通过插入小型网络模块来实现参数高效微调：</p>
<p><strong>标准 Adapter 架构：</strong></p>
<div class="codehilite"><pre><span></span><code>输入 → LayerNorm → Down-projection → 激活 → Up-projection → 残差连接
  ↓                                                               ↑
  └──────────────────────────────────────────────────────────────┘
</code></pre></div>

<p><strong>VLM 中的 Adapter 变体：</strong></p>
<ol>
<li><strong>Sequential Adapter：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">SequentialAdapter</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">reduction_factor</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">//</span> <span class="n">reduction_factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">down_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">up_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">residual</span>
</code></pre></div>

<ol start="2">
<li><strong>Parallel Adapter：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">ParallelAdapter</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;并行处理，减少延迟&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">original_output</span><span class="p">):</span>
        <span class="n">adapter_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">adapter</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">original_output</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">*</span> <span class="n">adapter_output</span>
</code></pre></div>

<ol start="3">
<li><strong>Cross-Modal Adapter：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">CrossModalAdapter</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;专门处理视觉-语言交互&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vision_dim</span><span class="p">,</span> <span class="n">text_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vision_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">vision_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">text_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vision_features</span><span class="p">,</span> <span class="n">text_features</span><span class="p">):</span>
        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_proj</span><span class="p">(</span><span class="n">vision_features</span><span class="p">)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_proj</span><span class="p">(</span><span class="n">text_features</span><span class="p">)</span>
        <span class="n">fused</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>  <span class="c1"># text 作 query</span>
        <span class="k">return</span> <span class="n">fused</span>
</code></pre></div>

<h3 id="334-peft">3.3.4 PEFT 方法对比与选择</h3>
<p><strong>性能对比表：</strong></p>
<div class="codehilite"><pre><span></span><code>方法        参数量   显存占用  训练速度  效果(相对全量)
---------------------------------------------------------
全量微调     100%     100%      1.0x      100%
LoRA        0.1-1%   ~60%      1.5x      95-98%
QLoRA       0.1-1%   ~25%      1.2x      92-96%
Adapter     1-5%     ~70%      1.3x      93-97%
Prefix      &lt;0.1%    ~50%      1.8x      85-92%
IA3         &lt;0.01%   ~55%      1.6x      88-94%
</code></pre></div>

<p><strong>选择决策树：</strong></p>
<div class="codehilite"><pre><span></span><code>显存限制严格？
├─ 是 → QLoRA（4-bit量化 + LoRA）
└─ 否 → 需要最佳性能？
        ├─ 是 → 全量微调 or LoRA (r=64)
        └─ 否 → 推理速度优先？
                ├─ 是 → LoRA (可合并权重)
                └─ 否 → Adapter (灵活性高)
</code></pre></div>

<p><strong>组合策略：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 混合 PEFT：不同层使用不同方法</span>
<span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;vision_encoder&quot;</span><span class="p">:</span> <span class="s2">&quot;frozen&quot;</span><span class="p">,</span>  <span class="c1"># 冻结</span>
    <span class="s2">&quot;projection&quot;</span><span class="p">:</span> <span class="s2">&quot;full&quot;</span><span class="p">,</span>        <span class="c1"># 全量微调</span>
    <span class="s2">&quot;llm_layers_0_16&quot;</span><span class="p">:</span> <span class="s2">&quot;lora&quot;</span><span class="p">,</span>  <span class="c1"># 底层用 LoRA</span>
    <span class="s2">&quot;llm_layers_16_32&quot;</span><span class="p">:</span> <span class="s2">&quot;adapter&quot;</span><span class="p">,</span>  <span class="c1"># 高层用 Adapter</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>实践建议：</strong></p>
<ol>
<li><strong>初始实验</strong>：从 LoRA r=8 开始，逐步增加</li>
<li><strong>视觉编码器</strong>：通常冻结或用很小的 rank（r=4）</li>
<li><strong>投影层</strong>：建议全量微调，参数量小但重要</li>
<li><strong>任务适配</strong>：简单任务用 LoRA，复杂任务考虑 Adapter</li>
</ol>
<h2 id="34">3.4 训练稳定性与收敛技巧</h2>
<p>训练大规模 VLM 时经常遇到不稳定问题：损失突然爆炸、梯度消失、收敛缓慢等。本节介绍实用的稳定性技巧。</p>
<h3 id="341">3.4.1 学习率调度策略</h3>
<p><strong>VLM 常用调度器：</strong></p>
<ol>
<li><strong>Cosine with Warmup：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">cosine_schedule_with_warmup</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">num_warmup_steps</span><span class="p">,</span> <span class="n">num_training_steps</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">lr_lambda</span><span class="p">(</span><span class="n">current_step</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">current_step</span> <span class="o">&lt;</span> <span class="n">num_warmup_steps</span><span class="p">:</span>
            <span class="c1"># 线性 warmup</span>
            <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">current_step</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_warmup_steps</span><span class="p">))</span>
        <span class="c1"># Cosine 衰减</span>
        <span class="n">progress</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">current_step</span> <span class="o">-</span> <span class="n">num_warmup_steps</span><span class="p">)</span> <span class="o">/</span> \
                  <span class="nb">float</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_training_steps</span> <span class="o">-</span> <span class="n">num_warmup_steps</span><span class="p">))</span>
        <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">progress</span><span class="p">)))</span>

    <span class="k">return</span> <span class="n">LambdaLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_lambda</span><span class="p">)</span>
</code></pre></div>

<ol start="2">
<li><strong>分阶段学习率：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code>阶段1（预热）: lr = 1e-6 → 2e-4 (线性增长)
阶段2（主训练）: lr = 2e-4 (恒定或缓慢衰减)
阶段3（精调）: lr = 2e-4 → 1e-5 (cosine衰减)
</code></pre></div>

<p><strong>视觉编码器特殊处理：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 不同组件不同学习率</span>
<span class="n">param_groups</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">vision_encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">},</span>  <span class="c1"># 更小</span>
    <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">projection</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">5e-4</span><span class="p">},</span>      <span class="c1"># 更大</span>
    <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">language_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">2e-4</span><span class="p">},</span>  <span class="c1"># 标准</span>
<span class="p">]</span>
</code></pre></div>

<h3 id="342">3.4.2 梯度裁剪与归一化</h3>
<p><strong>梯度裁剪策略：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 1. 全局梯度裁剪（推荐）</span>
<span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># 2. 分层梯度裁剪</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
    <span class="k">if</span> <span class="s2">&quot;vision&quot;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">([</span><span class="n">param</span><span class="p">],</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">([</span><span class="n">param</span><span class="p">],</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</code></pre></div>

<p><strong>梯度监控：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">monitor_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;监控梯度统计信息&quot;&quot;&quot;</span>
    <span class="n">grad_stats</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">grad_stats</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                <span class="s2">&quot;std&quot;</span><span class="p">:</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                <span class="s2">&quot;max&quot;</span><span class="p">:</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
            <span class="p">}</span>
    <span class="k">return</span> <span class="n">grad_stats</span>

<span class="c1"># 异常检测</span>
<span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">stat</span><span class="p">[</span><span class="s2">&quot;max&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">100</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">grad_stats</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;梯度爆炸风险！&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="343">3.4.3 权重初始化技巧</h3>
<p><strong>关键组件初始化：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">init_vlm_weights</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="c1"># 1. 投影层：Xavier 初始化</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;visual_projection&#39;</span><span class="p">):</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">visual_projection</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">visual_projection</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

    <span class="c1"># 2. LoRA 层：接近零初始化</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="s2">&quot;lora_B&quot;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>  <span class="c1"># B 矩阵初始化为0</span>
        <span class="k">elif</span> <span class="s2">&quot;lora_A&quot;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform_</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>

    <span class="c1"># 3. Layer Scale：小值初始化</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;layer_scale&#39;</span><span class="p">):</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layer_scale</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">)</span>
</code></pre></div>

<p><strong>稳定性技巧：</strong></p>
<div class="codehilite"><pre><span></span><code>初始化检查清单：
□ 投影层不能太大（std &lt; 0.02）
□ LoRA B 矩阵初始为 0
□ Layer Norm 权重 = 1, 偏置 = 0
□ 新增 token embedding 用已有 token 平均值
</code></pre></div>

<h3 id="344-checkpoint">3.4.4 早停与 Checkpoint 策略</h3>
<p><strong>智能 Checkpoint：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">SmartCheckpointer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">0.001</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delta</span> <span class="o">=</span> <span class="n">delta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">should_save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="n">val_loss</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="n">val_loss</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">delta</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="n">val_loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">should_stop</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span>
</code></pre></div>

<p><strong>Checkpoint 管理：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
    <span class="s1">&#39;model_state_dict&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
    <span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
    <span class="s1">&#39;scheduler_state_dict&#39;</span><span class="p">:</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
    <span class="s1">&#39;best_val_loss&#39;</span><span class="p">:</span> <span class="n">best_val_loss</span><span class="p">,</span>
    <span class="s1">&#39;training_history&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;train_losses&#39;</span><span class="p">:</span> <span class="n">train_losses</span><span class="p">,</span>
        <span class="s1">&#39;val_losses&#39;</span><span class="p">:</span> <span class="n">val_losses</span><span class="p">,</span>
        <span class="s1">&#39;learning_rates&#39;</span><span class="p">:</span> <span class="n">lrs</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># 保存策略</span>
<span class="n">save_strategies</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;best&quot;</span><span class="p">:</span> <span class="s2">&quot;checkpoint_best.pt&quot;</span><span class="p">,</span>        <span class="c1"># 最佳验证性能</span>
    <span class="s2">&quot;latest&quot;</span><span class="p">:</span> <span class="s2">&quot;checkpoint_latest.pt&quot;</span><span class="p">,</span>    <span class="c1"># 最新状态</span>
    <span class="s2">&quot;periodic&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;checkpoint_epoch_</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">.pt&quot;</span><span class="p">,</span>  <span class="c1"># 定期保存</span>
<span class="p">}</span>
</code></pre></div>

<h2 id="case-study-qwen-vl">Case Study: Qwen-VL 的三阶段训练策略实战</h2>
<p>Qwen-VL 采用渐进式三阶段训练策略，从大规模预训练到精细指令微调，实现了优秀的多模态性能。</p>
<h3 id="-">阶段一：视觉-语言预训练</h3>
<p><strong>目标</strong>：建立基础的视觉-语言对齐能力</p>
<p><strong>数据配置：</strong></p>
<div class="codehilite"><pre><span></span><code>总量：1.4B 图文对
├── LAION-400M: 40%（网络爬取）
├── COYO-700M: 30%（韩语+英语）
├── CC12M: 15%（概念描述）
└── 内部数据: 15%（高质量筛选）
</code></pre></div>

<p><strong>训练配置：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">stage1_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;vision_encoder&quot;</span><span class="p">:</span> <span class="s2">&quot;frozen&quot;</span><span class="p">,</span>  <span class="c1"># OpenCLIP ViT-G/14</span>
    <span class="s2">&quot;projection&quot;</span><span class="p">:</span> <span class="s2">&quot;trainable&quot;</span><span class="p">,</span>   <span class="c1"># 新增的 Resampler</span>
    <span class="s2">&quot;language_model&quot;</span><span class="p">:</span> <span class="s2">&quot;trainable&quot;</span><span class="p">,</span>  <span class="c1"># Qwen-7B</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>
    <span class="s2">&quot;warmup_steps&quot;</span><span class="p">:</span> <span class="mi">2000</span><span class="p">,</span>
    <span class="s2">&quot;total_steps&quot;</span><span class="p">:</span> <span class="mi">50000</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="_1">阶段二：多任务预训练</h3>
<p><strong>目标</strong>：学习多样化的视觉任务能力</p>
<p><strong>任务分布：</strong></p>
<div class="codehilite"><pre><span></span><code>任务类型         数据量    损失权重
--------------------------------------
图像描述         50M      0.3
VQA             30M      0.2
OCR             20M      0.2
Grounding       15M      0.15
Referring       10M      0.15
</code></pre></div>

<p><strong>关键技术：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 动态分辨率处理</span>
<span class="k">def</span> <span class="nf">dynamic_resolution</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">min_pixels</span><span class="o">=</span><span class="mi">224</span><span class="o">*</span><span class="mi">224</span><span class="p">,</span> <span class="n">max_pixels</span><span class="o">=</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;保持宽高比的动态分辨率&quot;&quot;&quot;</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">current_pixels</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="n">w</span>

    <span class="k">if</span> <span class="n">current_pixels</span> <span class="o">&lt;</span> <span class="n">min_pixels</span><span class="p">:</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">min_pixels</span> <span class="o">/</span> <span class="n">current_pixels</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">current_pixels</span> <span class="o">&gt;</span> <span class="n">max_pixels</span><span class="p">:</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">max_pixels</span> <span class="o">/</span> <span class="n">current_pixels</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="mf">1.0</span>

    <span class="n">new_h</span><span class="p">,</span> <span class="n">new_w</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">h</span> <span class="o">*</span> <span class="n">scale</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">scale</span><span class="p">)</span>
    <span class="c1"># 确保是 14 的倍数（ViT patch size）</span>
    <span class="n">new_h</span> <span class="o">=</span> <span class="p">(</span><span class="n">new_h</span> <span class="o">//</span> <span class="mi">14</span><span class="p">)</span> <span class="o">*</span> <span class="mi">14</span>
    <span class="n">new_w</span> <span class="o">=</span> <span class="p">(</span><span class="n">new_w</span> <span class="o">//</span> <span class="mi">14</span><span class="p">)</span> <span class="o">*</span> <span class="mi">14</span>

    <span class="k">return</span> <span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="n">new_h</span><span class="p">,</span> <span class="n">new_w</span><span class="p">))</span>
</code></pre></div>

<h3 id="_2">阶段三：指令微调</h3>
<p><strong>目标</strong>：优化指令遵循和对话能力</p>
<p><strong>数据构成：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">sft_data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;high_quality_vqa&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="n">k</span><span class="p">,</span>  <span class="c1"># 人工标注</span>
    <span class="s2">&quot;complex_reasoning&quot;</span><span class="p">:</span> <span class="mi">150</span><span class="n">k</span><span class="p">,</span>  <span class="c1"># GPT-4V 生成</span>
    <span class="s2">&quot;multi_turn_dialog&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="n">k</span><span class="p">,</span>  <span class="c1"># 多轮对话</span>
    <span class="s2">&quot;rejection_sampling&quot;</span><span class="p">:</span> <span class="mi">50</span><span class="n">k</span><span class="p">,</span>  <span class="c1"># 负样本</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>LoRA 微调配置：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">lora_config</span> <span class="o">=</span> <span class="n">LoRAConfig</span><span class="p">(</span>
    <span class="n">r</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>  <span class="c1"># 较大的 rank</span>
    <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">target_modules</span><span class="o">=</span><span class="p">[</span>
        <span class="s2">&quot;c_attn&quot;</span><span class="p">,</span>  <span class="c1"># Qwen 的注意力模块</span>
        <span class="s2">&quot;c_proj&quot;</span><span class="p">,</span> 
        <span class="s2">&quot;w1&quot;</span><span class="p">,</span> <span class="s2">&quot;w2&quot;</span><span class="p">,</span>  <span class="c1"># MLP</span>
    <span class="p">],</span>
    <span class="n">lora_dropout</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># 只微调语言模型部分</span>
<span class="n">trainable_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
<span class="n">total_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;可训练参数: </span><span class="si">{</span><span class="n">trainable_params</span><span class="o">/</span><span class="mf">1e6</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">M (</span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">trainable_params</span><span class="o">/</span><span class="n">total_params</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%)&quot;</span><span class="p">)</span>
<span class="c1"># 输出: 可训练参数: 384.00M (4.92%)</span>
</code></pre></div>

<p><strong>训练曲线监控：</strong></p>
<div class="codehilite"><pre><span></span><code>       Loss
   3.5 |
   3.0 |  Stage 1
   2.5 |    ╲___
   2.0 |         ╲__ Stage 2
   1.5 |             ╲____
   1.0 |                  ╲___ Stage 3
   0.5 |                      ╲________
       |__|__|__|__|__|__|__|__|__|__|__
         10k  20k  30k  40k  50k  60k  Steps
</code></pre></div>

<h2 id="_3">高级话题</h2>
<h3 id="_4">视觉编码器解冻时机</h3>
<p><strong>解冻策略对比：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c">策略            优点                缺点              适用场景</span>
<span class="nb">-----------------------------------------------------------------</span>
<span class="c">始终冻结        省显存、训练快      可能欠拟合        数据与预训练相似</span>
<span class="c">从头解冻        充分适应新任务      易过拟合、慢      大规模新领域数据</span>
<span class="c">阶段性解冻      平衡性能与效率      需要经验调参      通用场景（推荐）</span>
</code></pre></div>

<p><strong>阶段性解冻实践：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">staged_unfreeze</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">current_step</span><span class="p">,</span> <span class="n">total_steps</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;渐进解冻视觉编码器&quot;&quot;&quot;</span>
    <span class="n">progress</span> <span class="o">=</span> <span class="n">current_step</span> <span class="o">/</span> <span class="n">total_steps</span>

    <span class="k">if</span> <span class="n">progress</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="c1"># 前 50%: 全部冻结</span>
        <span class="n">freeze_vision_encoder</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">progress</span> <span class="o">&lt;</span> <span class="mf">0.8</span><span class="p">:</span>
        <span class="c1"># 50-80%: 解冻最后 4 层</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">vision_encoder</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">vision_encoder</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span> <span class="o">-</span> <span class="mi">4</span><span class="p">:</span>
                <span class="n">freeze_layer</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">unfreeze_layer</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># 最后 20%: 全部解冻，但用更小学习率</span>
        <span class="n">unfreeze_vision_encoder</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="c1"># 视觉编码器学习率 = 0.1 * 基础学习率</span>
</code></pre></div>

<h3 id="lora-rank">LoRA Rank 自适应选择</h3>
<p><strong>基于重要性的 Rank 分配：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_layer_importance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;计算各层的 Fisher 信息矩阵迹&quot;&quot;&quot;</span>
    <span class="n">importance_scores</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">[:</span><span class="n">num_samples</span><span class="p">]:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">compute_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">])</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                <span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">param</span><span class="p">,</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">importance_scores</span><span class="p">:</span>
                    <span class="n">importance_scores</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">importance_scores</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">grad</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="c1"># 归一化</span>
    <span class="n">total</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">importance_scores</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">importance_scores</span><span class="p">:</span>
        <span class="n">importance_scores</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">/=</span> <span class="n">total</span>

    <span class="k">return</span> <span class="n">importance_scores</span>

<span class="c1"># 根据重要性分配 rank</span>
<span class="k">def</span> <span class="nf">adaptive_rank_allocation</span><span class="p">(</span><span class="n">importance_scores</span><span class="p">,</span> <span class="n">total_rank_budget</span><span class="o">=</span><span class="mi">512</span><span class="p">):</span>
    <span class="n">rank_allocation</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">importance_scores</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># rank ∈ [4, 64]</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">score</span> <span class="o">*</span> <span class="n">total_rank_budget</span><span class="p">)))</span>
        <span class="c1"># 确保是 4 的倍数（硬件友好）</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="p">(</span><span class="n">rank</span> <span class="o">//</span> <span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="mi">4</span>
        <span class="n">rank_allocation</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">rank</span>
    <span class="k">return</span> <span class="n">rank_allocation</span>
</code></pre></div>

<h3 id="_5">混合精度训练的稳定性</h3>
<p><strong>BF16 vs FP16 选择：</strong></p>
<div class="codehilite"><pre><span></span><code>特性          FP16            BF16
-----------------------------------------
动态范围      ±65504          ±3.4e38
精度          高              中
硬件支持      广泛            A100+
溢出风险      高              极低
推荐场景      推理为主        训练为主
</code></pre></div>

<p><strong>混合精度最佳实践：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 自动混合精度配置</span>
<span class="kn">from</span> <span class="nn">torch.cuda.amp</span> <span class="kn">import</span> <span class="n">autocast</span><span class="p">,</span> <span class="n">GradScaler</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">GradScaler</span><span class="p">(</span>
    <span class="n">init_scale</span><span class="o">=</span><span class="mf">2.</span><span class="o">**</span><span class="mi">16</span><span class="p">,</span>  <span class="c1"># 初始缩放因子</span>
    <span class="n">growth_factor</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>   <span class="c1"># 增长因子</span>
    <span class="n">backoff_factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>  <span class="c1"># 回退因子</span>
    <span class="n">growth_interval</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span>  <span class="c1"># 增长间隔</span>
<span class="p">)</span>

<span class="c1"># 训练循环</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">autocast</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">):</span>  <span class="c1"># 或 torch.float16</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">compute_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">])</span>

    <span class="c1"># 梯度缩放</span>
    <span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># 梯度裁剪（在缩放空间）</span>
    <span class="n">scaler</span><span class="o">.</span><span class="n">unscale_</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

    <span class="c1"># 优化器步骤</span>
    <span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
    <span class="n">scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

    <span class="c1"># 监控溢出</span>
    <span class="k">if</span> <span class="n">scaler</span><span class="o">.</span><span class="n">get_scale</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;梯度溢出，当前 scale: </span><span class="si">{</span><span class="n">scaler</span><span class="o">.</span><span class="n">get_scale</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<h2 id="_6">本章小结</h2>
<p>本章系统介绍了 VLM 的监督微调策略，涵盖了从指令设计到训练优化的完整流程：</p>
<p><strong>核心要点回顾：</strong></p>
<ol>
<li><strong>指令设计</strong>：清晰的模板、合理的系统提示、多轮对话处理、视觉-语言对齐</li>
<li><strong>损失函数</strong>：自回归损失、掩码策略、多任务平衡、grounding 损失</li>
<li><strong>PEFT 方法</strong>：LoRA、QLoRA、Adapter 的原理与选择</li>
<li><strong>训练稳定性</strong>：学习率调度、梯度裁剪、权重初始化、checkpoint 策略</li>
</ol>
<p><strong>关键公式汇总：</strong></p>
<ul>
<li>语言模型损失：$\mathcal{L}_{LM} = -\sum_{t=1}^{T} \log P(x_t | x_{&lt;t}, I)$</li>
<li>LoRA 分解：$W' = W + BA$，其中 $r \ll \min(d, k)$</li>
<li>多任务损失：$\mathcal{L}_{total} = \sum_{i=1}^{N} w_i \mathcal{L}_i$</li>
<li>不确定性加权：$\mathcal{L}_{total} = \sum_{i=1}^{N} \frac{1}{2\sigma_i^2} \mathcal{L}_i + \log \sigma_i$</li>
</ul>
<h2 id="_7">练习题</h2>
<h3 id="_8">基础题（理解概念）</h3>
<p><strong>题 1：指令模板设计</strong>
设计一个支持多图像输入和 CoT（Chain of Thought）推理的指令模板。要求能够处理图像间的比较任务。</p>
<details markdown="1">
<summary>💡 提示</summary>
<p>考虑：1) 如何标记不同图像 2) CoT 的步骤分隔 3) 图像引用方式
</details></p>
<details>
<summary>📝 参考答案</summary>
<div class="codehilite"><pre><span></span><code><span class="n">System</span><span class="o">:</span><span class="w"> </span><span class="err">你是一个视觉推理助手，请一步步分析问题。</span>

<span class="n">User</span><span class="o">:</span><span class="w"> </span><span class="err">比较</span><span class="w"> </span><span class="o">&lt;</span><span class="n">image_1</span><span class="o">&gt;</span><span class="w"> </span><span class="err">和</span><span class="w"> </span><span class="o">&lt;</span><span class="n">image_2</span><span class="o">&gt;</span><span class="err">，找出主要差异。</span><span class="n">Assistant</span><span class="o">:</span><span class="w"> </span><span class="err">让我逐步分析：</span>
<span class="err">步骤</span><span class="mi">1</span><span class="err">：观察图像</span><span class="mi">1</span><span class="err">的主要元素</span><span class="o">...</span>
<span class="err">步骤</span><span class="mi">2</span><span class="err">：观察图像</span><span class="mi">2</span><span class="err">的主要元素</span><span class="o">...</span>
<span class="err">步骤</span><span class="mi">3</span><span class="err">：对比差异</span><span class="o">...</span>
<span class="err">结论：主要差异包括</span><span class="o">...</span>
</code></pre></div>

</details>
<p><strong>题 2：LoRA Rank 选择</strong>
给定一个 7B 参数的 VLM，显存限制为 24GB，如何选择合适的 LoRA rank？考虑训练效率和模型性能的权衡。</p>
<details>
<summary>💡 提示</summary>
<p>计算不同 rank 下的参数量和显存占用，考虑梯度和优化器状态</p>
</details>
<details>
<summary>📝 参考答案</summary>
<p>对于 7B 模型，24GB 显存下的 rank 选择：</p>
<ul>
<li>QLoRA 4-bit: r=64 可行（~20GB）</li>
<li>LoRA 16-bit: r=16-32 合适（~18-22GB）</li>
<li>建议从 r=16 开始，监控验证集性能，逐步增加到 r=32</li>
</ul>
</details>
<p><strong>题 3：多任务损失平衡</strong>
三个任务的初始损失分别为：图像描述 2.5、VQA 3.2、OCR 1.8。如何设置初始权重？</p>
<details>
<summary>💡 提示</summary>
<p>考虑损失量级差异和任务重要性</p>
</details>
<details>
<summary>📝 参考答案</summary>
<p>初始权重设置：</p>
<ul>
<li>图像描述: 1.0 / 2.5 = 0.4</li>
<li>VQA: 1.0 / 3.2 = 0.31</li>
<li>OCR: 1.0 / 1.8 = 0.56
归一化后：[0.32, 0.25, 0.43]</li>
</ul>
</details>
<h3 id="_9">挑战题（深入思考）</h3>
<p><strong>题 4：梯度累积策略</strong>
显存只够 batch_size=2，但最优 batch_size=32。设计一个考虑 VLM 特性的梯度累积方案。</p>
<details>
<summary>💡 提示</summary>
<p>考虑：1) 累积步数 2) 学习率缩放 3) 梯度裁剪时机</p>
</details>
<details>
<summary>📝 参考答案</summary>
<div class="codehilite"><pre><span></span><code><span class="n">accumulation_steps</span> <span class="o">=</span> <span class="mi">16</span>  <span class="c1"># 2 * 16 = 32</span>
<span class="n">effective_batch_size</span> <span class="o">=</span> <span class="mi">32</span>

<span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">compute_loss</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">/</span> <span class="n">accumulation_steps</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">accumulation_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># 在累积完成后裁剪</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

<span class="c1"># 学习率线性缩放</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">base_lr</span> <span class="o">*</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">effective_batch_size</span> <span class="o">/</span> <span class="n">base_batch_size</span><span class="p">)</span>
</code></pre></div>

</details>
<p><strong>题 5：视觉编码器微调决策</strong>
新任务是医学图像分析，与预训练数据（自然图像）差异很大。设计一个渐进式解冻方案。</p>
<details>
<summary>💡 提示</summary>
<p>医学图像的低层特征（边缘、纹理）可能相似，但高层语义差异大</p>
</details>
<details>
<summary>📝 参考答案</summary>
<p>三阶段解冻方案：</p>
<ol>
<li>阶段1（0-30%）：冻结所有层，只训练投影层</li>
<li>阶段2（30-70%）：解冻后 50% 层，学习率 0.1x</li>
<li>阶段3（70-100%）：全部解冻，前 50% 层用 0.01x 学习率，后 50% 用 0.1x
理由：保留低层通用特征，重点调整高层语义理解</li>
</ol>
</details>
<p><strong>题 6：训练崩溃诊断</strong>
训练到 40% 时损失突然变成 NaN。给出系统的排查流程和可能原因。</p>
<details>
<summary>💡 提示</summary>
<p>从数据、模型、优化器三个角度排查</p>
</details>
<details>
<summary>📝 参考答案</summary>
<p>排查流程：</p>
<ol>
<li>
<p><strong>数据检查</strong>：
   - 是否有损坏图像（全黑、全白）
   - 标签是否有异常值
   - Token ID 是否超出词表范围</p>
</li>
<li>
<p><strong>梯度监控</strong>：
   - 检查梯度范数历史
   - 定位第一个 NaN 出现的层
   - 查看该 batch 的具体数据</p>
</li>
<li>
<p><strong>可能原因及解决</strong>：
   - 学习率过大 → 降低学习率
   - 除零错误 → 添加 epsilon
   - FP16 溢出 → 切换到 BF16 或增大 loss scale
   - 某层未初始化 → 检查新增模块</p>
</li>
</ol>
</details>
<p><strong>题 7：PEFT 组合优化</strong>
设计一个针对 VLM 不同组件的混合 PEFT 策略，目标是在 16GB 显存限制下最大化性能。</p>
<details>
<summary>💡 提示</summary>
<p>不同组件的重要性和参数量不同</p>
</details>
<details>
<summary>📝 参考答案</summary>
<p>混合策略：</p>
<div class="codehilite"><pre><span></span><code><span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;vision_encoder&quot;</span><span class="p">:</span> <span class="s2">&quot;frozen&quot;</span><span class="p">,</span>         <span class="c1"># 省显存</span>
    <span class="s2">&quot;vision_projection&quot;</span><span class="p">:</span> <span class="s2">&quot;full&quot;</span><span class="p">,</span>        <span class="c1"># 关键组件，参数少</span>
    <span class="s2">&quot;llm_embed&quot;</span><span class="p">:</span> <span class="s2">&quot;frozen&quot;</span><span class="p">,</span>              <span class="c1"># 词嵌入不动</span>
    <span class="s2">&quot;llm_layers[0:8]&quot;</span><span class="p">:</span> <span class="s2">&quot;lora_r8&quot;</span><span class="p">,</span>      <span class="c1"># 底层小 rank</span>
    <span class="s2">&quot;llm_layers[8:24]&quot;</span><span class="p">:</span> <span class="s2">&quot;lora_r16&quot;</span><span class="p">,</span>    <span class="c1"># 中层中 rank</span>
    <span class="s2">&quot;llm_layers[24:32]&quot;</span><span class="p">:</span> <span class="s2">&quot;lora_r32&quot;</span><span class="p">,</span>   <span class="c1"># 高层大 rank</span>
    <span class="s2">&quot;llm_head&quot;</span><span class="p">:</span> <span class="s2">&quot;lora_r8&quot;</span><span class="p">,</span>             <span class="c1"># 输出头小 rank</span>
<span class="p">}</span>
</code></pre></div>

<p>预计显存：~14GB，可训练参数：~200M</p>
</details>
<p><strong>题 8：开放性思考</strong>
如果要设计下一代 VLM 的 SFT 策略，你认为最需要改进的三个方向是什么？</p>
<details>
<summary>💡 提示</summary>
<p>思考当前方法的局限性和实际应用需求</p>
</details>
<details>
<summary>📝 参考答案</summary>
<p>三个改进方向：</p>
<ol>
<li><strong>动态计算分配</strong>：根据图像复杂度动态调整计算资源，简单图像用少量 token，复杂图像用更多</li>
<li><strong>主动学习</strong>：训练过程中自动识别模型薄弱环节，动态调整数据采样策略</li>
<li><strong>跨模态一致性</strong>：设计更好的对齐机制，确保视觉理解和语言生成的一致性，减少幻觉</li>
</ol>
<p>理由：当前 SFT 策略较为静态，没有充分利用模型的自适应能力</p>
</details>
<h2 id="gotchas">常见陷阱与错误 (Gotchas)</h2>
<h3 id="_10">数据相关陷阱</h3>
<ol>
<li><strong>图像 Token 计算错误</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># 错误：忘记图像 token 占用</span>
<span class="n">max_length</span> <span class="o">=</span> <span class="mi">2048</span>  <span class="c1"># 以为有 2048 个文本 token</span>

<span class="c1"># 正确：扣除图像占用</span>
<span class="n">image_tokens</span> <span class="o">=</span> <span class="mi">576</span>  <span class="c1"># ViT-L/14 </span>
<span class="n">text_budget</span> <span class="o">=</span> <span class="mi">2048</span> <span class="o">-</span> <span class="n">image_tokens</span>  <span class="c1"># 实际只有 1472</span>
</code></pre></div>

<ol start="2">
<li><strong>响应截断问题</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># 陷阱：响应被截断但仍计算损失</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_length</span><span class="p">:</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[:</span><span class="n">max_length</span><span class="p">]</span>  <span class="c1"># 可能截断到响应中间</span>

<span class="c1"># 解决：确保完整响应或不计算损失</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_length</span><span class="p">:</span>
    <span class="c1"># 找到最后一个完整句子</span>
    <span class="n">last_period</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[:</span><span class="n">max_length</span><span class="p">]</span><span class="o">.</span><span class="n">rfind</span><span class="p">(</span><span class="n">period_token_id</span><span class="p">)</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[:</span><span class="n">last_period</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div>

<h3 id="_11">训练相关陷阱</h3>
<ol start="3">
<li><strong>LoRA 与正则化冲突</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># 陷阱：对 LoRA 参数使用 weight decay</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># 正确：LoRA 参数不用 weight decay</span>
<span class="n">lora_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span> <span class="k">if</span> <span class="s1">&#39;lora&#39;</span> <span class="ow">in</span> <span class="n">n</span><span class="p">]</span>
<span class="n">other_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span> <span class="k">if</span> <span class="s1">&#39;lora&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">n</span><span class="p">]</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">([</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">lora_params</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">other_params</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">}</span>
<span class="p">])</span>
</code></pre></div>

<ol start="4">
<li><strong>混合精度的 NaN 陷阱</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># 陷阱：某些操作在 FP16 下不稳定</span>
<span class="n">attention_scores</span> <span class="o">=</span> <span class="n">Q</span> <span class="o">@</span> <span class="n">K</span><span class="o">.</span><span class="n">T</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">d_k</span><span class="p">)</span>  <span class="c1"># 可能溢出</span>

<span class="c1"># 解决：关键操作用 FP32</span>
<span class="k">with</span> <span class="n">autocast</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">Q</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">@</span> <span class="n">K</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">T</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">d_k</span><span class="p">)</span>
</code></pre></div>

<ol start="5">
<li><strong>梯度累积与 Batch Norm</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># 陷阱：梯度累积时 BN 统计不准</span>
<span class="c1"># BN 只看当前 micro-batch，不是完整 batch</span>

<span class="c1"># 解决：使用 Layer Norm 或 RMSNorm</span>
<span class="c1"># 或者同步 BN（但会增加通信开销）</span>
</code></pre></div>

<h3 id="_12">评估相关陷阱</h3>
<ol start="6">
<li><strong>生成长度偏差</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># 陷阱：不同长度的生成影响评估</span>
<span class="c1"># 短回答可能 perplexity 更低但信息不足</span>

<span class="c1"># 解决：控制生成长度或使用长度归一化</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">log_prob</span> <span class="o">/</span> <span class="p">(</span><span class="n">length</span> <span class="o">**</span> <span class="n">alpha</span><span class="p">)</span>  <span class="c1"># alpha ~ 0.6-0.8</span>
</code></pre></div>

<ol start="7">
<li><strong>Teacher Forcing 与推理不一致</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># 训练时：每步都用真实标签</span>
<span class="c1"># 推理时：用自己的预测，误差累积</span>

<span class="c1"># 缓解：Scheduled Sampling</span>
<span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">teacher_forcing_ratio</span><span class="p">:</span>
    <span class="n">input_token</span> <span class="o">=</span> <span class="n">ground_truth</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">input_token</span> <span class="o">=</span> <span class="n">predicted</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div>

<h3 id="_13">调试技巧</h3>
<p><strong>快速诊断检查点：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 1. 检查梯度</span>
python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import torch; ckpt=torch.load(&#39;model.pt&#39;); print([(k,v.abs().max().item()) for k,v in ckpt[&#39;grad_dict&#39;].items() if v.abs().max() &gt; 100])&quot;</span>

<span class="c1"># 2. 检查权重分布</span>
python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import torch; ckpt=torch.load(&#39;model.pt&#39;); print([(k, v.std().item()) for k,v in ckpt[&#39;model_state_dict&#39;].items() if &#39;weight&#39; in k])&quot;</span>

<span class="c1"># 3. 检查损失历史</span>
python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import torch; import matplotlib.pyplot as plt; ckpt=torch.load(&#39;model.pt&#39;); plt.plot(ckpt[&#39;loss_history&#39;]); plt.show()&quot;</span>
</code></pre></div>

<h2 id="_14">最佳实践检查清单</h2>
<h3 id="_15">训练前准备</h3>
<ul>
<li>[ ] <strong>数据验证</strong></li>
<li>[ ] 所有图像可正常加载</li>
<li>[ ] 图像尺寸分布合理（没有极端大/小）</li>
<li>[ ] 文本长度分布检查</li>
<li>
<p>[ ] 特殊字符正确转义</p>
</li>
<li>
<p>[ ] <strong>模型配置</strong></p>
</li>
<li>[ ] 图像 token 数计算正确</li>
<li>[ ] 上下文长度设置合理</li>
<li>[ ] LoRA rank 根据显存选择</li>
<li>
<p>[ ] 检查点保存路径可写</p>
</li>
<li>
<p>[ ] <strong>训练配置</strong></p>
</li>
<li>[ ] 学习率设置（通常 1e-4 到 5e-4）</li>
<li>[ ] Warmup 步数（建议 3-10% 总步数）</li>
<li>[ ] 梯度裁剪阈值（通常 1.0）</li>
<li>[ ] 混合精度设置（BF16 优于 FP16）</li>
</ul>
<h3 id="_16">训练中监控</h3>
<ul>
<li>[ ] <strong>性能指标</strong></li>
<li>[ ] GPU 利用率 &gt; 90%</li>
<li>[ ] 显存使用稳定（无泄漏）</li>
<li>[ ] 训练速度（samples/sec）稳定</li>
<li>
<p>[ ] 数据加载不是瓶颈</p>
</li>
<li>
<p>[ ] <strong>模型指标</strong></p>
</li>
<li>[ ] 损失平稳下降</li>
<li>[ ] 梯度范数稳定</li>
<li>[ ] 学习率按计划衰减</li>
<li>
<p>[ ] 验证集指标提升</p>
</li>
<li>
<p>[ ] <strong>异常检测</strong></p>
</li>
<li>[ ] 无 NaN/Inf 出现</li>
<li>[ ] 无梯度爆炸/消失</li>
<li>[ ] 权重更新幅度合理</li>
<li>[ ] 生成样本质量检查</li>
</ul>
<h3 id="_17">训练后验证</h3>
<ul>
<li>[ ] <strong>模型质量</strong></li>
<li>[ ] 基础能力保持（没有灾难性遗忘）</li>
<li>[ ] 新任务性能达标</li>
<li>[ ] 生成多样性适中</li>
<li>
<p>[ ] 无明显偏见或有害输出</p>
</li>
<li>
<p>[ ] <strong>部署准备</strong></p>
</li>
<li>[ ] 模型可正确加载</li>
<li>[ ] 推理速度满足要求</li>
<li>[ ] 量化后精度损失可接受</li>
<li>
<p>[ ] 边界case测试通过</p>
</li>
<li>
<p>[ ] <strong>文档完善</strong></p>
</li>
<li>[ ] 训练配置记录</li>
<li>[ ] 数据集版本记录</li>
<li>[ ] 性能基准记录</li>
<li>[ ] 已知问题记录</li>
</ul>
<h3 id="_18">问题排查顺序</h3>
<p>遇到问题时，按以下顺序排查：</p>
<ol>
<li>
<p><strong>数据问题</strong>（50% 的问题来源）
   - 检查当前 batch 的数据
   - 验证数据预处理流程</p>
</li>
<li>
<p><strong>配置问题</strong>（30% 的问题来源）
   - 学习率是否过大
   - Batch size 是否合适</p>
</li>
<li>
<p><strong>代码问题</strong>（20% 的问题来源）
   - 是否有维度不匹配
   - 是否有未初始化的参数</p>
</li>
</ol>
<hr />
<p><em>通过本章的学习，您应该已经掌握了 VLM 监督微调的核心技术。下一章我们将探讨分布式训练与优化，进一步提升训练效率。</em></p>
<p><a href="index.html">← 返回目录</a> | <a href="chapter4.html">下一章：分布式训练与优化 →</a></p>
            </article>
            
            <nav class="page-nav"><a href="chapter2.html" class="nav-link prev">← 第 2 章：数据准备与预处理</a><a href="chapter4.html" class="nav-link next">第 4 章：分布式训练与优化 →</a></nav>
        </main>
    </div>
</body>
</html>